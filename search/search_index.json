{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GBC Publication Analysis This project analyses how biodata resources are described, mentioned and cited in the literature. Core module: globalbiodata (ORM-like classes, DB helpers) Utilities: gbcutils/* (connections, querying, parsing, cleaning, etc) Schema: Database tables & relationships See the API Reference for full class & method docs (pulled from Google-style docstrings).","title":"Home"},{"location":"#gbc-publication-analysis","text":"This project analyses how biodata resources are described, mentioned and cited in the literature. Core module: globalbiodata (ORM-like classes, DB helpers) Utilities: gbcutils/* (connections, querying, parsing, cleaning, etc) Schema: Database tables & relationships See the API Reference for full class & method docs (pulled from Google-style docstrings).","title":"GBC Publication Analysis"},{"location":"schema/","text":"\ud83e\uddf1 Database Schema Below is the full schema diagram used in the GBC publication analysis project. Core Tables resource Describes a biodata resource Linked to URLs and associated connection statuses/online status Linked to publications by inventory, mentions and accessions/data citation inventory links represented in the resource_publication table mentions links represented in the resource_mention table accession/data citation links represented in the accession and accession_publication tables Versioned by version_id , which is fully described in the version table each workflow run/data source represented by a different version, so provenece is captured by this too is_latest represents the most recent version of the resource is_gcbr captures GCBR status Represented in API by Resource object publication Stores metadata for publications (title, journal, year, etc.) Affiliation country inferred upon import Linked to resources by inventory, mentions and accessions/data citation inventory links represented in the resource_publication table mentions links represented in the resource_mention table accession/data citation links represented in the accession and accession_publication tables Linked to associated grants and grant agencies Represented in API by Publication object resource_publication Joins resource and publication tables, allowing a many-to-many type of relationship This link represents the inventory. i.e. a link here means that the publication describes the resource. Represented in API as the .publications attribute of a Resource object url Describes URL of a resource Represented in API by URL object connection_status Describes ping/connection information for a URL is_online inferred from ping return status Represented in API by ConnectionStatus object grant Describes grants associated with resources/publications and their agencies Represented in API by Grant object grant_agency Records for grant_agencies (name, estimated country) parent_agency_id and representative_agency_id represents relationships between agencies parent_agency_id introduces hierarchical relationships (i.e. agency X funds agency Y) representative_agency_id groups different names/aliases for the same agency (i.e. XYZ and X.Y.Z. are the same agency, and XYZ is the representative/canonical name for the whole group) Represented in API by GrantAgency object resource_grant Joins resource and grant tables Allows a many-to-many relationship between the two Represented in API as the .grants attribute of a Resource object publication_grant Joins publication and grant tables Allows a many-to-many relationship between the two Represented in API as the .grants attribute of a Publication object version Describes the pipeline/process that identified the data Means of versioning & data provenece Represented in API by Version object accession Holds data citations/accessions plus their associated metadata Links to resources via resource_id Versioned by version_id Represented in API by Accession object accession_publication Maps accessions to the publications they were found in Table to join accession and publication tables, allowing a many-to-many type of relationship Represented in API as the .publications attribute of an Accession object resource_mention Links resources to publications that have mentioned the resource's name in the article text Includes context, classifier confidence, etc. Represented in API by ResourceMention object Note: additional tables 2 additional tables are present in the schema definition file, which are largely independent of this analysis work: open_letter : track the signatures of GBC's open letter wildsi : imported data from the WilDSI project , about sequence data usage These tables do not have API classes.","title":"Database Schema"},{"location":"schema/#database-schema","text":"Below is the full schema diagram used in the GBC publication analysis project.","title":"\ud83e\uddf1 Database Schema"},{"location":"schema/#core-tables","text":"","title":"Core Tables"},{"location":"schema/#resource","text":"Describes a biodata resource Linked to URLs and associated connection statuses/online status Linked to publications by inventory, mentions and accessions/data citation inventory links represented in the resource_publication table mentions links represented in the resource_mention table accession/data citation links represented in the accession and accession_publication tables Versioned by version_id , which is fully described in the version table each workflow run/data source represented by a different version, so provenece is captured by this too is_latest represents the most recent version of the resource is_gcbr captures GCBR status Represented in API by Resource object","title":"resource"},{"location":"schema/#publication","text":"Stores metadata for publications (title, journal, year, etc.) Affiliation country inferred upon import Linked to resources by inventory, mentions and accessions/data citation inventory links represented in the resource_publication table mentions links represented in the resource_mention table accession/data citation links represented in the accession and accession_publication tables Linked to associated grants and grant agencies Represented in API by Publication object","title":"publication"},{"location":"schema/#resource_publication","text":"Joins resource and publication tables, allowing a many-to-many type of relationship This link represents the inventory. i.e. a link here means that the publication describes the resource. Represented in API as the .publications attribute of a Resource object","title":"resource_publication"},{"location":"schema/#url","text":"Describes URL of a resource Represented in API by URL object","title":"url"},{"location":"schema/#connection_status","text":"Describes ping/connection information for a URL is_online inferred from ping return status Represented in API by ConnectionStatus object","title":"connection_status"},{"location":"schema/#grant","text":"Describes grants associated with resources/publications and their agencies Represented in API by Grant object","title":"grant"},{"location":"schema/#grant_agency","text":"Records for grant_agencies (name, estimated country) parent_agency_id and representative_agency_id represents relationships between agencies parent_agency_id introduces hierarchical relationships (i.e. agency X funds agency Y) representative_agency_id groups different names/aliases for the same agency (i.e. XYZ and X.Y.Z. are the same agency, and XYZ is the representative/canonical name for the whole group) Represented in API by GrantAgency object","title":"grant_agency"},{"location":"schema/#resource_grant","text":"Joins resource and grant tables Allows a many-to-many relationship between the two Represented in API as the .grants attribute of a Resource object","title":"resource_grant"},{"location":"schema/#publication_grant","text":"Joins publication and grant tables Allows a many-to-many relationship between the two Represented in API as the .grants attribute of a Publication object","title":"publication_grant"},{"location":"schema/#version","text":"Describes the pipeline/process that identified the data Means of versioning & data provenece Represented in API by Version object","title":"version"},{"location":"schema/#accession","text":"Holds data citations/accessions plus their associated metadata Links to resources via resource_id Versioned by version_id Represented in API by Accession object","title":"accession"},{"location":"schema/#accession_publication","text":"Maps accessions to the publications they were found in Table to join accession and publication tables, allowing a many-to-many type of relationship Represented in API as the .publications attribute of an Accession object","title":"accession_publication"},{"location":"schema/#resource_mention","text":"Links resources to publications that have mentioned the resource's name in the article text Includes context, classifier confidence, etc. Represented in API by ResourceMention object","title":"resource_mention"},{"location":"schema/#note-additional-tables","text":"2 additional tables are present in the schema definition file, which are largely independent of this analysis work: open_letter : track the signatures of GBC's open letter wildsi : imported data from the WilDSI project , about sequence data usage These tables do not have API classes.","title":"Note: additional tables"},{"location":"usage/","text":"Usage Create database connection import globalbiodata as gbc import gbcutils.db as gbc_db # fetch read-only connection to the GBC cloud SQL db gcp , db_engine , db_conn = gbc_db . get_gbc_connection ( readonly = True ) Fetch publication by PubMed ID # fetch a publication by PubMed ID pub = gbc . Publication . fetch_by_pubmed_id ( 33651556 , conn = db_conn ) print ( \"Publication search result:\" ) print ( f \"pubmed_id: { pub . pubmed_id } \" ) print ( f \"title: { pub . title } \" ) print ( f \"authors: { pub . authors } \" ) Search for resources by name and inspect properties # fetch a resource chebi = gbc . Resource . fetch_by_name ( 'ChEBI' , conn = db_conn ) print ( \"ChEBI search result:\" ) print ( f \"short_name: { chebi . short_name } \" ) print ( f \"common_name: { chebi . common_name } \" ) print ( f \"full_name: { chebi . full_name } \" ) print ( f \"is_gcbr: { chebi . is_gcbr } \" ) print ( f \"is_online: { chebi . is_online () } \" ) # note that this is a function call not a property # check all inventory publications for your resource # and find first published record of this resource first_published , inv_pubmed_ids = None , [] for inv_pub in chebi . publications : inv_pubmed_ids . append ( inv_pub . pubmed_id ) if not first_published or inv_pub . publication_date < first_published . publication_date : first_published = inv_pub print ( f \"All inventory publication PubMed IDs for { chebi . short_name } : { inv_pubmed_ids } \" ) print ( f \"First published record of { chebi . short_name } :\" ) print ( f \" \\t pubmed_id: { first_published . pubmed_id } \" ) print ( f \" \\t title: { first_published . title } \" ) print ( f \" \\t publication_date: { first_published . publication_date } \" ) Find all publications citing a specific accession # find the PMC ID for all publications that contain the accession '0.9.4.1' accessions = gbc . Accession . fetch_by_accession ( '0.9.4.1' , conn = db_conn ) for accession in accessions : accession_pmc_ids = [ ap . pmc_id for ap in accession . publications if ap is not None ] print ( f \"accession: { accession . accession } ; accession_pmc_ids: { accession_pmc_ids } \" ) Fetch all publications mentioning a specific resource # fetch all publications mentioning a specific resource allie = gbc . Resource . fetch_by_name ( 'Allie' , conn = db_conn ) resource_mentions = gbc . ResourceMention . fetch_by_resource_id ( allie . id , conn = db_conn ) # all_pubs_with_mentions = set(mention.publication for mention in resource_mentions if mention.publication is not None) for mention in resource_mentions : found_aliases = [ alias . matched_alias for alias in mention . matched_aliases ] print ( f \"pubmed_id: { mention . publication . pubmed_id } ; match_count: { mention . match_count } ; matched_aliases: { found_aliases } \" ) print ( f \" \\t title: { mention . publication . title } \\n \" )","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#create-database-connection","text":"import globalbiodata as gbc import gbcutils.db as gbc_db # fetch read-only connection to the GBC cloud SQL db gcp , db_engine , db_conn = gbc_db . get_gbc_connection ( readonly = True )","title":"Create database connection"},{"location":"usage/#fetch-publication-by-pubmed-id","text":"# fetch a publication by PubMed ID pub = gbc . Publication . fetch_by_pubmed_id ( 33651556 , conn = db_conn ) print ( \"Publication search result:\" ) print ( f \"pubmed_id: { pub . pubmed_id } \" ) print ( f \"title: { pub . title } \" ) print ( f \"authors: { pub . authors } \" )","title":"Fetch publication by PubMed ID"},{"location":"usage/#search-for-resources-by-name-and-inspect-properties","text":"# fetch a resource chebi = gbc . Resource . fetch_by_name ( 'ChEBI' , conn = db_conn ) print ( \"ChEBI search result:\" ) print ( f \"short_name: { chebi . short_name } \" ) print ( f \"common_name: { chebi . common_name } \" ) print ( f \"full_name: { chebi . full_name } \" ) print ( f \"is_gcbr: { chebi . is_gcbr } \" ) print ( f \"is_online: { chebi . is_online () } \" ) # note that this is a function call not a property # check all inventory publications for your resource # and find first published record of this resource first_published , inv_pubmed_ids = None , [] for inv_pub in chebi . publications : inv_pubmed_ids . append ( inv_pub . pubmed_id ) if not first_published or inv_pub . publication_date < first_published . publication_date : first_published = inv_pub print ( f \"All inventory publication PubMed IDs for { chebi . short_name } : { inv_pubmed_ids } \" ) print ( f \"First published record of { chebi . short_name } :\" ) print ( f \" \\t pubmed_id: { first_published . pubmed_id } \" ) print ( f \" \\t title: { first_published . title } \" ) print ( f \" \\t publication_date: { first_published . publication_date } \" )","title":"Search for resources by name and inspect properties"},{"location":"usage/#find-all-publications-citing-a-specific-accession","text":"# find the PMC ID for all publications that contain the accession '0.9.4.1' accessions = gbc . Accession . fetch_by_accession ( '0.9.4.1' , conn = db_conn ) for accession in accessions : accession_pmc_ids = [ ap . pmc_id for ap in accession . publications if ap is not None ] print ( f \"accession: { accession . accession } ; accession_pmc_ids: { accession_pmc_ids } \" )","title":"Find all publications citing a specific accession"},{"location":"usage/#fetch-all-publications-mentioning-a-specific-resource","text":"# fetch all publications mentioning a specific resource allie = gbc . Resource . fetch_by_name ( 'Allie' , conn = db_conn ) resource_mentions = gbc . ResourceMention . fetch_by_resource_id ( allie . id , conn = db_conn ) # all_pubs_with_mentions = set(mention.publication for mention in resource_mentions if mention.publication is not None) for mention in resource_mentions : found_aliases = [ alias . matched_alias for alias in mention . matched_aliases ] print ( f \"pubmed_id: { mention . publication . pubmed_id } ; match_count: { mention . match_count } ; matched_aliases: { found_aliases } \" ) print ( f \" \\t title: { mention . publication . title } \\n \" )","title":"Fetch all publications mentioning a specific resource"},{"location":"api/gbcutils_db/","text":"gbcutils.db get_gbc_connection get_gbc_connection ( test = False , readonly = True , sqluser = \"gbcreader\" , sqlpass = None , ) Get a connection to the GBC Google Cloud SQL instance. Parameters: test ( bool , default: False ) \u2013 Whether to connect to the test database. readonly ( bool , default: True ) \u2013 Whether to connect in read-only mode. sqluser ( str , default: 'gbcreader' ) \u2013 The SQL username to connect with. sqlpass ( str , default: None ) \u2013 The SQL password to connect with. Required if readonly is False. Returns: tuple [ Connector , Engine , Connection ] \u2013 A tuple containing the Google Cloud SQL Connector, SQLAlchemy Engine, and SQLAlchemy Connection objects. Source code in gbcutils/db.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def get_gbc_connection ( test : bool = False , readonly : bool = True , sqluser : str = \"gbcreader\" , sqlpass : str = None ) -> tuple [ Connector , Engine , Connection ]: \"\"\"Get a connection to the GBC Google Cloud SQL instance. Args: test (bool): Whether to connect to the test database. readonly (bool): Whether to connect in read-only mode. sqluser (str): The SQL username to connect with. sqlpass (str): The SQL password to connect with. Required if readonly is False. Returns: A tuple containing the Google Cloud SQL Connector, SQLAlchemy Engine, and SQLAlchemy Connection objects. \"\"\" if not readonly and not sqlpass : raise ValueError ( \"You must provide a SQL user credentials if not in readonly mode.\" ) database = \"gbc-publication-analysis:europe-west2:gbc-sql/gbc-publication-analysis\" database += \"-test\" if test else \"\" instance , db_name = database . split ( '/' ) gcp_connector = Connector () def getcloudconn () -> pymysql . connections . Connection : conn : pymysql . connections . Connection = gcp_connector . connect ( instance , \"pymysql\" , user = sqluser , password = sqlpass , db = db_name ) return conn cloud_engine = db . create_engine ( \"mysql+pymysql://\" , creator = getcloudconn , pool_recycle = 60 * 5 , pool_pre_ping = True ) cloud_engine . execution_options ( isolation_level = \"READ COMMITTED\" ) return ( gcp_connector , cloud_engine , cloud_engine . connect ())","title":"db"},{"location":"api/gbcutils_db/#gbcutils.db","text":"","title":"db"},{"location":"api/gbcutils_db/#gbcutils.db.get_gbc_connection","text":"get_gbc_connection ( test = False , readonly = True , sqluser = \"gbcreader\" , sqlpass = None , ) Get a connection to the GBC Google Cloud SQL instance. Parameters: test ( bool , default: False ) \u2013 Whether to connect to the test database. readonly ( bool , default: True ) \u2013 Whether to connect in read-only mode. sqluser ( str , default: 'gbcreader' ) \u2013 The SQL username to connect with. sqlpass ( str , default: None ) \u2013 The SQL password to connect with. Required if readonly is False. Returns: tuple [ Connector , Engine , Connection ] \u2013 A tuple containing the Google Cloud SQL Connector, SQLAlchemy Engine, and SQLAlchemy Connection objects. Source code in gbcutils/db.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def get_gbc_connection ( test : bool = False , readonly : bool = True , sqluser : str = \"gbcreader\" , sqlpass : str = None ) -> tuple [ Connector , Engine , Connection ]: \"\"\"Get a connection to the GBC Google Cloud SQL instance. Args: test (bool): Whether to connect to the test database. readonly (bool): Whether to connect in read-only mode. sqluser (str): The SQL username to connect with. sqlpass (str): The SQL password to connect with. Required if readonly is False. Returns: A tuple containing the Google Cloud SQL Connector, SQLAlchemy Engine, and SQLAlchemy Connection objects. \"\"\" if not readonly and not sqlpass : raise ValueError ( \"You must provide a SQL user credentials if not in readonly mode.\" ) database = \"gbc-publication-analysis:europe-west2:gbc-sql/gbc-publication-analysis\" database += \"-test\" if test else \"\" instance , db_name = database . split ( '/' ) gcp_connector = Connector () def getcloudconn () -> pymysql . connections . Connection : conn : pymysql . connections . Connection = gcp_connector . connect ( instance , \"pymysql\" , user = sqluser , password = sqlpass , db = db_name ) return conn cloud_engine = db . create_engine ( \"mysql+pymysql://\" , creator = getcloudconn , pool_recycle = 60 * 5 , pool_pre_ping = True ) cloud_engine . execution_options ( isolation_level = \"READ COMMITTED\" ) return ( gcp_connector , cloud_engine , cloud_engine . connect ())","title":"get_gbc_connection"},{"location":"api/gbcutils_europepmc/","text":"gbcutils.europepmc epmc_search epmc_search ( query , result_type = \"core\" , limit = 0 , cursor = None , returncursor = False , fields = [], page_size = 1000 , ) Search Europe PMC with pagination support. Parameters: query ( str ) \u2013 The search query string. result_type ( str , default: 'core' ) \u2013 The type of results to return ('core', 'lite', 'idlist'). limit ( int , default: 0 ) \u2013 Maximum number of results to return (0 for all - default). cursor ( Optional [ str ] , default: None ) \u2013 Cursor mark for pagination (None for first page). returncursor ( bool , default: False ) \u2013 If True, return the final cursor along with results. fields ( list , default: [] ) \u2013 List of fields to include in results (empty for all). page_size ( int , default: 1000 ) \u2013 Number of results per page (max 1000). Returns: Optional [ list ] \u2013 List of search results, or (results, cursor) if returncursor is True . Source code in gbcutils/europepmc.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def epmc_search ( query : str , result_type : str = 'core' , limit : int = 0 , cursor : Optional [ str ] = None , returncursor : bool = False , fields : list = [], page_size : int = 1000 ) -> Optional [ list ]: \"\"\"Search Europe PMC with pagination support. Args: query (str): The search query string. result_type (str): The type of results to return ('core', 'lite', 'idlist'). limit (int): Maximum number of results to return (0 for all - default). cursor (Optional[str]): Cursor mark for pagination (None for first page). returncursor (bool): If True, return the final cursor along with results. fields (list): List of fields to include in results (empty for all). page_size (int): Number of results per page (max 1000). Returns: List of search results, or `(results, cursor)` if `returncursor` is `True`. \"\"\" page_size = limit if ( limit and limit <= page_size ) else page_size all_results = [] more_data = True while more_data : search_params = { 'query' : query , 'resultType' : result_type , 'format' : 'json' , 'pageSize' : page_size , 'cursorMark' : cursor } data = query_europepmc ( f \" { epmc_base_url } /search\" , search_params ) limit = limit if ( limit > 0 and limit < data . get ( 'hitCount' )) else data . get ( 'hitCount' ) if cursor is None and VERBOSE : print ( f \"-- Expecting { limit } of { data . get ( 'hitCount' ) } results for query ' { query } '!\" ) if fields : restricted_results = [] for result in data [ 'resultList' ][ 'result' ]: restricted_results . append ({ k : result [ k ] for k in fields if k in result }) data [ 'resultList' ][ 'result' ] = restricted_results all_results . extend ( data [ 'resultList' ][ 'result' ]) cursor = data . get ( 'nextCursorMark' ) print ( f \" \\t -- got { len ( all_results ) } results (cursor: { cursor } )\" ) if VERBOSE else None if not cursor : more_data = False if len ( all_results ) >= limit > 0 : if VERBOSE : print ( f \"Reached limit of { limit } results, stopping.\" ) more_data = False cursor = None # reset cursor to avoid further queries return ( all_results , cursor ) if returncursor else all_results get_fulltext_body get_fulltext_body ( pmcid , path = None , dest = '/tmp' ) Fetch the full text body of a publication from Europe PMC by PMCID. If a local path is provided, it will first check for a local XML file. If not found, it will download the XML from Europe PMC. Parameters: pmcid ( str ) \u2013 The PMCID of the publication (e.g., 'PMC123456'). path ( Optional [ str ] , default: None ) \u2013 Local directory path to search for XML files. dest ( str , default: '/tmp' ) \u2013 Destination directory for downloaded/extracted XML files. Returns: tuple \u2013 (text_blocks, table_blocks) where text_blocks is a list of strings representing the main text sections, and table_blocks is a list of strings representing the tables extracted from the XML. Source code in gbcutils/europepmc.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 def get_fulltext_body ( pmcid : str , path : Optional [ str ] = None , dest : str = '/tmp' ) -> tuple : \"\"\" Fetch the full text body of a publication from Europe PMC by PMCID. If a local path is provided, it will first check for a local XML file. If not found, it will download the XML from Europe PMC. Args: pmcid (str): The PMCID of the publication (e.g., 'PMC123456'). path (Optional[str]): Local directory path to search for XML files. dest (str): Destination directory for downloaded/extracted XML files. Returns: (text_blocks, table_blocks) where text_blocks is a list of strings representing the main text sections, and table_blocks is a list of strings representing the tables extracted from the XML. \"\"\" xml = None path = path or dest # check for files downloaded from FTP or local XMLs if path : # find the matching record in the filesystem if VERBOSE : print ( f \"[local] Searching { path } for full text XML for { pmcid } \" ) xml = _find_local_fulltext ( pmcid , path , dest = dest ) if not xml : # if not found locally, try the EuropePMC FTP if VERBOSE : print ( f \"[ftp] Searching EuropePMC FTP for full text XML for { pmcid } \" ) xml = _find_europepmc_ftp_fulltext ( pmcid , dest = dest ) if not xml : # 1. Download the XML if VERBOSE : print ( f \"[api] Querying EuropePMC's API for full text XML for { pmcid } \" ) url = f \" { epmc_base_url } / { pmcid } /fullTextXML\" response = requests . get ( url ) if response . status_code != 200 : return ( None , None ) xml = response . text if not xml : return ( None , None ) # 2. Parse with BeautifulSoup if VERBOSE : print ( \" \\n \ud83c\udf89 XML found! Parsing text and tables from XML body\" ) soup = BeautifulSoup ( xml , \"lxml-xml\" ) # 3. Extract body text with headers text_blocks = [] # 1. Title title = soup . find ( \"article-title\" ) if title : title_text = title . get_text ( strip = True ) if title_text : text_blocks . append ( f \"# TITLE \\n { title_text } \" ) text_blocks . append ( \" \\n \" ) # 2. Abstract abstract = soup . find ( \"abstract\" ) if abstract : abstract_title = abstract . find ( \"title\" ) if abstract_title and abstract_title . get_text ( strip = True ) . upper () == 'ABSTRACT' : abstract_title . extract () # remove the title text_blocks . append ( f \"# ABSTRACT \\n { _section_to_text ( abstract ) } \" ) # 2.1. Other metadata sections funding_statement = soup . find ( \"funding-statement\" ) if funding_statement : funding_text = funding_statement . get_text ( strip = True ) if funding_text : text_blocks . append ( f \"### FUNDING \\n { funding_text } \" ) all_custom_metas = soup . find_all ( \"custom-meta\" ) for custom_meta in all_custom_metas : meta_name = custom_meta . find ( \"meta-name\" ) . get_text ( strip = True ) meta_value = custom_meta . find ( \"meta-value\" ) . get_text ( strip = True ) if meta_name and meta_value : text_blocks . append ( f \"### { meta_name . upper () } \\n { meta_value } \" ) text_blocks . append ( \" \\n \" ) # 3. Tables (captions + content) table_blocks = [] for tbl in soup . find_all ( \"table-wrap\" ): tbl . extract () processed_table = _preprocess_xml_table ( tbl ) if processed_table : table_blocks . append ( processed_table ) # 4. Main body (sections + paragraphs) # excluded_section_types = [\"supplementary-material\", \"orcid\"] excluded_section_types = [ \"orcid\" ] body = soup . find ( \"body\" ) if body : all_sections = body . find_all ( \"sec\" , recursive = False ) for elem in all_sections : if elem . get ( \"sec-type\" ) in excluded_section_types : continue text_blocks . append ( _section_to_text ( elem )) text_blocks . append ( \" \\n \" ) return text_blocks , table_blocks query_europepmc query_europepmc ( endpoint , request_params = None , no_exit = False ) Query Europe PMC REST API endpoint with retries. Parameters: endpoint ( str ) \u2013 The Europe PMC API endpoint to query. request_params ( Optional [ dict ] , default: None ) \u2013 Dictionary of query parameters. no_exit ( bool , default: False ) \u2013 If True , do not exit on error, return None instead. Returns: Optional [ dict ] \u2013 The JSON response from Europe PMC, or None on error if no_exit is True . Source code in gbcutils/europepmc.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def query_europepmc ( endpoint : str , request_params : Optional [ dict ] = None , no_exit : bool = False ) -> Optional [ dict ]: \"\"\"Query Europe PMC REST API endpoint with retries. Args: endpoint (str): The Europe PMC API endpoint to query. request_params (Optional[dict]): Dictionary of query parameters. no_exit (bool): If `True`, do not exit on error, return `None` instead. Returns: The JSON response from Europe PMC, or `None` on error if `no_exit` is `True`. \"\"\" if not endpoint . startswith ( \"http\" ): endpoint = f \" { epmc_base_url } / { endpoint } \" for attempt in range ( max_retries ): try : response = session . get ( endpoint , params = request_params , timeout = 15 ) if response . status_code == 200 : return response . json () if 'json' in response . headers . get ( 'Content-Type' , '' ) else response . text else : if no_exit : return None else : sys . exit ( f \"Error: { response . status_code } for { endpoint } \" ) except requests . RequestException as e : print ( f \"\u26a0\ufe0f Request failed: { e } . Retrying ( { attempt + 1 } / { max_retries } )...\" ) sys . exit ( \"Max retries exceeded.\" )","title":"europepmc"},{"location":"api/gbcutils_europepmc/#gbcutils.europepmc","text":"","title":"europepmc"},{"location":"api/gbcutils_europepmc/#gbcutils.europepmc.epmc_search","text":"epmc_search ( query , result_type = \"core\" , limit = 0 , cursor = None , returncursor = False , fields = [], page_size = 1000 , ) Search Europe PMC with pagination support. Parameters: query ( str ) \u2013 The search query string. result_type ( str , default: 'core' ) \u2013 The type of results to return ('core', 'lite', 'idlist'). limit ( int , default: 0 ) \u2013 Maximum number of results to return (0 for all - default). cursor ( Optional [ str ] , default: None ) \u2013 Cursor mark for pagination (None for first page). returncursor ( bool , default: False ) \u2013 If True, return the final cursor along with results. fields ( list , default: [] ) \u2013 List of fields to include in results (empty for all). page_size ( int , default: 1000 ) \u2013 Number of results per page (max 1000). Returns: Optional [ list ] \u2013 List of search results, or (results, cursor) if returncursor is True . Source code in gbcutils/europepmc.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def epmc_search ( query : str , result_type : str = 'core' , limit : int = 0 , cursor : Optional [ str ] = None , returncursor : bool = False , fields : list = [], page_size : int = 1000 ) -> Optional [ list ]: \"\"\"Search Europe PMC with pagination support. Args: query (str): The search query string. result_type (str): The type of results to return ('core', 'lite', 'idlist'). limit (int): Maximum number of results to return (0 for all - default). cursor (Optional[str]): Cursor mark for pagination (None for first page). returncursor (bool): If True, return the final cursor along with results. fields (list): List of fields to include in results (empty for all). page_size (int): Number of results per page (max 1000). Returns: List of search results, or `(results, cursor)` if `returncursor` is `True`. \"\"\" page_size = limit if ( limit and limit <= page_size ) else page_size all_results = [] more_data = True while more_data : search_params = { 'query' : query , 'resultType' : result_type , 'format' : 'json' , 'pageSize' : page_size , 'cursorMark' : cursor } data = query_europepmc ( f \" { epmc_base_url } /search\" , search_params ) limit = limit if ( limit > 0 and limit < data . get ( 'hitCount' )) else data . get ( 'hitCount' ) if cursor is None and VERBOSE : print ( f \"-- Expecting { limit } of { data . get ( 'hitCount' ) } results for query ' { query } '!\" ) if fields : restricted_results = [] for result in data [ 'resultList' ][ 'result' ]: restricted_results . append ({ k : result [ k ] for k in fields if k in result }) data [ 'resultList' ][ 'result' ] = restricted_results all_results . extend ( data [ 'resultList' ][ 'result' ]) cursor = data . get ( 'nextCursorMark' ) print ( f \" \\t -- got { len ( all_results ) } results (cursor: { cursor } )\" ) if VERBOSE else None if not cursor : more_data = False if len ( all_results ) >= limit > 0 : if VERBOSE : print ( f \"Reached limit of { limit } results, stopping.\" ) more_data = False cursor = None # reset cursor to avoid further queries return ( all_results , cursor ) if returncursor else all_results","title":"epmc_search"},{"location":"api/gbcutils_europepmc/#gbcutils.europepmc.get_fulltext_body","text":"get_fulltext_body ( pmcid , path = None , dest = '/tmp' ) Fetch the full text body of a publication from Europe PMC by PMCID. If a local path is provided, it will first check for a local XML file. If not found, it will download the XML from Europe PMC. Parameters: pmcid ( str ) \u2013 The PMCID of the publication (e.g., 'PMC123456'). path ( Optional [ str ] , default: None ) \u2013 Local directory path to search for XML files. dest ( str , default: '/tmp' ) \u2013 Destination directory for downloaded/extracted XML files. Returns: tuple \u2013 (text_blocks, table_blocks) where text_blocks is a list of strings representing the main text sections, and table_blocks is a list of strings representing the tables extracted from the XML. Source code in gbcutils/europepmc.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 def get_fulltext_body ( pmcid : str , path : Optional [ str ] = None , dest : str = '/tmp' ) -> tuple : \"\"\" Fetch the full text body of a publication from Europe PMC by PMCID. If a local path is provided, it will first check for a local XML file. If not found, it will download the XML from Europe PMC. Args: pmcid (str): The PMCID of the publication (e.g., 'PMC123456'). path (Optional[str]): Local directory path to search for XML files. dest (str): Destination directory for downloaded/extracted XML files. Returns: (text_blocks, table_blocks) where text_blocks is a list of strings representing the main text sections, and table_blocks is a list of strings representing the tables extracted from the XML. \"\"\" xml = None path = path or dest # check for files downloaded from FTP or local XMLs if path : # find the matching record in the filesystem if VERBOSE : print ( f \"[local] Searching { path } for full text XML for { pmcid } \" ) xml = _find_local_fulltext ( pmcid , path , dest = dest ) if not xml : # if not found locally, try the EuropePMC FTP if VERBOSE : print ( f \"[ftp] Searching EuropePMC FTP for full text XML for { pmcid } \" ) xml = _find_europepmc_ftp_fulltext ( pmcid , dest = dest ) if not xml : # 1. Download the XML if VERBOSE : print ( f \"[api] Querying EuropePMC's API for full text XML for { pmcid } \" ) url = f \" { epmc_base_url } / { pmcid } /fullTextXML\" response = requests . get ( url ) if response . status_code != 200 : return ( None , None ) xml = response . text if not xml : return ( None , None ) # 2. Parse with BeautifulSoup if VERBOSE : print ( \" \\n \ud83c\udf89 XML found! Parsing text and tables from XML body\" ) soup = BeautifulSoup ( xml , \"lxml-xml\" ) # 3. Extract body text with headers text_blocks = [] # 1. Title title = soup . find ( \"article-title\" ) if title : title_text = title . get_text ( strip = True ) if title_text : text_blocks . append ( f \"# TITLE \\n { title_text } \" ) text_blocks . append ( \" \\n \" ) # 2. Abstract abstract = soup . find ( \"abstract\" ) if abstract : abstract_title = abstract . find ( \"title\" ) if abstract_title and abstract_title . get_text ( strip = True ) . upper () == 'ABSTRACT' : abstract_title . extract () # remove the title text_blocks . append ( f \"# ABSTRACT \\n { _section_to_text ( abstract ) } \" ) # 2.1. Other metadata sections funding_statement = soup . find ( \"funding-statement\" ) if funding_statement : funding_text = funding_statement . get_text ( strip = True ) if funding_text : text_blocks . append ( f \"### FUNDING \\n { funding_text } \" ) all_custom_metas = soup . find_all ( \"custom-meta\" ) for custom_meta in all_custom_metas : meta_name = custom_meta . find ( \"meta-name\" ) . get_text ( strip = True ) meta_value = custom_meta . find ( \"meta-value\" ) . get_text ( strip = True ) if meta_name and meta_value : text_blocks . append ( f \"### { meta_name . upper () } \\n { meta_value } \" ) text_blocks . append ( \" \\n \" ) # 3. Tables (captions + content) table_blocks = [] for tbl in soup . find_all ( \"table-wrap\" ): tbl . extract () processed_table = _preprocess_xml_table ( tbl ) if processed_table : table_blocks . append ( processed_table ) # 4. Main body (sections + paragraphs) # excluded_section_types = [\"supplementary-material\", \"orcid\"] excluded_section_types = [ \"orcid\" ] body = soup . find ( \"body\" ) if body : all_sections = body . find_all ( \"sec\" , recursive = False ) for elem in all_sections : if elem . get ( \"sec-type\" ) in excluded_section_types : continue text_blocks . append ( _section_to_text ( elem )) text_blocks . append ( \" \\n \" ) return text_blocks , table_blocks","title":"get_fulltext_body"},{"location":"api/gbcutils_europepmc/#gbcutils.europepmc.query_europepmc","text":"query_europepmc ( endpoint , request_params = None , no_exit = False ) Query Europe PMC REST API endpoint with retries. Parameters: endpoint ( str ) \u2013 The Europe PMC API endpoint to query. request_params ( Optional [ dict ] , default: None ) \u2013 Dictionary of query parameters. no_exit ( bool , default: False ) \u2013 If True , do not exit on error, return None instead. Returns: Optional [ dict ] \u2013 The JSON response from Europe PMC, or None on error if no_exit is True . Source code in gbcutils/europepmc.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def query_europepmc ( endpoint : str , request_params : Optional [ dict ] = None , no_exit : bool = False ) -> Optional [ dict ]: \"\"\"Query Europe PMC REST API endpoint with retries. Args: endpoint (str): The Europe PMC API endpoint to query. request_params (Optional[dict]): Dictionary of query parameters. no_exit (bool): If `True`, do not exit on error, return `None` instead. Returns: The JSON response from Europe PMC, or `None` on error if `no_exit` is `True`. \"\"\" if not endpoint . startswith ( \"http\" ): endpoint = f \" { epmc_base_url } / { endpoint } \" for attempt in range ( max_retries ): try : response = session . get ( endpoint , params = request_params , timeout = 15 ) if response . status_code == 200 : return response . json () if 'json' in response . headers . get ( 'Content-Type' , '' ) else response . text else : if no_exit : return None else : sys . exit ( f \"Error: { response . status_code } for { endpoint } \" ) except requests . RequestException as e : print ( f \"\u26a0\ufe0f Request failed: { e } . Retrying ( { attempt + 1 } / { max_retries } )...\" ) sys . exit ( \"Max retries exceeded.\" )","title":"query_europepmc"},{"location":"api/gbcutils_metadata/","text":"gbcutils.metadata get_article_metadata get_article_metadata ( article_id , basepath = \"\" , shards = default_shard_count ) Return the metadata dict for article_id from sharded JSONL.gz files under basepath . Expects lines like: {\"pmc_id\": \"...\", \"meta\": {...}}. Parameters: article_id ( str ) \u2013 The article identifier (e.g., PMC ID). basepath ( str , default: '' ) \u2013 The base path where the shard files are located. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: Optional [ dict ] \u2013 The metadata dictionary for the article_id, or None if not found. Source code in gbcutils/metadata.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def get_article_metadata ( article_id : str , basepath : str = '' , shards : int = default_shard_count ) -> Optional [ dict ]: \"\"\" Return the metadata dict for `article_id` from sharded JSONL.gz files under `basepath`. Expects lines like: {\"pmc_id\": \"...\", \"meta\": {...}}. Args: article_id (str): The article identifier (e.g., PMC ID). basepath (str): The base path where the shard files are located. shards (int): The total number of shards (default: 128). Returns: The metadata dictionary for the article_id, or None if not found. \"\"\" global _shard_cache k = shard_key ( article_id , shards ) if k not in _shard_cache : shard_file = shard_path ( k , basepath = basepath , shards = shards ) shard_map = {} if os . path . exists ( shard_file ): with gzip . open ( shard_file , 'rt' , encoding = 'utf-8' ) as fh : for line in fh : try : rec = json . loads ( line ) pid = rec . get ( 'id' ) if pid is not None : shard_map [ str ( pid )] = rec . get ( 'meta' ) or rec except Exception : # swallow bad lines but keep going; optionally log if you want pass _shard_cache = {} # Reset the cache for this shard - only hold 1 shard at a time in memory _shard_cache [ k ] = shard_map return _shard_cache [ k ] . get ( str ( article_id )) shard_key shard_key ( article_id , shards = default_shard_count ) Return the shard key (0 to shards-1) for the given article_id string. Uses MD5 hash to ensure even distribution. Parameters: article_id ( str ) \u2013 The article identifier (e.g., PMC ID). shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: int \u2013 The shard key for the given article_id. Source code in gbcutils/metadata.py 12 13 14 15 16 17 18 19 20 21 22 23 24 def shard_key ( article_id : str , shards : int = default_shard_count ) -> int : \"\"\" Return the shard key (0 to shards-1) for the given article_id string. Uses MD5 hash to ensure even distribution. Args: article_id (str): The article identifier (e.g., PMC ID). shards (int): The total number of shards (default: 128). Returns: The shard key for the given article_id. \"\"\" return int ( hashlib . md5 ( article_id . encode ()) . hexdigest (), 16 ) % shards shard_path shard_path ( k , basepath = '' , shards = default_shard_count ) Return the file path for shard key k under basepath . Parameters: k ( int ) \u2013 The shard key. basepath ( str , default: '' ) \u2013 The base path where the shard file is located. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: str \u2013 The file path for the shard key k . Source code in gbcutils/metadata.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def shard_path ( k : int , basepath : str = '' , shards : int = default_shard_count ) -> str : \"\"\" Return the file path for shard key `k` under `basepath`. Args: k (int): The shard key. basepath (str): The base path where the shard file is located. shards (int): The total number of shards (default: 128). Returns: The file path for the shard key `k`. \"\"\" width = max ( 2 , len ( str ( max ( 1 , shards ) - 1 ))) return os . path . join ( basepath , f \"metadata_shard_ { k : 0 { width } d } .jsonl.gz\" ) sort_ids_by_shard sort_ids_by_shard ( ids_iterable , shards = default_shard_count ) Return IDs sorted so that those sharing a shard are contiguous. Parameters: ids_iterable ( list ) \u2013 List of article IDs to sort. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: list \u2013 The list of article IDs, sorted by their shard key. Source code in gbcutils/metadata.py 77 78 79 80 81 82 83 84 85 86 87 def sort_ids_by_shard ( ids_iterable : list , shards : int = default_shard_count ) -> list : \"\"\"Return IDs sorted so that those sharing a shard are contiguous. Args: ids_iterable (list): List of article IDs to sort. shards (int): The total number of shards (default: 128). Returns: The list of article IDs, sorted by their shard key. \"\"\" return sorted ( ids_iterable , key = lambda _id : shard_key ( str ( _id ), shards ))","title":"metadata"},{"location":"api/gbcutils_metadata/#gbcutils.metadata","text":"","title":"metadata"},{"location":"api/gbcutils_metadata/#gbcutils.metadata.get_article_metadata","text":"get_article_metadata ( article_id , basepath = \"\" , shards = default_shard_count ) Return the metadata dict for article_id from sharded JSONL.gz files under basepath . Expects lines like: {\"pmc_id\": \"...\", \"meta\": {...}}. Parameters: article_id ( str ) \u2013 The article identifier (e.g., PMC ID). basepath ( str , default: '' ) \u2013 The base path where the shard files are located. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: Optional [ dict ] \u2013 The metadata dictionary for the article_id, or None if not found. Source code in gbcutils/metadata.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def get_article_metadata ( article_id : str , basepath : str = '' , shards : int = default_shard_count ) -> Optional [ dict ]: \"\"\" Return the metadata dict for `article_id` from sharded JSONL.gz files under `basepath`. Expects lines like: {\"pmc_id\": \"...\", \"meta\": {...}}. Args: article_id (str): The article identifier (e.g., PMC ID). basepath (str): The base path where the shard files are located. shards (int): The total number of shards (default: 128). Returns: The metadata dictionary for the article_id, or None if not found. \"\"\" global _shard_cache k = shard_key ( article_id , shards ) if k not in _shard_cache : shard_file = shard_path ( k , basepath = basepath , shards = shards ) shard_map = {} if os . path . exists ( shard_file ): with gzip . open ( shard_file , 'rt' , encoding = 'utf-8' ) as fh : for line in fh : try : rec = json . loads ( line ) pid = rec . get ( 'id' ) if pid is not None : shard_map [ str ( pid )] = rec . get ( 'meta' ) or rec except Exception : # swallow bad lines but keep going; optionally log if you want pass _shard_cache = {} # Reset the cache for this shard - only hold 1 shard at a time in memory _shard_cache [ k ] = shard_map return _shard_cache [ k ] . get ( str ( article_id ))","title":"get_article_metadata"},{"location":"api/gbcutils_metadata/#gbcutils.metadata.shard_key","text":"shard_key ( article_id , shards = default_shard_count ) Return the shard key (0 to shards-1) for the given article_id string. Uses MD5 hash to ensure even distribution. Parameters: article_id ( str ) \u2013 The article identifier (e.g., PMC ID). shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: int \u2013 The shard key for the given article_id. Source code in gbcutils/metadata.py 12 13 14 15 16 17 18 19 20 21 22 23 24 def shard_key ( article_id : str , shards : int = default_shard_count ) -> int : \"\"\" Return the shard key (0 to shards-1) for the given article_id string. Uses MD5 hash to ensure even distribution. Args: article_id (str): The article identifier (e.g., PMC ID). shards (int): The total number of shards (default: 128). Returns: The shard key for the given article_id. \"\"\" return int ( hashlib . md5 ( article_id . encode ()) . hexdigest (), 16 ) % shards","title":"shard_key"},{"location":"api/gbcutils_metadata/#gbcutils.metadata.shard_path","text":"shard_path ( k , basepath = '' , shards = default_shard_count ) Return the file path for shard key k under basepath . Parameters: k ( int ) \u2013 The shard key. basepath ( str , default: '' ) \u2013 The base path where the shard file is located. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: str \u2013 The file path for the shard key k . Source code in gbcutils/metadata.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def shard_path ( k : int , basepath : str = '' , shards : int = default_shard_count ) -> str : \"\"\" Return the file path for shard key `k` under `basepath`. Args: k (int): The shard key. basepath (str): The base path where the shard file is located. shards (int): The total number of shards (default: 128). Returns: The file path for the shard key `k`. \"\"\" width = max ( 2 , len ( str ( max ( 1 , shards ) - 1 ))) return os . path . join ( basepath , f \"metadata_shard_ { k : 0 { width } d } .jsonl.gz\" )","title":"shard_path"},{"location":"api/gbcutils_metadata/#gbcutils.metadata.sort_ids_by_shard","text":"sort_ids_by_shard ( ids_iterable , shards = default_shard_count ) Return IDs sorted so that those sharing a shard are contiguous. Parameters: ids_iterable ( list ) \u2013 List of article IDs to sort. shards ( int , default: default_shard_count ) \u2013 The total number of shards (default: 128). Returns: list \u2013 The list of article IDs, sorted by their shard key. Source code in gbcutils/metadata.py 77 78 79 80 81 82 83 84 85 86 87 def sort_ids_by_shard ( ids_iterable : list , shards : int = default_shard_count ) -> list : \"\"\"Return IDs sorted so that those sharing a shard are contiguous. Args: ids_iterable (list): List of article IDs to sort. shards (int): The total number of shards (default: 128). Returns: The list of article IDs, sorted by their shard key. \"\"\" return sorted ( ids_iterable , key = lambda _id : shard_key ( str ( _id ), shards ))","title":"sort_ids_by_shard"},{"location":"api/gbcutils_scibert/","text":"gbcutils.scibert_classify classify_mentions classify_mentions ( this_id , candidate_pairs , tokenizer = None , model = None , device = None , ) Classify candidate resource mentions using the SciBERT model. Parameters: this_id ( str ) \u2013 Identifier for the publication or text being classified. candidate_pairs ( list ) \u2013 List of tuples (sentence, matched_alias, resource_name). tokenizer ( PreTrainedTokenizer , default: None ) \u2013 The tokenizer to use. model ( PreTrainedModel , default: None ) \u2013 The pre-trained SciBERT model. device ( device , default: None ) \u2013 The device to run the model on. Returns: list \u2013 List of prediction dictionaries with keys: - prediction (int): 1 for positive, 0 for negative. - id (str): The provided this_id. - resource_name (str): The name of the resource. - matched_alias (str): The alias that was matched. - sentence (str): The sentence in which the alias was found. - confidence (float): The confidence score for the prediction. Source code in gbcutils/scibert_classify.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def classify_mentions ( this_id : str , candidate_pairs : list , tokenizer : Optional [ PreTrainedTokenizer ] = None , model : Optional [ PreTrainedModel ] = None , device : Optional [ torch . device ] = None ) -> list : \"\"\" Classify candidate resource mentions using the SciBERT model. Args: this_id (str): Identifier for the publication or text being classified. candidate_pairs (list): List of tuples (sentence, matched_alias, resource_name). tokenizer (PreTrainedTokenizer, optional): The tokenizer to use. model (PreTrainedModel, optional): The pre-trained SciBERT model. device (torch.device, optional): The device to run the model on. Returns: List of prediction dictionaries with keys: - prediction (int): 1 for positive, 0 for negative. - id (str): The provided this_id. - resource_name (str): The name of the resource. - matched_alias (str): The alias that was matched. - sentence (str): The sentence in which the alias was found. - confidence (float): The confidence score for the prediction. \"\"\" predictions = [] for sentence , alias , resource in tqdm ( candidate_pairs , desc = \"\ud83d\udd0d Classifying\" ): inputs = tokenizer ( alias , sentence , return_tensors = \"pt\" , truncation = True , padding = \"max_length\" , max_length = 512 ) . to ( device ) with torch . no_grad (): outputs = model ( ** inputs ) probs = torch . nn . functional . softmax ( outputs . logits , dim =- 1 ) pred = torch . argmax ( probs , dim = 1 ) . item () if pred == 1 : predictions . append ({ \"prediction\" : 1 , \"id\" : this_id , \"resource_name\" : resource , \"matched_alias\" : alias , \"sentence\" : sentence , \"confidence\" : probs [ 0 , 1 ] . item () }) else : predictions . append ({ \"prediction\" : 0 , \"id\" : this_id , \"resource_name\" : resource , \"matched_alias\" : alias , \"sentence\" : sentence , \"confidence\" : probs [ 0 , 0 ] . item () }) return predictions get_resource_mentions get_resource_mentions ( text , resource_names , case_sensitive_resources = [] ) Identify mentions of resources from a body of text, by text matching. Parameters: text ( str ) \u2013 The full text to search. resource_names ( list ) \u2013 List of resource name lists (each list contains aliases for a resource). case_sensitive_resources ( list , default: [] ) \u2013 List of resource names that should be matched case-sensitively. Returns: list \u2013 List of tuples (sentence, matched_alias, resource_name) . Source code in gbcutils/scibert_classify.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def get_resource_mentions ( text : str , resource_names : list , case_sensitive_resources : list = []) -> list : \"\"\" Identify mentions of resources from a body of text, by text matching. Args: text (str): The full text to search. resource_names (list): List of resource name lists (each list contains aliases for a resource). case_sensitive_resources (list): List of resource names that should be matched case-sensitively. Returns: List of tuples `(sentence, matched_alias, resource_name)`. \"\"\" mentions = [] # precompile regex patterns for each resource alias # This is more efficient than compiling them on-the-fly in the loop compiled_patterns = [] for resource in resource_names : resource_name = resource [ 0 ] for alias in resource : if resource_name in case_sensitive_resources : alias_norm = _normalize_alias_for_regex ( alias ) pattern_case_sensitive = re . compile ( rf \"(?<![A-Za-z]) { alias_norm } (?![A-Za-z])\" ) compiled_patterns . append (( resource_name , alias , pattern_case_sensitive , True )) else : # Use case-insensitive pattern for all other resources alias_norm = _normalize_alias_for_regex ( alias . lower ()) pattern_case_insensitive = re . compile ( rf \"(?<![A-Za-z]) { alias_norm } (?![A-Za-z])\" ) compiled_patterns . append (( resource_name , alias , pattern_case_insensitive , False )) # Tokenize the text into sentences and search for resource names sentences = sent_tokenize ( text ) # Use NLTK to split into sentences for sentence in sentences : sentence = sentence . replace ( \" \\n \" , \" \" ) s_lowered = sentence . lower () this_sentence_mentions = [] for resource_name , alias , pattern , is_case_sensitive in compiled_patterns : if not is_case_sensitive and pattern . search ( s_lowered ): this_sentence_mentions . append (( sentence . strip (), alias , resource_name )) elif is_case_sensitive and pattern . search ( sentence ): this_sentence_mentions . append (( sentence . strip (), alias , resource_name )) if len ( this_sentence_mentions ) > 1 : this_sentence_mentions = _remove_substring_matches ( this_sentence_mentions ) mentions . extend ( this_sentence_mentions ) # if a large number of matches are found for one resource, switch to case sensitive mode filtered_mentions = [] alias_counts = Counter ([ m [ 1 ] for m in mentions ]) for alias , count in alias_counts . items (): if count > case_sensitive_threshold and alias not in case_sensitive_resources : if VERBOSE : print ( f \"\u26a0\ufe0f { count } matches found for { alias } - switching to case sensitive mode\" ) pattern_case_sensitive = re . compile ( rf \"(?<![A-Za-z]) { re . escape ( alias ) } (?![A-Za-z])\" ) for m in mentions : if m [ 1 ] == alias and pattern_case_sensitive . search ( m [ 0 ]): filtered_mentions . append ( m ) else : this_alias_mentions = [ m for m in mentions if m [ 1 ] == alias ] filtered_mentions . extend ( this_alias_mentions ) # Remove duplicates mentions = list ( set ( filtered_mentions )) # Remove empty mentions mentions = [ m for m in mentions if m [ 0 ]] return mentions load_model load_model ( model_name , num_threads = 1 ) Load the SciBERT model and tokenizer for sequence classification. Parameters: model_name ( str ) \u2013 The name/path of the pre-trained model. num_threads ( int , default: 1 ) \u2013 Number of CPU threads to use if running on CPU. Returns: tuple \u2013 (tokenizer, model, device) Source code in gbcutils/scibert_classify.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def load_model ( model_name : str , num_threads : int = 1 ) -> tuple : \"\"\" Load the SciBERT model and tokenizer for sequence classification. Args: model_name (str): The name/path of the pre-trained model. num_threads (int): Number of CPU threads to use if running on CPU. Returns: `(tokenizer, model, device)` \"\"\" if torch . cuda . is_available (): if VERBOSE : print ( \" \\t \ud83e\udde0 Using CUDA GPU for inference\" ) device = torch . device ( \"cuda\" ) elif torch . backends . mps . is_available (): if VERBOSE : print ( \" \\t \ud83e\udde0 Using Apple MPS GPU for inference\" ) device = torch . device ( \"mps\" ) else : if VERBOSE : print ( \" \\t \ud83e\udde0 Using CPU for inference\" ) device = torch . device ( \"cpu\" ) torch . set_num_threads ( num_threads ) tokenizer = AutoTokenizer . from_pretrained ( model_name ) model = AutoModelForSequenceClassification . from_pretrained ( model_name ) . to ( device ) model . eval () return ( tokenizer , model , device )","title":"scibert_classify"},{"location":"api/gbcutils_scibert/#gbcutils.scibert_classify","text":"","title":"scibert_classify"},{"location":"api/gbcutils_scibert/#gbcutils.scibert_classify.classify_mentions","text":"classify_mentions ( this_id , candidate_pairs , tokenizer = None , model = None , device = None , ) Classify candidate resource mentions using the SciBERT model. Parameters: this_id ( str ) \u2013 Identifier for the publication or text being classified. candidate_pairs ( list ) \u2013 List of tuples (sentence, matched_alias, resource_name). tokenizer ( PreTrainedTokenizer , default: None ) \u2013 The tokenizer to use. model ( PreTrainedModel , default: None ) \u2013 The pre-trained SciBERT model. device ( device , default: None ) \u2013 The device to run the model on. Returns: list \u2013 List of prediction dictionaries with keys: - prediction (int): 1 for positive, 0 for negative. - id (str): The provided this_id. - resource_name (str): The name of the resource. - matched_alias (str): The alias that was matched. - sentence (str): The sentence in which the alias was found. - confidence (float): The confidence score for the prediction. Source code in gbcutils/scibert_classify.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def classify_mentions ( this_id : str , candidate_pairs : list , tokenizer : Optional [ PreTrainedTokenizer ] = None , model : Optional [ PreTrainedModel ] = None , device : Optional [ torch . device ] = None ) -> list : \"\"\" Classify candidate resource mentions using the SciBERT model. Args: this_id (str): Identifier for the publication or text being classified. candidate_pairs (list): List of tuples (sentence, matched_alias, resource_name). tokenizer (PreTrainedTokenizer, optional): The tokenizer to use. model (PreTrainedModel, optional): The pre-trained SciBERT model. device (torch.device, optional): The device to run the model on. Returns: List of prediction dictionaries with keys: - prediction (int): 1 for positive, 0 for negative. - id (str): The provided this_id. - resource_name (str): The name of the resource. - matched_alias (str): The alias that was matched. - sentence (str): The sentence in which the alias was found. - confidence (float): The confidence score for the prediction. \"\"\" predictions = [] for sentence , alias , resource in tqdm ( candidate_pairs , desc = \"\ud83d\udd0d Classifying\" ): inputs = tokenizer ( alias , sentence , return_tensors = \"pt\" , truncation = True , padding = \"max_length\" , max_length = 512 ) . to ( device ) with torch . no_grad (): outputs = model ( ** inputs ) probs = torch . nn . functional . softmax ( outputs . logits , dim =- 1 ) pred = torch . argmax ( probs , dim = 1 ) . item () if pred == 1 : predictions . append ({ \"prediction\" : 1 , \"id\" : this_id , \"resource_name\" : resource , \"matched_alias\" : alias , \"sentence\" : sentence , \"confidence\" : probs [ 0 , 1 ] . item () }) else : predictions . append ({ \"prediction\" : 0 , \"id\" : this_id , \"resource_name\" : resource , \"matched_alias\" : alias , \"sentence\" : sentence , \"confidence\" : probs [ 0 , 0 ] . item () }) return predictions","title":"classify_mentions"},{"location":"api/gbcutils_scibert/#gbcutils.scibert_classify.get_resource_mentions","text":"get_resource_mentions ( text , resource_names , case_sensitive_resources = [] ) Identify mentions of resources from a body of text, by text matching. Parameters: text ( str ) \u2013 The full text to search. resource_names ( list ) \u2013 List of resource name lists (each list contains aliases for a resource). case_sensitive_resources ( list , default: [] ) \u2013 List of resource names that should be matched case-sensitively. Returns: list \u2013 List of tuples (sentence, matched_alias, resource_name) . Source code in gbcutils/scibert_classify.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def get_resource_mentions ( text : str , resource_names : list , case_sensitive_resources : list = []) -> list : \"\"\" Identify mentions of resources from a body of text, by text matching. Args: text (str): The full text to search. resource_names (list): List of resource name lists (each list contains aliases for a resource). case_sensitive_resources (list): List of resource names that should be matched case-sensitively. Returns: List of tuples `(sentence, matched_alias, resource_name)`. \"\"\" mentions = [] # precompile regex patterns for each resource alias # This is more efficient than compiling them on-the-fly in the loop compiled_patterns = [] for resource in resource_names : resource_name = resource [ 0 ] for alias in resource : if resource_name in case_sensitive_resources : alias_norm = _normalize_alias_for_regex ( alias ) pattern_case_sensitive = re . compile ( rf \"(?<![A-Za-z]) { alias_norm } (?![A-Za-z])\" ) compiled_patterns . append (( resource_name , alias , pattern_case_sensitive , True )) else : # Use case-insensitive pattern for all other resources alias_norm = _normalize_alias_for_regex ( alias . lower ()) pattern_case_insensitive = re . compile ( rf \"(?<![A-Za-z]) { alias_norm } (?![A-Za-z])\" ) compiled_patterns . append (( resource_name , alias , pattern_case_insensitive , False )) # Tokenize the text into sentences and search for resource names sentences = sent_tokenize ( text ) # Use NLTK to split into sentences for sentence in sentences : sentence = sentence . replace ( \" \\n \" , \" \" ) s_lowered = sentence . lower () this_sentence_mentions = [] for resource_name , alias , pattern , is_case_sensitive in compiled_patterns : if not is_case_sensitive and pattern . search ( s_lowered ): this_sentence_mentions . append (( sentence . strip (), alias , resource_name )) elif is_case_sensitive and pattern . search ( sentence ): this_sentence_mentions . append (( sentence . strip (), alias , resource_name )) if len ( this_sentence_mentions ) > 1 : this_sentence_mentions = _remove_substring_matches ( this_sentence_mentions ) mentions . extend ( this_sentence_mentions ) # if a large number of matches are found for one resource, switch to case sensitive mode filtered_mentions = [] alias_counts = Counter ([ m [ 1 ] for m in mentions ]) for alias , count in alias_counts . items (): if count > case_sensitive_threshold and alias not in case_sensitive_resources : if VERBOSE : print ( f \"\u26a0\ufe0f { count } matches found for { alias } - switching to case sensitive mode\" ) pattern_case_sensitive = re . compile ( rf \"(?<![A-Za-z]) { re . escape ( alias ) } (?![A-Za-z])\" ) for m in mentions : if m [ 1 ] == alias and pattern_case_sensitive . search ( m [ 0 ]): filtered_mentions . append ( m ) else : this_alias_mentions = [ m for m in mentions if m [ 1 ] == alias ] filtered_mentions . extend ( this_alias_mentions ) # Remove duplicates mentions = list ( set ( filtered_mentions )) # Remove empty mentions mentions = [ m for m in mentions if m [ 0 ]] return mentions","title":"get_resource_mentions"},{"location":"api/gbcutils_scibert/#gbcutils.scibert_classify.load_model","text":"load_model ( model_name , num_threads = 1 ) Load the SciBERT model and tokenizer for sequence classification. Parameters: model_name ( str ) \u2013 The name/path of the pre-trained model. num_threads ( int , default: 1 ) \u2013 Number of CPU threads to use if running on CPU. Returns: tuple \u2013 (tokenizer, model, device) Source code in gbcutils/scibert_classify.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def load_model ( model_name : str , num_threads : int = 1 ) -> tuple : \"\"\" Load the SciBERT model and tokenizer for sequence classification. Args: model_name (str): The name/path of the pre-trained model. num_threads (int): Number of CPU threads to use if running on CPU. Returns: `(tokenizer, model, device)` \"\"\" if torch . cuda . is_available (): if VERBOSE : print ( \" \\t \ud83e\udde0 Using CUDA GPU for inference\" ) device = torch . device ( \"cuda\" ) elif torch . backends . mps . is_available (): if VERBOSE : print ( \" \\t \ud83e\udde0 Using Apple MPS GPU for inference\" ) device = torch . device ( \"mps\" ) else : if VERBOSE : print ( \" \\t \ud83e\udde0 Using CPU for inference\" ) device = torch . device ( \"cpu\" ) torch . set_num_threads ( num_threads ) tokenizer = AutoTokenizer . from_pretrained ( model_name ) model = AutoModelForSequenceClassification . from_pretrained ( model_name ) . to ( device ) model . eval () return ( tokenizer , model , device )","title":"load_model"},{"location":"api/globalbiodata_accession/","text":"globalbiodata.accession Accession dataclass Class representing an Accession - denoting a data citation of a Resource in a Publication, with associated metadata. Attributes: accession ( str ) \u2013 Accession ID resource ( Resource ) \u2013 Resource object publications ( list [ Publication ] ) \u2013 Publication object(s) version ( Version ) \u2013 Version object url ( str ) \u2013 URL string additional_metadata ( str ) \u2013 Additional version metadata in JSON format Source code in globalbiodata/accession.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @dataclass class Accession : \"\"\" Class representing an Accession - denoting a data citation of a Resource in a Publication, with associated metadata. Attributes: accession (str): Accession ID resource (Resource): Resource object publications (list[Publication]): Publication object(s) version (Version): Version object url (str): URL string additional_metadata (str): Additional version metadata in JSON format \"\"\" accession : str resource : Resource publications : list [ Publication ] version : Version url : str additional_metadata : str def __init__ ( self , a ): self . accession = a . get ( 'accession' ) self . resource = a . get ( 'resource' ) or Resource ( extract_fields_by_type ( a , 'resource' )) self . publications = a . get ( 'publications' ) or [ Publication ( extract_fields_by_type ( a , 'publication' ))] self . version = a . get ( 'version' ) or Version ( extract_fields_by_type ( a , 'version' )) self . url = a . get ( 'url' ) self . additional_metadata = a . get ( 'additional_metadata' ) def __str__ ( self ): accession_str = ', ' . join ([ f \"accession= { self . accession } \" , f \"resource= { self . resource . __str__ () } \" , f \"version= { self . version . __str__ () } \" , f \"additional_metadata= { self . additional_metadata } \" , f \"publications=[ { ', ' . join ([ p . __str__ () for p in self . publications ]) } ]\" if self . publications else \"publications=[]\" , f \"url= { self . url } \" , f \"additional_metadata= { self . additional_metadata } \" ]) return f \"Accession( { accession_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Accession to database along with associated Resource, Version, and Publication data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Accession written to the database. \"\"\" if not self . resource . id or force : resource_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = resource_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id accession_cols = { 'accession' : self . accession , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'url' : self . url , 'additional_metadata' : self . additional_metadata } insert_into_table ( 'accession' , accession_cols , conn = conn , engine = engine , debug = debug ) if self . publications : for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'accession_publication' , { 'accession' : self . accession , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Accession from database along with associated links to publications. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . accession : raise ValueError ( \"Accession object must have an accession field to perform delete.\" ) delete_from_table ( 'accession_publication' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'accession' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) def fetch_by_accession ( accession : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Accession : \"\"\"Fetch Accession from database by accession ID. Args: accession (str): Accession ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Accession object. \"\"\" return fetch_accession ({ 'accession' : accession }, conn = conn , engine = engine , debug = debug ) def fetch_by_resource ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Resource ID. Args: resource_id (int): Resource ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_publication ( self , publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Publication ID. Args: publication_id (int): Publication ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug ) delete delete ( conn = None , engine = None , debug = False ) Delete Accession from database along with associated links to publications. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/accession.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Accession from database along with associated links to publications. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . accession : raise ValueError ( \"Accession object must have an accession field to perform delete.\" ) delete_from_table ( 'accession_publication' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'accession' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) fetch_by_accession fetch_by_accession ( accession , conn = None , engine = None , debug = False ) Fetch Accession from database by accession ID. Parameters: accession ( str ) \u2013 Accession ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Accession \u2013 The Accession object. Source code in globalbiodata/accession.py 107 108 109 110 111 112 113 114 115 116 117 118 119 def fetch_by_accession ( accession : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Accession : \"\"\"Fetch Accession from database by accession ID. Args: accession (str): Accession ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Accession object. \"\"\" return fetch_accession ({ 'accession' : accession }, conn = conn , engine = engine , debug = debug ) fetch_by_publication fetch_by_publication ( publication_id , conn = None , engine = None , debug = False ) Fetch Accession from database by Publication ID. Parameters: publication_id ( int ) \u2013 Publication ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of Accession objects. Source code in globalbiodata/accession.py 135 136 137 138 139 140 141 142 143 144 145 146 147 def fetch_by_publication ( self , publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Publication ID. Args: publication_id (int): Publication ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug ) fetch_by_resource fetch_by_resource ( resource_id , conn = None , engine = None , debug = False ) Fetch Accession from database by Resource ID. Parameters: resource_id ( int ) \u2013 Resource ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of Accession objects. Source code in globalbiodata/accession.py 121 122 123 124 125 126 127 128 129 130 131 132 133 def fetch_by_resource ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Resource ID. Args: resource_id (int): Resource ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False , force = False ) Write Accession to database along with associated Resource, Version, and Publication data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Accession written to the database. Source code in globalbiodata/accession.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Accession to database along with associated Resource, Version, and Publication data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Accession written to the database. \"\"\" if not self . resource . id or force : resource_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = resource_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id accession_cols = { 'accession' : self . accession , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'url' : self . url , 'additional_metadata' : self . additional_metadata } insert_into_table ( 'accession' , accession_cols , conn = conn , engine = engine , debug = debug ) if self . publications : for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'accession_publication' , { 'accession' : self . accession , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug )","title":"Accession"},{"location":"api/globalbiodata_accession/#globalbiodata.accession","text":"","title":"accession"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession","text":"Class representing an Accession - denoting a data citation of a Resource in a Publication, with associated metadata. Attributes: accession ( str ) \u2013 Accession ID resource ( Resource ) \u2013 Resource object publications ( list [ Publication ] ) \u2013 Publication object(s) version ( Version ) \u2013 Version object url ( str ) \u2013 URL string additional_metadata ( str ) \u2013 Additional version metadata in JSON format Source code in globalbiodata/accession.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @dataclass class Accession : \"\"\" Class representing an Accession - denoting a data citation of a Resource in a Publication, with associated metadata. Attributes: accession (str): Accession ID resource (Resource): Resource object publications (list[Publication]): Publication object(s) version (Version): Version object url (str): URL string additional_metadata (str): Additional version metadata in JSON format \"\"\" accession : str resource : Resource publications : list [ Publication ] version : Version url : str additional_metadata : str def __init__ ( self , a ): self . accession = a . get ( 'accession' ) self . resource = a . get ( 'resource' ) or Resource ( extract_fields_by_type ( a , 'resource' )) self . publications = a . get ( 'publications' ) or [ Publication ( extract_fields_by_type ( a , 'publication' ))] self . version = a . get ( 'version' ) or Version ( extract_fields_by_type ( a , 'version' )) self . url = a . get ( 'url' ) self . additional_metadata = a . get ( 'additional_metadata' ) def __str__ ( self ): accession_str = ', ' . join ([ f \"accession= { self . accession } \" , f \"resource= { self . resource . __str__ () } \" , f \"version= { self . version . __str__ () } \" , f \"additional_metadata= { self . additional_metadata } \" , f \"publications=[ { ', ' . join ([ p . __str__ () for p in self . publications ]) } ]\" if self . publications else \"publications=[]\" , f \"url= { self . url } \" , f \"additional_metadata= { self . additional_metadata } \" ]) return f \"Accession( { accession_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Accession to database along with associated Resource, Version, and Publication data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Accession written to the database. \"\"\" if not self . resource . id or force : resource_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = resource_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id accession_cols = { 'accession' : self . accession , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'url' : self . url , 'additional_metadata' : self . additional_metadata } insert_into_table ( 'accession' , accession_cols , conn = conn , engine = engine , debug = debug ) if self . publications : for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'accession_publication' , { 'accession' : self . accession , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Accession from database along with associated links to publications. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . accession : raise ValueError ( \"Accession object must have an accession field to perform delete.\" ) delete_from_table ( 'accession_publication' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'accession' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) def fetch_by_accession ( accession : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Accession : \"\"\"Fetch Accession from database by accession ID. Args: accession (str): Accession ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Accession object. \"\"\" return fetch_accession ({ 'accession' : accession }, conn = conn , engine = engine , debug = debug ) def fetch_by_resource ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Resource ID. Args: resource_id (int): Resource ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_publication ( self , publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Publication ID. Args: publication_id (int): Publication ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug )","title":"Accession"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete Accession from database along with associated links to publications. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/accession.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Accession from database along with associated links to publications. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . accession : raise ValueError ( \"Accession object must have an accession field to perform delete.\" ) delete_from_table ( 'accession_publication' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'accession' , { 'accession' : self . accession }, conn = conn , engine = engine , debug = debug )","title":"delete"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession.fetch_by_accession","text":"fetch_by_accession ( accession , conn = None , engine = None , debug = False ) Fetch Accession from database by accession ID. Parameters: accession ( str ) \u2013 Accession ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Accession \u2013 The Accession object. Source code in globalbiodata/accession.py 107 108 109 110 111 112 113 114 115 116 117 118 119 def fetch_by_accession ( accession : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Accession : \"\"\"Fetch Accession from database by accession ID. Args: accession (str): Accession ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Accession object. \"\"\" return fetch_accession ({ 'accession' : accession }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_accession"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession.fetch_by_publication","text":"fetch_by_publication ( publication_id , conn = None , engine = None , debug = False ) Fetch Accession from database by Publication ID. Parameters: publication_id ( int ) \u2013 Publication ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of Accession objects. Source code in globalbiodata/accession.py 135 136 137 138 139 140 141 142 143 144 145 146 147 def fetch_by_publication ( self , publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Publication ID. Args: publication_id (int): Publication ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_publication"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession.fetch_by_resource","text":"fetch_by_resource ( resource_id , conn = None , engine = None , debug = False ) Fetch Accession from database by Resource ID. Parameters: resource_id ( int ) \u2013 Resource ID of the Accession to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of Accession objects. Source code in globalbiodata/accession.py 121 122 123 124 125 126 127 128 129 130 131 132 133 def fetch_by_resource ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Accession from database by Resource ID. Args: resource_id (int): Resource ID of the Accession to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_resource"},{"location":"api/globalbiodata_accession/#globalbiodata.accession.Accession.write","text":"write ( conn = None , engine = None , debug = False , force = False ) Write Accession to database along with associated Resource, Version, and Publication data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Accession written to the database. Source code in globalbiodata/accession.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Accession to database along with associated Resource, Version, and Publication data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Accession written to the database. \"\"\" if not self . resource . id or force : resource_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = resource_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id accession_cols = { 'accession' : self . accession , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'url' : self . url , 'additional_metadata' : self . additional_metadata } insert_into_table ( 'accession' , accession_cols , conn = conn , engine = engine , debug = debug ) if self . publications : for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'accession_publication' , { 'accession' : self . accession , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug )","title":"write"},{"location":"api/globalbiodata_grant/","text":"globalbiodata.grant Grant dataclass Class representing a Grant with associated metadata and linked GrantAgency. Attributes: id ( int ) \u2013 Database ID for Grant ext_grant_id ( str ) \u2013 External grant ID grant_agency ( GrantAgency ) \u2013 GrantAgency object Source code in globalbiodata/grant.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @dataclass class Grant : \"\"\" Class representing a Grant with associated metadata and linked GrantAgency. Attributes: id (int): Database ID for Grant ext_grant_id (str): External grant ID grant_agency (GrantAgency): GrantAgency object \"\"\" id : int ext_grant_id : str grant_agency : GrantAgency def __init__ ( self , g ): self . id = g . get ( 'id' ) self . ext_grant_id = g . get ( 'ext_grant_id' ) if type ( g . get ( 'grant_agency' )) is str : self . grant_agency = GrantAgency ({ 'name' : g . get ( 'grant_agency' )}) elif type ( g . get ( 'grant_agency' )) is GrantAgency : self . grant_agency = g . get ( 'grant_agency' ) else : raise ValueError ( f \"Grant Agency must be a string or GrantAgency object. Got: { g . get ( 'grant_agency' ) } (type: { type ( g . get ( 'grant_agency' )) } ).\" ) def __str__ ( self ): grant_str = f \"Grant(id= { self . id } , ext_grant_id= { self . ext_grant_id } , grant_agency= { self . grant_agency . __str__ () } )\" return grant_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Grant to database along with associated GrantAgency data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Grant written to the database. \"\"\" if not self . grant_agency . id or force : new_ga_id = self . grant_agency . write ( conn = conn , engine = engine , debug = debug ) self . grant_agency . id = new_ga_id g_cols = { 'id' : self . id , 'ext_grant_id' : self . ext_grant_id , 'grant_agency_id' : self . grant_agency . id } new_g_id = insert_into_table ( 'grant' , g_cols , conn = conn , engine = engine , debug = debug ) self . id = new_g_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Grant from database along with associated links to resources. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Grant object must have an ID to delete.\" ) delete_from_table ( 'resource_grant' , { 'grant_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'grant' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_ext_id ( ext_id : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Grant : \"\"\"Fetch Grant from database by external ID. Args: ext_id (str): External ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Grant object. \"\"\" return fetch_grant ({ 'ext_grant_id' : ext_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_grant_agency_id ( grant_agency_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Grant from database by GrantAgency ID. Args: grant_agency_id (int): GrantAgency ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Grant objects. \"\"\" return fetch_grant ({ 'grant_agency_id' : grant_agency_id }, conn = conn , engine = engine , debug = debug ) delete delete ( conn = None , engine = None , debug = False ) Delete Grant from database along with associated links to resources. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/grant.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Grant from database along with associated links to resources. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Grant object must have an ID to delete.\" ) delete_from_table ( 'resource_grant' , { 'grant_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'grant' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_ext_id fetch_by_ext_id ( ext_id , conn = None , engine = None , debug = False ) Fetch Grant from database by external ID. Parameters: ext_id ( str ) \u2013 External ID of the Grant to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Grant \u2013 The Grant object. Source code in globalbiodata/grant.py 81 82 83 84 85 86 87 88 89 90 91 92 93 def fetch_by_ext_id ( ext_id : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Grant : \"\"\"Fetch Grant from database by external ID. Args: ext_id (str): External ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Grant object. \"\"\" return fetch_grant ({ 'ext_grant_id' : ext_id }, conn = conn , engine = engine , debug = debug ) fetch_by_grant_agency_id fetch_by_grant_agency_id ( grant_agency_id , conn = None , engine = None , debug = False ) Fetch Grant from database by GrantAgency ID. Parameters: grant_agency_id ( int ) \u2013 GrantAgency ID of the Grant to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of fetched Grant objects. Source code in globalbiodata/grant.py 95 96 97 98 99 100 101 102 103 104 105 106 107 def fetch_by_grant_agency_id ( grant_agency_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Grant from database by GrantAgency ID. Args: grant_agency_id (int): GrantAgency ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Grant objects. \"\"\" return fetch_grant ({ 'grant_agency_id' : grant_agency_id }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False , force = False ) Write Grant to database along with associated GrantAgency data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Grant written to the database. Source code in globalbiodata/grant.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Grant to database along with associated GrantAgency data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Grant written to the database. \"\"\" if not self . grant_agency . id or force : new_ga_id = self . grant_agency . write ( conn = conn , engine = engine , debug = debug ) self . grant_agency . id = new_ga_id g_cols = { 'id' : self . id , 'ext_grant_id' : self . ext_grant_id , 'grant_agency_id' : self . grant_agency . id } new_g_id = insert_into_table ( 'grant' , g_cols , conn = conn , engine = engine , debug = debug ) self . id = new_g_id return self . id GrantAgency dataclass id: Database ID for GrantAgency name: Name of grant agency parent_agency: Parent agency (to show hierarchy of agencies) representative_agency: Representative agency (to show grouping of agencies) Source code in globalbiodata/grant.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 @dataclass class GrantAgency : \"\"\" id: Database ID for GrantAgency name: Name of grant agency parent_agency: Parent agency (to show hierarchy of agencies) representative_agency: Representative agency (to show grouping of agencies) \"\"\" id : int name : str country : str parent_agency : 'GrantAgency' representative_agency : 'GrantAgency' def __init__ ( self , ga ): self . id = ga . get ( 'id' ) self . name = ga . get ( 'name' ) self . country = ga . get ( 'country' ) if ga . get ( 'parent_agency' ) or ga . get ( 'parent_agency_id' ): self . parent_agency = ga . get ( 'parent_agency' ) or GrantAgency ({ 'id' : ga . get ( 'parent_agency_id' )}) else : self . parent_agency = None if ga . get ( 'representative_agency' ) or ga . get ( 'representative_agency_id' ): self . representative_agency = ga . get ( 'representative_agency' ) or GrantAgency ({ 'id' : ga . get ( 'representative_agency_id' )}) else : self . representative_agency = None def __str__ ( self ): grant_agency_str = f \"GrantAgency(id= { self . id } , name= { self . name } , country= { self . country } , \" grant_agency_str += f \"parent_agency_id= { self . parent_agency . id if self . parent_agency else '' } \" grant_agency_str += f \"representative_agency_id= { self . representative_agency . id if self . representative_agency else '' } )\" return grant_agency_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write GrantAgency to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the GrantAgency written to the database. \"\"\" writable = { 'id' : self . id , 'name' : self . name , 'country' : self . country } writable [ 'parent_agency_id' ] = self . parent_agency . id if self . parent_agency else None writable [ 'representative_agency_id' ] = self . representative_agency . id if self . representative_agency else None new_ga_id = insert_into_table ( 'grant_agency' , writable , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_ga_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete GrantAgency from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"GrantAgency object must have an ID to delete.\" ) del_result = delete_from_table ( 'grant_agency' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_name ( name : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> GrantAgency : \"\"\"Fetch GrantAgency from database by name. Args: name (str): Name of the GrantAgency to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else `None`. \"\"\" return fetch_grant_agency ({ 'name' : name }, conn = conn , engine = engine , debug = debug ) delete delete ( conn = None , engine = None , debug = False ) Delete GrantAgency from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/grant.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete GrantAgency from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"GrantAgency object must have an ID to delete.\" ) del_result = delete_from_table ( 'grant_agency' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_name fetch_by_name ( name , conn = None , engine = None , debug = False ) Fetch GrantAgency from database by name. Parameters: name ( str ) \u2013 Name of the GrantAgency to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: GrantAgency \u2013 The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else None . Source code in globalbiodata/grant.py 184 185 186 187 188 189 190 191 192 193 194 195 196 def fetch_by_name ( name : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> GrantAgency : \"\"\"Fetch GrantAgency from database by name. Args: name (str): Name of the GrantAgency to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else `None`. \"\"\" return fetch_grant_agency ({ 'name' : name }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False ) Write GrantAgency to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the GrantAgency written to the database. Source code in globalbiodata/grant.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write GrantAgency to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the GrantAgency written to the database. \"\"\" writable = { 'id' : self . id , 'name' : self . name , 'country' : self . country } writable [ 'parent_agency_id' ] = self . parent_agency . id if self . parent_agency else None writable [ 'representative_agency_id' ] = self . representative_agency . id if self . representative_agency else None new_ga_id = insert_into_table ( 'grant_agency' , writable , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_ga_id return self . id","title":"Grant & GrantAgency"},{"location":"api/globalbiodata_grant/#globalbiodata.grant","text":"","title":"grant"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.Grant","text":"Class representing a Grant with associated metadata and linked GrantAgency. Attributes: id ( int ) \u2013 Database ID for Grant ext_grant_id ( str ) \u2013 External grant ID grant_agency ( GrantAgency ) \u2013 GrantAgency object Source code in globalbiodata/grant.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @dataclass class Grant : \"\"\" Class representing a Grant with associated metadata and linked GrantAgency. Attributes: id (int): Database ID for Grant ext_grant_id (str): External grant ID grant_agency (GrantAgency): GrantAgency object \"\"\" id : int ext_grant_id : str grant_agency : GrantAgency def __init__ ( self , g ): self . id = g . get ( 'id' ) self . ext_grant_id = g . get ( 'ext_grant_id' ) if type ( g . get ( 'grant_agency' )) is str : self . grant_agency = GrantAgency ({ 'name' : g . get ( 'grant_agency' )}) elif type ( g . get ( 'grant_agency' )) is GrantAgency : self . grant_agency = g . get ( 'grant_agency' ) else : raise ValueError ( f \"Grant Agency must be a string or GrantAgency object. Got: { g . get ( 'grant_agency' ) } (type: { type ( g . get ( 'grant_agency' )) } ).\" ) def __str__ ( self ): grant_str = f \"Grant(id= { self . id } , ext_grant_id= { self . ext_grant_id } , grant_agency= { self . grant_agency . __str__ () } )\" return grant_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Grant to database along with associated GrantAgency data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Grant written to the database. \"\"\" if not self . grant_agency . id or force : new_ga_id = self . grant_agency . write ( conn = conn , engine = engine , debug = debug ) self . grant_agency . id = new_ga_id g_cols = { 'id' : self . id , 'ext_grant_id' : self . ext_grant_id , 'grant_agency_id' : self . grant_agency . id } new_g_id = insert_into_table ( 'grant' , g_cols , conn = conn , engine = engine , debug = debug ) self . id = new_g_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Grant from database along with associated links to resources. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Grant object must have an ID to delete.\" ) delete_from_table ( 'resource_grant' , { 'grant_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'grant' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_ext_id ( ext_id : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Grant : \"\"\"Fetch Grant from database by external ID. Args: ext_id (str): External ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Grant object. \"\"\" return fetch_grant ({ 'ext_grant_id' : ext_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_grant_agency_id ( grant_agency_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Grant from database by GrantAgency ID. Args: grant_agency_id (int): GrantAgency ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Grant objects. \"\"\" return fetch_grant ({ 'grant_agency_id' : grant_agency_id }, conn = conn , engine = engine , debug = debug )","title":"Grant"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.Grant.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete Grant from database along with associated links to resources. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/grant.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Grant from database along with associated links to resources. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Grant object must have an ID to delete.\" ) delete_from_table ( 'resource_grant' , { 'grant_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'grant' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.Grant.fetch_by_ext_id","text":"fetch_by_ext_id ( ext_id , conn = None , engine = None , debug = False ) Fetch Grant from database by external ID. Parameters: ext_id ( str ) \u2013 External ID of the Grant to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Grant \u2013 The Grant object. Source code in globalbiodata/grant.py 81 82 83 84 85 86 87 88 89 90 91 92 93 def fetch_by_ext_id ( ext_id : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Grant : \"\"\"Fetch Grant from database by external ID. Args: ext_id (str): External ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The Grant object. \"\"\" return fetch_grant ({ 'ext_grant_id' : ext_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_ext_id"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.Grant.fetch_by_grant_agency_id","text":"fetch_by_grant_agency_id ( grant_agency_id , conn = None , engine = None , debug = False ) Fetch Grant from database by GrantAgency ID. Parameters: grant_agency_id ( int ) \u2013 GrantAgency ID of the Grant to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of fetched Grant objects. Source code in globalbiodata/grant.py 95 96 97 98 99 100 101 102 103 104 105 106 107 def fetch_by_grant_agency_id ( grant_agency_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch Grant from database by GrantAgency ID. Args: grant_agency_id (int): GrantAgency ID of the Grant to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Grant objects. \"\"\" return fetch_grant ({ 'grant_agency_id' : grant_agency_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_grant_agency_id"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.Grant.write","text":"write ( conn = None , engine = None , debug = False , force = False ) Write Grant to database along with associated GrantAgency data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Grant written to the database. Source code in globalbiodata/grant.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Grant to database along with associated GrantAgency data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the Grant written to the database. \"\"\" if not self . grant_agency . id or force : new_ga_id = self . grant_agency . write ( conn = conn , engine = engine , debug = debug ) self . grant_agency . id = new_ga_id g_cols = { 'id' : self . id , 'ext_grant_id' : self . ext_grant_id , 'grant_agency_id' : self . grant_agency . id } new_g_id = insert_into_table ( 'grant' , g_cols , conn = conn , engine = engine , debug = debug ) self . id = new_g_id return self . id","title":"write"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.GrantAgency","text":"id: Database ID for GrantAgency name: Name of grant agency parent_agency: Parent agency (to show hierarchy of agencies) representative_agency: Representative agency (to show grouping of agencies) Source code in globalbiodata/grant.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 @dataclass class GrantAgency : \"\"\" id: Database ID for GrantAgency name: Name of grant agency parent_agency: Parent agency (to show hierarchy of agencies) representative_agency: Representative agency (to show grouping of agencies) \"\"\" id : int name : str country : str parent_agency : 'GrantAgency' representative_agency : 'GrantAgency' def __init__ ( self , ga ): self . id = ga . get ( 'id' ) self . name = ga . get ( 'name' ) self . country = ga . get ( 'country' ) if ga . get ( 'parent_agency' ) or ga . get ( 'parent_agency_id' ): self . parent_agency = ga . get ( 'parent_agency' ) or GrantAgency ({ 'id' : ga . get ( 'parent_agency_id' )}) else : self . parent_agency = None if ga . get ( 'representative_agency' ) or ga . get ( 'representative_agency_id' ): self . representative_agency = ga . get ( 'representative_agency' ) or GrantAgency ({ 'id' : ga . get ( 'representative_agency_id' )}) else : self . representative_agency = None def __str__ ( self ): grant_agency_str = f \"GrantAgency(id= { self . id } , name= { self . name } , country= { self . country } , \" grant_agency_str += f \"parent_agency_id= { self . parent_agency . id if self . parent_agency else '' } \" grant_agency_str += f \"representative_agency_id= { self . representative_agency . id if self . representative_agency else '' } )\" return grant_agency_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write GrantAgency to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the GrantAgency written to the database. \"\"\" writable = { 'id' : self . id , 'name' : self . name , 'country' : self . country } writable [ 'parent_agency_id' ] = self . parent_agency . id if self . parent_agency else None writable [ 'representative_agency_id' ] = self . representative_agency . id if self . representative_agency else None new_ga_id = insert_into_table ( 'grant_agency' , writable , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_ga_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete GrantAgency from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"GrantAgency object must have an ID to delete.\" ) del_result = delete_from_table ( 'grant_agency' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_name ( name : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> GrantAgency : \"\"\"Fetch GrantAgency from database by name. Args: name (str): Name of the GrantAgency to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else `None`. \"\"\" return fetch_grant_agency ({ 'name' : name }, conn = conn , engine = engine , debug = debug )","title":"GrantAgency"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.GrantAgency.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete GrantAgency from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/grant.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete GrantAgency from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"GrantAgency object must have an ID to delete.\" ) del_result = delete_from_table ( 'grant_agency' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.GrantAgency.fetch_by_name","text":"fetch_by_name ( name , conn = None , engine = None , debug = False ) Fetch GrantAgency from database by name. Parameters: name ( str ) \u2013 Name of the GrantAgency to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: GrantAgency \u2013 The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else None . Source code in globalbiodata/grant.py 184 185 186 187 188 189 190 191 192 193 194 195 196 def fetch_by_name ( name : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> GrantAgency : \"\"\"Fetch GrantAgency from database by name. Args: name (str): Name of the GrantAgency to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of GrantAgency objects if more than one is found, else a single GrantAgency object, else `None`. \"\"\" return fetch_grant_agency ({ 'name' : name }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_name"},{"location":"api/globalbiodata_grant/#globalbiodata.grant.GrantAgency.write","text":"write ( conn = None , engine = None , debug = False ) Write GrantAgency to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the GrantAgency written to the database. Source code in globalbiodata/grant.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write GrantAgency to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the GrantAgency written to the database. \"\"\" writable = { 'id' : self . id , 'name' : self . name , 'country' : self . country } writable [ 'parent_agency_id' ] = self . parent_agency . id if self . parent_agency else None writable [ 'representative_agency_id' ] = self . representative_agency . id if self . representative_agency else None new_ga_id = insert_into_table ( 'grant_agency' , writable , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_ga_id return self . id","title":"write"},{"location":"api/globalbiodata_publication/","text":"globalbiodata.publication Publication dataclass Class representing a Publication with associated metadata and linked Grants. Attributes: id ( int ) \u2013 Database ID for Publication title ( str ) \u2013 Title of publication pubmed_id ( int ) \u2013 PubMed ID pmc_id ( str ) \u2013 PubMed Central ID publication_date ( date ) \u2013 Date of publication authors ( str ) \u2013 Authors of publication (; separated) affiliation ( str ) \u2013 Affiliation of authors (; separated) affiliation_countries ( str ) \u2013 Countries of affiliation (; separated) citation_count ( int ) \u2013 Number of citations grants ( list [ Grant ] ) \u2013 Associated Grant objects keywords ( str ) \u2013 Keywords/Mesh terms (; separated) Source code in globalbiodata/publication.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 @dataclass class Publication : \"\"\"Class representing a Publication with associated metadata and linked Grants. Attributes: id (int): Database ID for Publication title (str): Title of publication pubmed_id (int): PubMed ID pmc_id (str): PubMed Central ID publication_date (date): Date of publication authors (str): Authors of publication (; separated) affiliation (str): Affiliation of authors (; separated) affiliation_countries (str): Countries of affiliation (; separated) citation_count (int): Number of citations grants (list[Grant]): Associated Grant objects keywords (str): Keywords/Mesh terms (; separated) \"\"\" id : int title : str pubmed_id : int pmc_id : str publication_date : date authors : str affiliation : str affiliation_countries : str grants : list [ Grant ] citation_count : int keywords : str __conn__ : Connection __engine__ : Engine def __init__ ( self , p ): self . id = p . get ( 'id' ) self . title = p . get ( 'publication_title' ) or p . get ( 'title' ) self . pubmed_id = None if p . get ( 'pubmed_id' , '' ) == '' else p . get ( 'pubmed_id' ) self . pmc_id = None if p . get ( 'pmc_id' , '' ) == '' else p . get ( 'pmc_id' ) self . publication_date = datetime . strptime ( p . get ( 'publication_date' ), \"%Y-%m- %d \" ) . date () if p . get ( 'publication_date' ) and type ( p . get ( 'publication_date' )) is str else p . get ( 'publication_date' ) self . authors = p . get ( 'authors' ) if type ( p . get ( 'authors' )) is not list else '; ' . join ( p . get ( 'authors' )) self . affiliation = p . get ( 'affiliation' ) if type ( p . get ( 'affiliation' )) is not list else '; ' . join ( p . get ( 'affiliation' )) self . affiliation_countries = p . get ( 'affiliation_countries' ) if type ( p . get ( 'affiliation_countries' )) is not list else '; ' . join ( p . get ( 'affiliation_countries' )) self . citation_count = p . get ( 'citation_count' ) self . keywords = p . get ( 'keywords' ) if type ( p . get ( 'keywords' )) is not list else '; ' . join ( p . get ( 'keywords' )) self . __conn__ = p . get ( '__conn__' ) self . __engine__ = p . get ( '__engine__' ) if p . get ( 'grants' ): self . grants = [ Grant ( p )] if type ( p . get ( 'grants' )[ 0 ]) is str else p . get ( 'grants' ) elif p . get ( 'ext_grant_ids' ) and p . get ( 'grant_agencies' ): self . grants = [ Grant ({ 'ext_grant_id' : g , 'grant_agency' : ga }) for g , ga in zip ([ e . strip () for e in p . get ( 'ext_grant_ids' ) . split ( ',' )], [ e . strip () for e in p . get ( 'grant_agencies' ) . split ( ',' )])] else : self . grants = None def __str__ ( self ): pub_str = ', ' . join ([ f \"id= { self . id } \" , f \"title= { self . title } \" , f \"pubmed_id= { self . pubmed_id } \" , f \"pmc_id= { self . pmc_id } \" , f \"publication_date= { self . publication_date } \" , f \"authors= { self . authors } \" , f \"affiliation= { self . affiliation } \" , f \"affiliation_countries= { self . affiliation_countries } \" , f \"citation_count= { self . citation_count } \" , f \"keywords= { self . keywords } \" , f \"grants=[ { ', ' . join ( g . __str__ () for g in self . grants ) } ]\" if self . grants else \"grants=[]\" ]) return f \"Publication( { pub_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Publication to database along with associated Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. force (bool, optional): If True, force writing of associated objects even if they have IDs. Returns: The ID of the Publication written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ self_dict = self . __dict__ . copy () pub_grants = self_dict . pop ( 'grants' ) if not self . title or not self . authors or self . citation_count is None : raise ValueError ( \"Publication must have a title, authors, and citation count to write to the database.\" ) new_pub_id = insert_into_table ( 'publication' , self_dict , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_pub_id if pub_grants : # delete_from_table('publication_grant', {'publication_id':new_pub_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in pub_grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between publication and grant tables insert_into_table ( 'publication_grant' , { 'publication_id' : new_pub_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Publication from database along with associated links to grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Publication object must have an ID to delete.\" ) del_result = delete_from_table ( 'publication' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by ID. Args: id (int): ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'id' : id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_pubmed_id ( pubmed_id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed ID. Args: pubmed_id (int): PubMed ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pubmed_id' : pubmed_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_pmc_id ( pmc_id : str , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed Central ID. Args: pmc_id (str): PubMed Central ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pmc_id' : pmc_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Publication. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Publication. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def references_resources ( self ) -> list [ Resource ]: \"\"\"Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: List of Resource objects. \"\"\" resources = {} accessions = self . accessions () for acc in accessions : resources [ acc . resource . id ] = acc . resource mentions = self . mentions () for mention in mentions : resources [ mention . resource . id ] = mention . resource # print(f\"[SET] resources: {', '.join([str(r.id) for r in resources.values()])}\") # print(f\"[LIST] resources: {','.join([str(r.id) for r in list(resources.values())])}\") return list ( resources . values ()) def from_EuropePMC_search ( result : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None ) -> Publication : \"\"\"Create Publication object from EuropePMC search API result dictionary. Args: result (dict): EuropePMC search API result dictionary. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. Returns: The Publication object. \"\"\" return new_publication_from_EuropePMC_result ( result , conn = conn , engine = engine ) accessions accessions () Return list of Accession objects associated with this Publication. Returns: list [ Accession ] \u2013 List of Accession objects. Source code in globalbiodata/publication.py 184 185 186 187 188 189 190 def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Publication. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) delete delete ( conn = None , engine = None , debug = False ) Delete Publication from database along with associated links to grants. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/publication.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Publication from database along with associated links to grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Publication object must have an ID to delete.\" ) del_result = delete_from_table ( 'publication' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_id fetch_by_id ( id , expanded = False , conn = None , engine = None , debug = False ) Fetch Publication from database by ID. Parameters: id ( int ) \u2013 ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 142 143 144 145 146 147 148 149 150 151 152 153 154 def fetch_by_id ( id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by ID. Args: id (int): ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'id' : id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_by_pmc_id fetch_by_pmc_id ( pmc_id , expanded = False , conn = None , engine = None , debug = False , ) Fetch Publication from database by PubMed Central ID. Parameters: pmc_id ( str ) \u2013 PubMed Central ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 170 171 172 173 174 175 176 177 178 179 180 181 182 def fetch_by_pmc_id ( pmc_id : str , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed Central ID. Args: pmc_id (str): PubMed Central ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pmc_id' : pmc_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_by_pubmed_id fetch_by_pubmed_id ( pubmed_id , expanded = False , conn = None , engine = None , debug = False , ) Fetch Publication from database by PubMed ID. Parameters: pubmed_id ( int ) \u2013 PubMed ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 156 157 158 159 160 161 162 163 164 165 166 167 168 def fetch_by_pubmed_id ( pubmed_id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed ID. Args: pubmed_id (int): PubMed ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pubmed_id' : pubmed_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) from_EuropePMC_search from_EuropePMC_search ( result , conn = None , engine = None ) Create Publication object from EuropePMC search API result dictionary. Parameters: result ( dict ) \u2013 EuropePMC search API result dictionary. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 219 220 221 222 223 224 225 226 227 228 229 230 def from_EuropePMC_search ( result : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None ) -> Publication : \"\"\"Create Publication object from EuropePMC search API result dictionary. Args: result (dict): EuropePMC search API result dictionary. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. Returns: The Publication object. \"\"\" return new_publication_from_EuropePMC_result ( result , conn = conn , engine = engine ) mentions mentions () Return list of ResourceMention objects that mention this Publication. Returns: list [ ResourceMention ] \u2013 List of ResourceMention objects. Source code in globalbiodata/publication.py 192 193 194 195 196 197 198 def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Publication. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) references_resources references_resources () Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: list [ Resource ] \u2013 List of Resource objects. Source code in globalbiodata/publication.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def references_resources ( self ) -> list [ Resource ]: \"\"\"Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: List of Resource objects. \"\"\" resources = {} accessions = self . accessions () for acc in accessions : resources [ acc . resource . id ] = acc . resource mentions = self . mentions () for mention in mentions : resources [ mention . resource . id ] = mention . resource # print(f\"[SET] resources: {', '.join([str(r.id) for r in resources.values()])}\") # print(f\"[LIST] resources: {','.join([str(r.id) for r in list(resources.values())])}\") return list ( resources . values ()) write write ( conn = None , engine = None , debug = False , force = False ) Write Publication to database along with associated Grant data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. force ( bool , default: False ) \u2013 If True, force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Publication written to the database. Source code in globalbiodata/publication.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Publication to database along with associated Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. force (bool, optional): If True, force writing of associated objects even if they have IDs. Returns: The ID of the Publication written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ self_dict = self . __dict__ . copy () pub_grants = self_dict . pop ( 'grants' ) if not self . title or not self . authors or self . citation_count is None : raise ValueError ( \"Publication must have a title, authors, and citation count to write to the database.\" ) new_pub_id = insert_into_table ( 'publication' , self_dict , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_pub_id if pub_grants : # delete_from_table('publication_grant', {'publication_id':new_pub_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in pub_grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between publication and grant tables insert_into_table ( 'publication_grant' , { 'publication_id' : new_pub_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id","title":"Publication"},{"location":"api/globalbiodata_publication/#globalbiodata.publication","text":"","title":"publication"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication","text":"Class representing a Publication with associated metadata and linked Grants. Attributes: id ( int ) \u2013 Database ID for Publication title ( str ) \u2013 Title of publication pubmed_id ( int ) \u2013 PubMed ID pmc_id ( str ) \u2013 PubMed Central ID publication_date ( date ) \u2013 Date of publication authors ( str ) \u2013 Authors of publication (; separated) affiliation ( str ) \u2013 Affiliation of authors (; separated) affiliation_countries ( str ) \u2013 Countries of affiliation (; separated) citation_count ( int ) \u2013 Number of citations grants ( list [ Grant ] ) \u2013 Associated Grant objects keywords ( str ) \u2013 Keywords/Mesh terms (; separated) Source code in globalbiodata/publication.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 @dataclass class Publication : \"\"\"Class representing a Publication with associated metadata and linked Grants. Attributes: id (int): Database ID for Publication title (str): Title of publication pubmed_id (int): PubMed ID pmc_id (str): PubMed Central ID publication_date (date): Date of publication authors (str): Authors of publication (; separated) affiliation (str): Affiliation of authors (; separated) affiliation_countries (str): Countries of affiliation (; separated) citation_count (int): Number of citations grants (list[Grant]): Associated Grant objects keywords (str): Keywords/Mesh terms (; separated) \"\"\" id : int title : str pubmed_id : int pmc_id : str publication_date : date authors : str affiliation : str affiliation_countries : str grants : list [ Grant ] citation_count : int keywords : str __conn__ : Connection __engine__ : Engine def __init__ ( self , p ): self . id = p . get ( 'id' ) self . title = p . get ( 'publication_title' ) or p . get ( 'title' ) self . pubmed_id = None if p . get ( 'pubmed_id' , '' ) == '' else p . get ( 'pubmed_id' ) self . pmc_id = None if p . get ( 'pmc_id' , '' ) == '' else p . get ( 'pmc_id' ) self . publication_date = datetime . strptime ( p . get ( 'publication_date' ), \"%Y-%m- %d \" ) . date () if p . get ( 'publication_date' ) and type ( p . get ( 'publication_date' )) is str else p . get ( 'publication_date' ) self . authors = p . get ( 'authors' ) if type ( p . get ( 'authors' )) is not list else '; ' . join ( p . get ( 'authors' )) self . affiliation = p . get ( 'affiliation' ) if type ( p . get ( 'affiliation' )) is not list else '; ' . join ( p . get ( 'affiliation' )) self . affiliation_countries = p . get ( 'affiliation_countries' ) if type ( p . get ( 'affiliation_countries' )) is not list else '; ' . join ( p . get ( 'affiliation_countries' )) self . citation_count = p . get ( 'citation_count' ) self . keywords = p . get ( 'keywords' ) if type ( p . get ( 'keywords' )) is not list else '; ' . join ( p . get ( 'keywords' )) self . __conn__ = p . get ( '__conn__' ) self . __engine__ = p . get ( '__engine__' ) if p . get ( 'grants' ): self . grants = [ Grant ( p )] if type ( p . get ( 'grants' )[ 0 ]) is str else p . get ( 'grants' ) elif p . get ( 'ext_grant_ids' ) and p . get ( 'grant_agencies' ): self . grants = [ Grant ({ 'ext_grant_id' : g , 'grant_agency' : ga }) for g , ga in zip ([ e . strip () for e in p . get ( 'ext_grant_ids' ) . split ( ',' )], [ e . strip () for e in p . get ( 'grant_agencies' ) . split ( ',' )])] else : self . grants = None def __str__ ( self ): pub_str = ', ' . join ([ f \"id= { self . id } \" , f \"title= { self . title } \" , f \"pubmed_id= { self . pubmed_id } \" , f \"pmc_id= { self . pmc_id } \" , f \"publication_date= { self . publication_date } \" , f \"authors= { self . authors } \" , f \"affiliation= { self . affiliation } \" , f \"affiliation_countries= { self . affiliation_countries } \" , f \"citation_count= { self . citation_count } \" , f \"keywords= { self . keywords } \" , f \"grants=[ { ', ' . join ( g . __str__ () for g in self . grants ) } ]\" if self . grants else \"grants=[]\" ]) return f \"Publication( { pub_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Publication to database along with associated Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. force (bool, optional): If True, force writing of associated objects even if they have IDs. Returns: The ID of the Publication written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ self_dict = self . __dict__ . copy () pub_grants = self_dict . pop ( 'grants' ) if not self . title or not self . authors or self . citation_count is None : raise ValueError ( \"Publication must have a title, authors, and citation count to write to the database.\" ) new_pub_id = insert_into_table ( 'publication' , self_dict , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_pub_id if pub_grants : # delete_from_table('publication_grant', {'publication_id':new_pub_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in pub_grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between publication and grant tables insert_into_table ( 'publication_grant' , { 'publication_id' : new_pub_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Publication from database along with associated links to grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Publication object must have an ID to delete.\" ) del_result = delete_from_table ( 'publication' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by ID. Args: id (int): ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'id' : id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_pubmed_id ( pubmed_id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed ID. Args: pubmed_id (int): PubMed ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pubmed_id' : pubmed_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_pmc_id ( pmc_id : str , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed Central ID. Args: pmc_id (str): PubMed Central ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pmc_id' : pmc_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Publication. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Publication. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def references_resources ( self ) -> list [ Resource ]: \"\"\"Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: List of Resource objects. \"\"\" resources = {} accessions = self . accessions () for acc in accessions : resources [ acc . resource . id ] = acc . resource mentions = self . mentions () for mention in mentions : resources [ mention . resource . id ] = mention . resource # print(f\"[SET] resources: {', '.join([str(r.id) for r in resources.values()])}\") # print(f\"[LIST] resources: {','.join([str(r.id) for r in list(resources.values())])}\") return list ( resources . values ()) def from_EuropePMC_search ( result : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None ) -> Publication : \"\"\"Create Publication object from EuropePMC search API result dictionary. Args: result (dict): EuropePMC search API result dictionary. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. Returns: The Publication object. \"\"\" return new_publication_from_EuropePMC_result ( result , conn = conn , engine = engine )","title":"Publication"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.accessions","text":"accessions () Return list of Accession objects associated with this Publication. Returns: list [ Accession ] \u2013 List of Accession objects. Source code in globalbiodata/publication.py 184 185 186 187 188 189 190 def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Publication. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False )","title":"accessions"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete Publication from database along with associated links to grants. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/publication.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Publication from database along with associated links to grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Publication object must have an ID to delete.\" ) del_result = delete_from_table ( 'publication' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.fetch_by_id","text":"fetch_by_id ( id , expanded = False , conn = None , engine = None , debug = False ) Fetch Publication from database by ID. Parameters: id ( int ) \u2013 ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 142 143 144 145 146 147 148 149 150 151 152 153 154 def fetch_by_id ( id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by ID. Args: id (int): ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'id' : id }, expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_by_id"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.fetch_by_pmc_id","text":"fetch_by_pmc_id ( pmc_id , expanded = False , conn = None , engine = None , debug = False , ) Fetch Publication from database by PubMed Central ID. Parameters: pmc_id ( str ) \u2013 PubMed Central ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 170 171 172 173 174 175 176 177 178 179 180 181 182 def fetch_by_pmc_id ( pmc_id : str , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed Central ID. Args: pmc_id (str): PubMed Central ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pmc_id' : pmc_id }, expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_by_pmc_id"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.fetch_by_pubmed_id","text":"fetch_by_pubmed_id ( pubmed_id , expanded = False , conn = None , engine = None , debug = False , ) Fetch Publication from database by PubMed ID. Parameters: pubmed_id ( int ) \u2013 PubMed ID of the Publication to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 156 157 158 159 160 161 162 163 164 165 166 167 168 def fetch_by_pubmed_id ( pubmed_id : int , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Publication : \"\"\"Fetch Publication from database by PubMed ID. Args: pubmed_id (int): PubMed ID of the Publication to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. Returns: The Publication object. \"\"\" return fetch_publication ({ 'pubmed_id' : pubmed_id }, expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_by_pubmed_id"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.from_EuropePMC_search","text":"from_EuropePMC_search ( result , conn = None , engine = None ) Create Publication object from EuropePMC search API result dictionary. Parameters: result ( dict ) \u2013 EuropePMC search API result dictionary. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. Returns: Publication \u2013 The Publication object. Source code in globalbiodata/publication.py 219 220 221 222 223 224 225 226 227 228 229 230 def from_EuropePMC_search ( result : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None ) -> Publication : \"\"\"Create Publication object from EuropePMC search API result dictionary. Args: result (dict): EuropePMC search API result dictionary. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. Returns: The Publication object. \"\"\" return new_publication_from_EuropePMC_result ( result , conn = conn , engine = engine )","title":"from_EuropePMC_search"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.mentions","text":"mentions () Return list of ResourceMention objects that mention this Publication. Returns: list [ ResourceMention ] \u2013 List of ResourceMention objects. Source code in globalbiodata/publication.py 192 193 194 195 196 197 198 def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Publication. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False )","title":"mentions"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.references_resources","text":"references_resources () Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: list [ Resource ] \u2013 List of Resource objects. Source code in globalbiodata/publication.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def references_resources ( self ) -> list [ Resource ]: \"\"\"Return list of Resource objects that are referenced by this Publication either via an Accession or a ResourceMention. Returns: List of Resource objects. \"\"\" resources = {} accessions = self . accessions () for acc in accessions : resources [ acc . resource . id ] = acc . resource mentions = self . mentions () for mention in mentions : resources [ mention . resource . id ] = mention . resource # print(f\"[SET] resources: {', '.join([str(r.id) for r in resources.values()])}\") # print(f\"[LIST] resources: {','.join([str(r.id) for r in list(resources.values())])}\") return list ( resources . values ())","title":"references_resources"},{"location":"api/globalbiodata_publication/#globalbiodata.publication.Publication.write","text":"write ( conn = None , engine = None , debug = False , force = False ) Write Publication to database along with associated Grant data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True, print debug information. force ( bool , default: False ) \u2013 If True, force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the Publication written to the database. Source code in globalbiodata/publication.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Publication to database along with associated Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If True, print debug information. force (bool, optional): If True, force writing of associated objects even if they have IDs. Returns: The ID of the Publication written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ self_dict = self . __dict__ . copy () pub_grants = self_dict . pop ( 'grants' ) if not self . title or not self . authors or self . citation_count is None : raise ValueError ( \"Publication must have a title, authors, and citation count to write to the database.\" ) new_pub_id = insert_into_table ( 'publication' , self_dict , conn = conn , engine = engine , debug = debug , filter_long_data = True ) self . id = new_pub_id if pub_grants : # delete_from_table('publication_grant', {'publication_id':new_pub_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in pub_grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between publication and grant tables insert_into_table ( 'publication_grant' , { 'publication_id' : new_pub_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id","title":"write"},{"location":"api/globalbiodata_resource/","text":"globalbiodata.resource Resource dataclass Class representing a Biodata Resource. Attributes: id ( int ) \u2013 Database ID for the resource. short_name ( str ) \u2013 Short name of the resource. common_name ( str ) \u2013 Common name of the resource. full_name ( str ) \u2013 Full name of the resource. url ( URL ) \u2013 URL object. version ( Version ) \u2013 Version object. prediction_metadata ( str ) \u2013 Additional prediction metadata (JSON). publications ( list [ Publication ] ) \u2013 Associated publications. grants ( list [ Grant ] ) \u2013 Associated grants. is_gcbr ( bool ) \u2013 Core Biodata Resource status. is_latest ( bool ) \u2013 Whether this is the most current version. Source code in globalbiodata/resource.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 @dataclass class Resource : \"\"\"Class representing a Biodata Resource. Attributes: id (int): Database ID for the resource. short_name (str): Short name of the resource. common_name (str): Common name of the resource. full_name (str): Full name of the resource. url (URL): URL object. version (Version): Version object. prediction_metadata (str): Additional prediction metadata (JSON). publications (list[Publication]): Associated publications. grants (list[Grant]): Associated grants. is_gcbr (bool): Core Biodata Resource status. is_latest (bool): Whether this is the most current version. \"\"\" id : int short_name : str common_name : str full_name : str url : URL version : Version prediction_metadata : str publications : list [ Publication ] grants : list [ Grant ] is_gcbr : bool is_latest : bool __conn__ : Connection __engine__ : Engine def __init__ ( self , r ): self . id = r . get ( 'id' ) self . short_name = r . get ( 'short_name' ) self . common_name = r . get ( 'common_name' ) self . full_name = r . get ( 'full_name' ) r2 = { k : r [ k ] for k in r . keys () if k != 'id' } # copy input and remove id to avoid propagating it to other objects self . url = URL ( r2 ) if type ( r . get ( 'url' )) is str else r . get ( 'url' ) self . version = r . get ( 'version' ) or Version ( r2 ) self . prediction_metadata = r . get ( 'resource_prediction_metadata' ) or r . get ( 'prediction_metadata' ) self . is_gcbr = r . get ( 'is_gcbr' ) self . is_latest = r . get ( 'is_latest' ) self . __conn__ = r . get ( '__conn__' ) self . __engine__ = r . get ( '__engine__' ) if r . get ( 'grants' ): self . grants = [ Grant ( r2 )] if type ( r . get ( 'grants' )[ 0 ]) is str else r . get ( 'grants' ) elif r . get ( 'ext_grant_ids' ) and r . get ( 'grant_agencies' ): self . grants = [ Grant ({ 'ext_grant_id' : g , 'grant_agency' : ga }) for g , ga in zip ([ x . strip () for x in r . get ( 'ext_grant_ids' ) . split ( ',' )], [ x . strip () for x in r . get ( 'grant_agencies' ) . split ( ',' )])] else : self . grants = [] if not r . get ( 'publications' ) and r . get ( 'title' ) and r . get ( 'pubmed_id' ) and r . get ( 'authors' ): self . publications = [ Publication ( r2 )] else : self . publications = r . get ( 'publications' ) def __str__ ( self ): resource_str = ', ' . join ([ f \"id= { self . id } \" , f \"short_name= { self . short_name } \" , f \"common_name= { self . common_name } \" , f \"full_name= { self . full_name } \" , f \"is_gcbr= { self . is_gcbr } \" , f \"is_latest= { self . is_latest } \" , f \"url= { self . url . __str__ () } \" , f \"version= { self . version . __str__ () } \" , f \"prediction_metadata= { self . prediction_metadata } \" , f \"publications=[ { ', ' . join ([ p . __str__ () for p in self . publications ]) } ]\" if self . publications else \"publications=[]\" , f \"grants=[ { ', ' . join ( g . __str__ () for g in self . grants ) } ]\" if self . grants else \"grants=[]\" ]) return f \"Resource( { resource_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Resource to database along with associated URL, Version, Publication, and Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the resource written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if not self . url . id or force : url_id = self . url . write ( conn = conn , engine = engine , debug = debug ) self . url . id = url_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id # set is_latest to 0 for other versions of this resource if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE resource SET is_latest = 0 WHERE short_name = ' { self . short_name } '\" )) lconn . commit () resource_cols = { 'id' : self . id , 'short_name' : self . short_name , 'common_name' : self . common_name , 'full_name' : self . full_name , 'url_id' : self . url . id , 'version_id' : self . version . id , 'prediction_metadata' : self . prediction_metadata , 'is_gcbr' : self . is_gcbr , 'is_latest' : self . is_latest } new_resource_id = insert_into_table ( 'resource' , resource_cols , conn = conn , engine = engine , debug = debug ) self . id = new_resource_id if self . publications : # delete_from_table('resource_publication', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'resource_publication' , { 'resource_id' : new_resource_id , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) if self . grants : # delete_from_table('resource_grant', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in self . grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between resource and grant tables insert_into_table ( 'resource_grant' , { 'resource_id' : new_resource_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Resource from database along with associated links to publications and grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Resource object must have an ID to delete.\" ) delete_from_table ( 'resource_publication' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'resource_grant' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) self . url . delete ( conn = conn , engine = engine , debug = debug ) r_result = delete_from_table ( 'resource' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return r_result def fetch_by_id ( resource_id : int , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Resource : \"\"\"Fetch Resource from database by ID. Args: resource_id (int): ID of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Resource object. \"\"\" return fetch_resource ({ 'id' : resource_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_name ( name : str , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Args: name (str): Name of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Resource objects. \"\"\" sn_results = fetch_resource ({ 'short_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) cn_results = fetch_resource ({ 'common_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fn_results = fetch_resource ({ 'full_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) sn_results = sn_results if type ( sn_results ) is list else [ sn_results ] if sn_results else [] cn_results = cn_results if type ( cn_results ) is list else [ cn_results ] if cn_results else [] fn_results = fn_results if type ( fn_results ) is list else [ fn_results ] if fn_results else [] combined_results = { r . id : r for r in ( sn_results + cn_results + fn_results )} if len ( combined_results ) == 1 : return list ( combined_results . values ())[ 0 ] elif len ( combined_results ) > 1 : return list ( combined_results . values ()) else : return None def is_online ( self ) -> bool : \"\"\"Return boolean describing whether resource URL is online. Returns: `True` if resource URL is online, `False` otherwise. \"\"\" return self . url . is_online () def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Resource. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Resource. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def referenced_by ( self ) -> list [ Publication ]: \"\"\"Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: List of Publication objects. \"\"\" refs = {} for acc in self . accessions (): for pub in acc . publications : refs [ pub . id ] = pub for mention in self . mentions (): refs [ mention . publication . id ] = mention . publication return list ( refs . values ()) accessions accessions () Return list of Accession objects associated with this Resource. Returns: list [ Accession ] \u2013 List of Accession objects. Source code in globalbiodata/resource.py 225 226 227 228 229 230 231 def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Resource. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) delete delete ( conn = None , engine = None , debug = False ) Delete Resource from database along with associated links to publications and grants. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/resource.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Resource from database along with associated links to publications and grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Resource object must have an ID to delete.\" ) delete_from_table ( 'resource_publication' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'resource_grant' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) self . url . delete ( conn = conn , engine = engine , debug = debug ) r_result = delete_from_table ( 'resource' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return r_result fetch_by_id fetch_by_id ( resource_id , expanded = True , conn = None , engine = None , debug = False , ) Fetch Resource from database by ID. Parameters: resource_id ( int ) \u2013 ID of the Resource to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Resource \u2013 The fetched Resource object. Source code in globalbiodata/resource.py 175 176 177 178 179 180 181 182 183 184 185 186 187 def fetch_by_id ( resource_id : int , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Resource : \"\"\"Fetch Resource from database by ID. Args: resource_id (int): ID of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Resource object. \"\"\" return fetch_resource ({ 'id' : resource_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_by_name fetch_by_name ( name , expanded = True , conn = None , engine = None , debug = False ) Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Parameters: name ( str ) \u2013 Name of the Resource to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 The list of fetched Resource objects. Source code in globalbiodata/resource.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def fetch_by_name ( name : str , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Args: name (str): Name of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Resource objects. \"\"\" sn_results = fetch_resource ({ 'short_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) cn_results = fetch_resource ({ 'common_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fn_results = fetch_resource ({ 'full_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) sn_results = sn_results if type ( sn_results ) is list else [ sn_results ] if sn_results else [] cn_results = cn_results if type ( cn_results ) is list else [ cn_results ] if cn_results else [] fn_results = fn_results if type ( fn_results ) is list else [ fn_results ] if fn_results else [] combined_results = { r . id : r for r in ( sn_results + cn_results + fn_results )} if len ( combined_results ) == 1 : return list ( combined_results . values ())[ 0 ] elif len ( combined_results ) > 1 : return list ( combined_results . values ()) else : return None is_online is_online () Return boolean describing whether resource URL is online. Returns: bool \u2013 True if resource URL is online, False otherwise. Source code in globalbiodata/resource.py 217 218 219 220 221 222 223 def is_online ( self ) -> bool : \"\"\"Return boolean describing whether resource URL is online. Returns: `True` if resource URL is online, `False` otherwise. \"\"\" return self . url . is_online () mentions mentions () Return list of ResourceMention objects that mention this Resource. Returns: list [ ResourceMention ] \u2013 List of ResourceMention objects. Source code in globalbiodata/resource.py 233 234 235 236 237 238 239 def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Resource. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) referenced_by referenced_by () Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: list [ Publication ] \u2013 List of Publication objects. Source code in globalbiodata/resource.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def referenced_by ( self ) -> list [ Publication ]: \"\"\"Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: List of Publication objects. \"\"\" refs = {} for acc in self . accessions (): for pub in acc . publications : refs [ pub . id ] = pub for mention in self . mentions (): refs [ mention . publication . id ] = mention . publication return list ( refs . values ()) write write ( conn = None , engine = None , debug = False , force = False ) Write Resource to database along with associated URL, Version, Publication, and Grant data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the resource written to the database. Source code in globalbiodata/resource.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Resource to database along with associated URL, Version, Publication, and Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the resource written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if not self . url . id or force : url_id = self . url . write ( conn = conn , engine = engine , debug = debug ) self . url . id = url_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id # set is_latest to 0 for other versions of this resource if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE resource SET is_latest = 0 WHERE short_name = ' { self . short_name } '\" )) lconn . commit () resource_cols = { 'id' : self . id , 'short_name' : self . short_name , 'common_name' : self . common_name , 'full_name' : self . full_name , 'url_id' : self . url . id , 'version_id' : self . version . id , 'prediction_metadata' : self . prediction_metadata , 'is_gcbr' : self . is_gcbr , 'is_latest' : self . is_latest } new_resource_id = insert_into_table ( 'resource' , resource_cols , conn = conn , engine = engine , debug = debug ) self . id = new_resource_id if self . publications : # delete_from_table('resource_publication', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'resource_publication' , { 'resource_id' : new_resource_id , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) if self . grants : # delete_from_table('resource_grant', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in self . grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between resource and grant tables insert_into_table ( 'resource_grant' , { 'resource_id' : new_resource_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id","title":"Resource"},{"location":"api/globalbiodata_resource/#globalbiodata.resource","text":"","title":"resource"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource","text":"Class representing a Biodata Resource. Attributes: id ( int ) \u2013 Database ID for the resource. short_name ( str ) \u2013 Short name of the resource. common_name ( str ) \u2013 Common name of the resource. full_name ( str ) \u2013 Full name of the resource. url ( URL ) \u2013 URL object. version ( Version ) \u2013 Version object. prediction_metadata ( str ) \u2013 Additional prediction metadata (JSON). publications ( list [ Publication ] ) \u2013 Associated publications. grants ( list [ Grant ] ) \u2013 Associated grants. is_gcbr ( bool ) \u2013 Core Biodata Resource status. is_latest ( bool ) \u2013 Whether this is the most current version. Source code in globalbiodata/resource.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 @dataclass class Resource : \"\"\"Class representing a Biodata Resource. Attributes: id (int): Database ID for the resource. short_name (str): Short name of the resource. common_name (str): Common name of the resource. full_name (str): Full name of the resource. url (URL): URL object. version (Version): Version object. prediction_metadata (str): Additional prediction metadata (JSON). publications (list[Publication]): Associated publications. grants (list[Grant]): Associated grants. is_gcbr (bool): Core Biodata Resource status. is_latest (bool): Whether this is the most current version. \"\"\" id : int short_name : str common_name : str full_name : str url : URL version : Version prediction_metadata : str publications : list [ Publication ] grants : list [ Grant ] is_gcbr : bool is_latest : bool __conn__ : Connection __engine__ : Engine def __init__ ( self , r ): self . id = r . get ( 'id' ) self . short_name = r . get ( 'short_name' ) self . common_name = r . get ( 'common_name' ) self . full_name = r . get ( 'full_name' ) r2 = { k : r [ k ] for k in r . keys () if k != 'id' } # copy input and remove id to avoid propagating it to other objects self . url = URL ( r2 ) if type ( r . get ( 'url' )) is str else r . get ( 'url' ) self . version = r . get ( 'version' ) or Version ( r2 ) self . prediction_metadata = r . get ( 'resource_prediction_metadata' ) or r . get ( 'prediction_metadata' ) self . is_gcbr = r . get ( 'is_gcbr' ) self . is_latest = r . get ( 'is_latest' ) self . __conn__ = r . get ( '__conn__' ) self . __engine__ = r . get ( '__engine__' ) if r . get ( 'grants' ): self . grants = [ Grant ( r2 )] if type ( r . get ( 'grants' )[ 0 ]) is str else r . get ( 'grants' ) elif r . get ( 'ext_grant_ids' ) and r . get ( 'grant_agencies' ): self . grants = [ Grant ({ 'ext_grant_id' : g , 'grant_agency' : ga }) for g , ga in zip ([ x . strip () for x in r . get ( 'ext_grant_ids' ) . split ( ',' )], [ x . strip () for x in r . get ( 'grant_agencies' ) . split ( ',' )])] else : self . grants = [] if not r . get ( 'publications' ) and r . get ( 'title' ) and r . get ( 'pubmed_id' ) and r . get ( 'authors' ): self . publications = [ Publication ( r2 )] else : self . publications = r . get ( 'publications' ) def __str__ ( self ): resource_str = ', ' . join ([ f \"id= { self . id } \" , f \"short_name= { self . short_name } \" , f \"common_name= { self . common_name } \" , f \"full_name= { self . full_name } \" , f \"is_gcbr= { self . is_gcbr } \" , f \"is_latest= { self . is_latest } \" , f \"url= { self . url . __str__ () } \" , f \"version= { self . version . __str__ () } \" , f \"prediction_metadata= { self . prediction_metadata } \" , f \"publications=[ { ', ' . join ([ p . __str__ () for p in self . publications ]) } ]\" if self . publications else \"publications=[]\" , f \"grants=[ { ', ' . join ( g . __str__ () for g in self . grants ) } ]\" if self . grants else \"grants=[]\" ]) return f \"Resource( { resource_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Resource to database along with associated URL, Version, Publication, and Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the resource written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if not self . url . id or force : url_id = self . url . write ( conn = conn , engine = engine , debug = debug ) self . url . id = url_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id # set is_latest to 0 for other versions of this resource if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE resource SET is_latest = 0 WHERE short_name = ' { self . short_name } '\" )) lconn . commit () resource_cols = { 'id' : self . id , 'short_name' : self . short_name , 'common_name' : self . common_name , 'full_name' : self . full_name , 'url_id' : self . url . id , 'version_id' : self . version . id , 'prediction_metadata' : self . prediction_metadata , 'is_gcbr' : self . is_gcbr , 'is_latest' : self . is_latest } new_resource_id = insert_into_table ( 'resource' , resource_cols , conn = conn , engine = engine , debug = debug ) self . id = new_resource_id if self . publications : # delete_from_table('resource_publication', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'resource_publication' , { 'resource_id' : new_resource_id , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) if self . grants : # delete_from_table('resource_grant', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in self . grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between resource and grant tables insert_into_table ( 'resource_grant' , { 'resource_id' : new_resource_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Resource from database along with associated links to publications and grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Resource object must have an ID to delete.\" ) delete_from_table ( 'resource_publication' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'resource_grant' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) self . url . delete ( conn = conn , engine = engine , debug = debug ) r_result = delete_from_table ( 'resource' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return r_result def fetch_by_id ( resource_id : int , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Resource : \"\"\"Fetch Resource from database by ID. Args: resource_id (int): ID of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Resource object. \"\"\" return fetch_resource ({ 'id' : resource_id }, expanded = expanded , conn = conn , engine = engine , debug = debug ) def fetch_by_name ( name : str , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Args: name (str): Name of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Resource objects. \"\"\" sn_results = fetch_resource ({ 'short_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) cn_results = fetch_resource ({ 'common_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fn_results = fetch_resource ({ 'full_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) sn_results = sn_results if type ( sn_results ) is list else [ sn_results ] if sn_results else [] cn_results = cn_results if type ( cn_results ) is list else [ cn_results ] if cn_results else [] fn_results = fn_results if type ( fn_results ) is list else [ fn_results ] if fn_results else [] combined_results = { r . id : r for r in ( sn_results + cn_results + fn_results )} if len ( combined_results ) == 1 : return list ( combined_results . values ())[ 0 ] elif len ( combined_results ) > 1 : return list ( combined_results . values ()) else : return None def is_online ( self ) -> bool : \"\"\"Return boolean describing whether resource URL is online. Returns: `True` if resource URL is online, `False` otherwise. \"\"\" return self . url . is_online () def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Resource. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Resource. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False ) def referenced_by ( self ) -> list [ Publication ]: \"\"\"Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: List of Publication objects. \"\"\" refs = {} for acc in self . accessions (): for pub in acc . publications : refs [ pub . id ] = pub for mention in self . mentions (): refs [ mention . publication . id ] = mention . publication return list ( refs . values ())","title":"Resource"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.accessions","text":"accessions () Return list of Accession objects associated with this Resource. Returns: list [ Accession ] \u2013 List of Accession objects. Source code in globalbiodata/resource.py 225 226 227 228 229 230 231 def accessions ( self ) -> list [ Accession ]: \"\"\"Return list of Accession objects associated with this Resource. Returns: List of Accession objects. \"\"\" return fetch_accession ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False )","title":"accessions"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete Resource from database along with associated links to publications and grants. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/resource.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Resource from database along with associated links to publications and grants. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Resource object must have an ID to delete.\" ) delete_from_table ( 'resource_publication' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) delete_from_table ( 'resource_grant' , { 'resource_id' : self . id }, conn = conn , engine = engine , debug = debug ) self . url . delete ( conn = conn , engine = engine , debug = debug ) r_result = delete_from_table ( 'resource' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return r_result","title":"delete"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.fetch_by_id","text":"fetch_by_id ( resource_id , expanded = True , conn = None , engine = None , debug = False , ) Fetch Resource from database by ID. Parameters: resource_id ( int ) \u2013 ID of the Resource to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Resource \u2013 The fetched Resource object. Source code in globalbiodata/resource.py 175 176 177 178 179 180 181 182 183 184 185 186 187 def fetch_by_id ( resource_id : int , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Resource : \"\"\"Fetch Resource from database by ID. Args: resource_id (int): ID of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Resource object. \"\"\" return fetch_resource ({ 'id' : resource_id }, expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_by_id"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.fetch_by_name","text":"fetch_by_name ( name , expanded = True , conn = None , engine = None , debug = False ) Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Parameters: name ( str ) \u2013 Name of the Resource to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 The list of fetched Resource objects. Source code in globalbiodata/resource.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def fetch_by_name ( name : str , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Resource from database by name. This will search short_name, common_name, and full_name fields. Args: name (str): Name of the Resource to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched Resource objects. \"\"\" sn_results = fetch_resource ({ 'short_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) cn_results = fetch_resource ({ 'common_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) fn_results = fetch_resource ({ 'full_name' : name , 'is_latest' : 1 }, expanded = expanded , conn = conn , engine = engine , debug = debug ) sn_results = sn_results if type ( sn_results ) is list else [ sn_results ] if sn_results else [] cn_results = cn_results if type ( cn_results ) is list else [ cn_results ] if cn_results else [] fn_results = fn_results if type ( fn_results ) is list else [ fn_results ] if fn_results else [] combined_results = { r . id : r for r in ( sn_results + cn_results + fn_results )} if len ( combined_results ) == 1 : return list ( combined_results . values ())[ 0 ] elif len ( combined_results ) > 1 : return list ( combined_results . values ()) else : return None","title":"fetch_by_name"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.is_online","text":"is_online () Return boolean describing whether resource URL is online. Returns: bool \u2013 True if resource URL is online, False otherwise. Source code in globalbiodata/resource.py 217 218 219 220 221 222 223 def is_online ( self ) -> bool : \"\"\"Return boolean describing whether resource URL is online. Returns: `True` if resource URL is online, `False` otherwise. \"\"\" return self . url . is_online ()","title":"is_online"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.mentions","text":"mentions () Return list of ResourceMention objects that mention this Resource. Returns: list [ ResourceMention ] \u2013 List of ResourceMention objects. Source code in globalbiodata/resource.py 233 234 235 236 237 238 239 def mentions ( self ) -> list [ ResourceMention ]: \"\"\"Return list of ResourceMention objects that mention this Resource. Returns: List of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : self . id }, conn = self . __conn__ , engine = self . __engine__ , debug = False )","title":"mentions"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.referenced_by","text":"referenced_by () Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: list [ Publication ] \u2013 List of Publication objects. Source code in globalbiodata/resource.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 def referenced_by ( self ) -> list [ Publication ]: \"\"\"Return list of Publication objects that reference this Resource either via an Accession or a ResourceMention. Returns: List of Publication objects. \"\"\" refs = {} for acc in self . accessions (): for pub in acc . publications : refs [ pub . id ] = pub for mention in self . mentions (): refs [ mention . publication . id ] = mention . publication return list ( refs . values ())","title":"referenced_by"},{"location":"api/globalbiodata_resource/#globalbiodata.resource.Resource.write","text":"write ( conn = None , engine = None , debug = False , force = False ) Write Resource to database along with associated URL, Version, Publication, and Grant data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the resource written to the database. Source code in globalbiodata/resource.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write Resource to database along with associated URL, Version, Publication, and Grant data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the resource written to the database. \"\"\" conn = conn or self . __conn__ engine = engine or self . __engine__ if not self . url . id or force : url_id = self . url . write ( conn = conn , engine = engine , debug = debug ) self . url . id = url_id if not self . version . id or force : version_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = version_id # set is_latest to 0 for other versions of this resource if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE resource SET is_latest = 0 WHERE short_name = ' { self . short_name } '\" )) lconn . commit () resource_cols = { 'id' : self . id , 'short_name' : self . short_name , 'common_name' : self . common_name , 'full_name' : self . full_name , 'url_id' : self . url . id , 'version_id' : self . version . id , 'prediction_metadata' : self . prediction_metadata , 'is_gcbr' : self . is_gcbr , 'is_latest' : self . is_latest } new_resource_id = insert_into_table ( 'resource' , resource_cols , conn = conn , engine = engine , debug = debug ) self . id = new_resource_id if self . publications : # delete_from_table('resource_publication', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for p in self . publications : if not p . id or force : new_pub_id = p . write ( conn = conn , engine = engine , debug = debug ) p . id = new_pub_id # create links between resource and publication tables insert_into_table ( 'resource_publication' , { 'resource_id' : new_resource_id , 'publication_id' : p . id }, conn = conn , engine = engine , debug = debug ) if self . grants : # delete_from_table('resource_grant', {'resource_id':new_resource_id}, conn=conn, engine=engine, debug=debug) # delete existing links for g in self . grants : if not g . id or force : new_grant_id = g . write ( conn = conn , engine = engine , debug = debug ) g . id = new_grant_id # create links between resource and grant tables insert_into_table ( 'resource_grant' , { 'resource_id' : new_resource_id , 'grant_id' : g . id }, conn = conn , engine = engine , debug = debug ) return self . id","title":"write"},{"location":"api/globalbiodata_resource_mention/","text":"globalbiodata.resource_mention MatchedAlias dataclass Object to represent a matched alias with match count and confidence. Attributes: matched_alias ( str ) \u2013 alias string that matched match_count ( int ) \u2013 number of matches mean_confidence ( float ) \u2013 mean confidence score Source code in globalbiodata/resource_mention.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @dataclass class MatchedAlias : \"\"\" Object to represent a matched alias with match count and confidence. Attributes: matched_alias (str): alias string that matched match_count (int): number of matches mean_confidence (float): mean confidence score \"\"\" matched_alias : str match_count : int mean_confidence : float def __init__ ( self , ma ): self . matched_alias = ma . get ( 'matched_alias' ) self . match_count = ma . get ( 'match_count' , 0 ) self . mean_confidence = ma . get ( 'mean_confidence' , 0.0 ) ResourceMention dataclass Object to represent a link between a Publication and a Resource, with match info. Attributes: publication ( Publication ) \u2013 Publication object resource ( Resource ) \u2013 Resource object version ( Version ) \u2013 Version object matched_aliases ( list [ MatchedAlias ] ) \u2013 list of MatchedAlias objects, each representing an alias that matched match_count ( int ) \u2013 number of matches mean_confidence ( float ) \u2013 mean confidence score Source code in globalbiodata/resource_mention.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 @dataclass class ResourceMention : \"\"\" Object to represent a link between a Publication and a Resource, with match info. Attributes: publication (Publication): Publication object resource (Resource): Resource object version (Version): Version object matched_aliases (list[MatchedAlias]): list of MatchedAlias objects, each representing an alias that matched match_count (int): number of matches mean_confidence (float): mean confidence score \"\"\" publication : Publication resource : Resource version : Version matched_aliases : list [ MatchedAlias ] match_count : int mean_confidence : float def __init__ ( self , m ): self . publication = m . get ( 'publication' ) or Publication ( extract_fields_by_type ( m , 'publication' )) self . resource = m . get ( 'resource' ) or Resource ( extract_fields_by_type ( m , 'resource' )) self . version = m . get ( 'version' ) or Version ( extract_fields_by_type ( m , 'version' )) if m . get ( 'matched_alias' ) and type ( m . get ( 'matched_alias' )) is str : this_ma = MatchedAlias ({ 'matched_alias' : m . get ( 'matched_alias' ), 'match_count' : m . get ( 'match_count' , 0 ), 'mean_confidence' : m . get ( 'mean_confidence' , 0.0 )}) self . matched_aliases = [ this_ma ] elif type ( m . get ( 'matched_aliases' )) is list : if type ( m . get ( 'matched_aliases' )[ 0 ]) is str : raise ValueError ( \"matched_aliases cannot be a list of strings; must be a list of dicts with matched_alias, match_count, and mean_confidence.\" ) if type ( m . get ( 'matched_aliases' )[ 0 ]) is MatchedAlias : self . matched_aliases = m . get ( 'matched_aliases' , []) elif type ( m . get ( 'matched_aliases' )[ 0 ]) is dict : self . matched_aliases = [ MatchedAlias ( ma ) for ma in m . get ( 'matched_aliases' , [])] elif type ( m . get ( 'matched_aliases' )) is MatchedAlias : self . matched_aliases = [ m . get ( 'matched_aliases' )] self . match_count = sum ([ ma . match_count for ma in self . matched_aliases ]) self . mean_confidence = mean ([ ma . mean_confidence for ma in self . matched_aliases ]) if self . matched_aliases else 0.0 def __str__ ( self ): return ( f \"ResourceMention(pub= { self . publication . __str__ () } , res= { self . resource . __str__ () } , \" f \"ver= { self . version . __str__ () } , aliases=' { self . matched_aliases } ', \" f \"count= { self . match_count } , mean_conf= { self . mean_confidence } )\" ) def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write ResourceMention to database along with associated Publication, Resource, and Version data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the ResourceMention written to the database. \"\"\" if not self . publication . id or force : pub_id = self . publication . write ( conn = conn , engine = engine , debug = debug ) self . publication . id = pub_id if not self . resource . id or force : res_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = res_id if not self . version . id or force : ver_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = ver_id for matched_alias in self . matched_aliases : mention_cols = { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'matched_alias' : matched_alias . matched_alias , 'match_count' : matched_alias . match_count , 'mean_confidence' : matched_alias . mean_confidence , } insert_into_table ( 'resource_mention' , mention_cols , conn = conn , engine = engine , debug = debug ) def delete ( self , conn = None , engine = None , debug = False ): if conn is None : conn = engine . connect () if not self . publication_id or not self . resource_id : raise ValueError ( \"ResourceMention requires publication_id and resource_id to delete.\" ) for matched_alias in self . matched_aliases : del_result = delete_from_table ( 'resource_mention' , { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'matched_alias' : matched_alias [ 'matched_alias' ]}, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_publication_id ( publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Publication ID. Args: publication_id (int): Publication ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_resource_id ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Resource ID. Args: resource_id (int): Resource ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug ) fetch_by_publication_id fetch_by_publication_id ( publication_id , conn = None , engine = None , debug = False ) Fetch ResourceMention from database by Publication ID. Parameters: publication_id ( int ) \u2013 Publication ID of the ResourceMention to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of ResourceMention objects. Source code in globalbiodata/resource_mention.py 115 116 117 118 119 120 121 122 123 124 125 126 127 def fetch_by_publication_id ( publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Publication ID. Args: publication_id (int): Publication ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug ) fetch_by_resource_id fetch_by_resource_id ( resource_id , conn = None , engine = None , debug = False ) Fetch ResourceMention from database by Resource ID. Parameters: resource_id ( int ) \u2013 Resource ID of the ResourceMention to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of ResourceMention objects. Source code in globalbiodata/resource_mention.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def fetch_by_resource_id ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Resource ID. Args: resource_id (int): Resource ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False , force = False ) Write ResourceMention to database along with associated Publication, Resource, and Version data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the ResourceMention written to the database. Source code in globalbiodata/resource_mention.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write ResourceMention to database along with associated Publication, Resource, and Version data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the ResourceMention written to the database. \"\"\" if not self . publication . id or force : pub_id = self . publication . write ( conn = conn , engine = engine , debug = debug ) self . publication . id = pub_id if not self . resource . id or force : res_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = res_id if not self . version . id or force : ver_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = ver_id for matched_alias in self . matched_aliases : mention_cols = { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'matched_alias' : matched_alias . matched_alias , 'match_count' : matched_alias . match_count , 'mean_confidence' : matched_alias . mean_confidence , } insert_into_table ( 'resource_mention' , mention_cols , conn = conn , engine = engine , debug = debug )","title":"ResourceMention & MatchedAlias"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention","text":"","title":"resource_mention"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention.MatchedAlias","text":"Object to represent a matched alias with match count and confidence. Attributes: matched_alias ( str ) \u2013 alias string that matched match_count ( int ) \u2013 number of matches mean_confidence ( float ) \u2013 mean confidence score Source code in globalbiodata/resource_mention.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 @dataclass class MatchedAlias : \"\"\" Object to represent a matched alias with match count and confidence. Attributes: matched_alias (str): alias string that matched match_count (int): number of matches mean_confidence (float): mean confidence score \"\"\" matched_alias : str match_count : int mean_confidence : float def __init__ ( self , ma ): self . matched_alias = ma . get ( 'matched_alias' ) self . match_count = ma . get ( 'match_count' , 0 ) self . mean_confidence = ma . get ( 'mean_confidence' , 0.0 )","title":"MatchedAlias"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention.ResourceMention","text":"Object to represent a link between a Publication and a Resource, with match info. Attributes: publication ( Publication ) \u2013 Publication object resource ( Resource ) \u2013 Resource object version ( Version ) \u2013 Version object matched_aliases ( list [ MatchedAlias ] ) \u2013 list of MatchedAlias objects, each representing an alias that matched match_count ( int ) \u2013 number of matches mean_confidence ( float ) \u2013 mean confidence score Source code in globalbiodata/resource_mention.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 @dataclass class ResourceMention : \"\"\" Object to represent a link between a Publication and a Resource, with match info. Attributes: publication (Publication): Publication object resource (Resource): Resource object version (Version): Version object matched_aliases (list[MatchedAlias]): list of MatchedAlias objects, each representing an alias that matched match_count (int): number of matches mean_confidence (float): mean confidence score \"\"\" publication : Publication resource : Resource version : Version matched_aliases : list [ MatchedAlias ] match_count : int mean_confidence : float def __init__ ( self , m ): self . publication = m . get ( 'publication' ) or Publication ( extract_fields_by_type ( m , 'publication' )) self . resource = m . get ( 'resource' ) or Resource ( extract_fields_by_type ( m , 'resource' )) self . version = m . get ( 'version' ) or Version ( extract_fields_by_type ( m , 'version' )) if m . get ( 'matched_alias' ) and type ( m . get ( 'matched_alias' )) is str : this_ma = MatchedAlias ({ 'matched_alias' : m . get ( 'matched_alias' ), 'match_count' : m . get ( 'match_count' , 0 ), 'mean_confidence' : m . get ( 'mean_confidence' , 0.0 )}) self . matched_aliases = [ this_ma ] elif type ( m . get ( 'matched_aliases' )) is list : if type ( m . get ( 'matched_aliases' )[ 0 ]) is str : raise ValueError ( \"matched_aliases cannot be a list of strings; must be a list of dicts with matched_alias, match_count, and mean_confidence.\" ) if type ( m . get ( 'matched_aliases' )[ 0 ]) is MatchedAlias : self . matched_aliases = m . get ( 'matched_aliases' , []) elif type ( m . get ( 'matched_aliases' )[ 0 ]) is dict : self . matched_aliases = [ MatchedAlias ( ma ) for ma in m . get ( 'matched_aliases' , [])] elif type ( m . get ( 'matched_aliases' )) is MatchedAlias : self . matched_aliases = [ m . get ( 'matched_aliases' )] self . match_count = sum ([ ma . match_count for ma in self . matched_aliases ]) self . mean_confidence = mean ([ ma . mean_confidence for ma in self . matched_aliases ]) if self . matched_aliases else 0.0 def __str__ ( self ): return ( f \"ResourceMention(pub= { self . publication . __str__ () } , res= { self . resource . __str__ () } , \" f \"ver= { self . version . __str__ () } , aliases=' { self . matched_aliases } ', \" f \"count= { self . match_count } , mean_conf= { self . mean_confidence } )\" ) def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write ResourceMention to database along with associated Publication, Resource, and Version data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the ResourceMention written to the database. \"\"\" if not self . publication . id or force : pub_id = self . publication . write ( conn = conn , engine = engine , debug = debug ) self . publication . id = pub_id if not self . resource . id or force : res_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = res_id if not self . version . id or force : ver_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = ver_id for matched_alias in self . matched_aliases : mention_cols = { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'matched_alias' : matched_alias . matched_alias , 'match_count' : matched_alias . match_count , 'mean_confidence' : matched_alias . mean_confidence , } insert_into_table ( 'resource_mention' , mention_cols , conn = conn , engine = engine , debug = debug ) def delete ( self , conn = None , engine = None , debug = False ): if conn is None : conn = engine . connect () if not self . publication_id or not self . resource_id : raise ValueError ( \"ResourceMention requires publication_id and resource_id to delete.\" ) for matched_alias in self . matched_aliases : del_result = delete_from_table ( 'resource_mention' , { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'matched_alias' : matched_alias [ 'matched_alias' ]}, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_publication_id ( publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Publication ID. Args: publication_id (int): Publication ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_resource_id ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Resource ID. Args: resource_id (int): Resource ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug )","title":"ResourceMention"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention.ResourceMention.fetch_by_publication_id","text":"fetch_by_publication_id ( publication_id , conn = None , engine = None , debug = False ) Fetch ResourceMention from database by Publication ID. Parameters: publication_id ( int ) \u2013 Publication ID of the ResourceMention to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of ResourceMention objects. Source code in globalbiodata/resource_mention.py 115 116 117 118 119 120 121 122 123 124 125 126 127 def fetch_by_publication_id ( publication_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Publication ID. Args: publication_id (int): Publication ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'publication_id' : publication_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_publication_id"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention.ResourceMention.fetch_by_resource_id","text":"fetch_by_resource_id ( resource_id , conn = None , engine = None , debug = False ) Fetch ResourceMention from database by Resource ID. Parameters: resource_id ( int ) \u2013 Resource ID of the ResourceMention to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of ResourceMention objects. Source code in globalbiodata/resource_mention.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def fetch_by_resource_id ( resource_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ResourceMention from database by Resource ID. Args: resource_id (int): Resource ID of the ResourceMention to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of ResourceMention objects. \"\"\" return fetch_resource_mention ({ 'resource_id' : resource_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_resource_id"},{"location":"api/globalbiodata_resource_mention/#globalbiodata.resource_mention.ResourceMention.write","text":"write ( conn = None , engine = None , debug = False , force = False ) Write ResourceMention to database along with associated Publication, Resource, and Version data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. force ( bool , default: False ) \u2013 If True , force writing of associated objects even if they have IDs. Returns: int \u2013 The ID of the ResourceMention written to the database. Source code in globalbiodata/resource_mention.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , force : bool = False ) -> int : \"\"\"Write ResourceMention to database along with associated Publication, Resource, and Version data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. force (bool, optional): If `True`, force writing of associated objects even if they have IDs. Returns: The ID of the ResourceMention written to the database. \"\"\" if not self . publication . id or force : pub_id = self . publication . write ( conn = conn , engine = engine , debug = debug ) self . publication . id = pub_id if not self . resource . id or force : res_id = self . resource . write ( conn = conn , engine = engine , debug = debug ) self . resource . id = res_id if not self . version . id or force : ver_id = self . version . write ( conn = conn , engine = engine , debug = debug ) self . version . id = ver_id for matched_alias in self . matched_aliases : mention_cols = { 'publication_id' : self . publication . id , 'resource_id' : self . resource . id , 'version_id' : self . version . id , 'matched_alias' : matched_alias . matched_alias , 'match_count' : matched_alias . match_count , 'mean_confidence' : matched_alias . mean_confidence , } insert_into_table ( 'resource_mention' , mention_cols , conn = conn , engine = engine , debug = debug )","title":"write"},{"location":"api/globalbiodata_url/","text":"globalbiodata.url ConnectionStatus dataclass Class to represent status of a ping of a URL Attributes: url_id ( int ) \u2013 Database ID for URL status ( str ) \u2013 Code returned from connection date ( datetime ) \u2013 Date of connection is_online ( bool ) \u2013 boolean describing whether return code indicates resource is online is_latest ( bool ) \u2013 boolean value describing whether this is the most recent connection attempt Source code in globalbiodata/url.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 @dataclass class ConnectionStatus : \"\"\" Class to represent status of a ping of a URL Attributes: url_id (int): Database ID for URL status (str): Code returned from connection date (datetime): Date of connection is_online (bool): boolean describing whether return code indicates resource is online is_latest (bool): boolean value describing whether this is the most recent connection attempt \"\"\" url_id : int status : str date : datetime is_online : bool is_latest : bool def __init__ ( self , c ): self . url_id = c . get ( 'url_id' ) self . status = str ( c . get ( 'status' )) self . date = c . get ( 'connection_date' ) or c . get ( 'date' ) self . is_latest = c . get ( 'is_latest' , 0 ) if not self . date : self . date = datetime . now () . strftime ( \"%Y-%m- %d %H:%M:%S\" ) self . is_latest = 1 else : self . date = datetime . strptime ( self . date , \"%Y-%m- %d %H:%M:%S\" ) if type ( self . date ) is str else self . date if c . get ( 'is_online' ) is None : self . is_online = self . status [: 18 ] not in [ '404' , '500' , 'HTTPConnectionPool' ] else : self . is_online = c . get ( 'is_online' ) def __str__ ( self ): status_str = f \"ConnectionStatus(url_id= { self . url_id } , status= { self . status } , date= { self . date } , is_online= { self . is_online } , is_latest= { self . is_latest } )\" return status_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write ConnectionStatus to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the ConnectionStatus written to the database. \"\"\" # update is_latest to 0 for other connection statuses if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE connection_status SET is_latest = 0 WHERE url_id = { self . url_id } \" )) lconn . commit () insert_into_table ( 'connection_status' , self . __dict__ , conn = conn , engine = engine , debug = debug ) def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete ConnectionStatus from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . url_id : raise ValueError ( \"ConnectionStatus object must have a URL ID to delete.\" ) del_result = delete_from_table ( 'connection_status' , { 'url_id' : self . url_id , 'date' : self . date }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_url_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ConnectionStatus from database by URL ID. Args: url_id (int): URL ID of the ConnectionStatus to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched ConnectionStatus objects. \"\"\" return fetch_connection_status ({ 'url_id' : url_id }, conn = conn , engine = engine , debug = debug ) delete delete ( conn = None , engine = None , debug = False ) Delete ConnectionStatus from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/url.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete ConnectionStatus from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . url_id : raise ValueError ( \"ConnectionStatus object must have a URL ID to delete.\" ) del_result = delete_from_table ( 'connection_status' , { 'url_id' : self . url_id , 'date' : self . date }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_url_id fetch_by_url_id ( url_id , conn = None , engine = None , debug = False ) Fetch ConnectionStatus from database by URL ID. Parameters: url_id ( int ) \u2013 URL ID of the ConnectionStatus to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of fetched ConnectionStatus objects. Source code in globalbiodata/url.py 243 244 245 246 247 248 249 250 251 252 253 254 255 def fetch_by_url_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ConnectionStatus from database by URL ID. Args: url_id (int): URL ID of the ConnectionStatus to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched ConnectionStatus objects. \"\"\" return fetch_connection_status ({ 'url_id' : url_id }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False ) Write ConnectionStatus to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the ConnectionStatus written to the database. Source code in globalbiodata/url.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write ConnectionStatus to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the ConnectionStatus written to the database. \"\"\" # update is_latest to 0 for other connection statuses if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE connection_status SET is_latest = 0 WHERE url_id = { self . url_id } \" )) lconn . commit () insert_into_table ( 'connection_status' , self . __dict__ , conn = conn , engine = engine , debug = debug ) URL dataclass Class to represent URL objects and associated information Attributes: id ( int ) \u2013 Database ID for URL url ( str ) \u2013 URL string url_country ( str ) \u2013 Country of URL url_coordinates ( str ) \u2013 Coordinates of URL status ( list [ ConnectionStatus ] ) \u2013 ConnectionStatus object(s) wayback_url ( str ) \u2013 URL for Wayback Machine Source code in globalbiodata/url.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @dataclass class URL : \"\"\" Class to represent URL objects and associated information Attributes: id (int): Database ID for URL url (str): URL string url_country (str): Country of URL url_coordinates (str): Coordinates of URL status (list[ConnectionStatus]): ConnectionStatus object(s) wayback_url (str): URL for Wayback Machine \"\"\" id : int url : str url_country : str url_coordinates : str url_status : str status : list [ ConnectionStatus ] wayback_url : str def __init__ ( self , u ): self . id = u . get ( 'id' ) self . url = u . get ( 'url' ) self . url_country = u . get ( 'url_country' ) self . url_coordinates = u . get ( 'url_coordinates' ) self . wayback_url = u . get ( 'wayback_url' ) # ConnectionStatus can either come as a list of dicts, a list of ConnectionStatus objects # or status fields directly in the url object. # End result should be a list of ConnectionStatus objs. if ( not u . get ( 'status' ) or len ( str ( u . get ( 'status' ))) == 0 ) and not u . get ( 'url_status' ): cs = [] if u . get ( 'status' ) and type ( u . get ( 'status' )) is not list : u [ 'status' ] = [ u [ 'status' ]] if type ( u . get ( 'status' )) is list : if type ( u . get ( 'status' )[ 0 ]) is dict : cs = [ ConnectionStatus ( s ) for s in u . get ( 'status' )] elif type ( u . get ( 'status' )[ 0 ]) is ConnectionStatus : cs = u . get ( 'status' ) elif u . get ( 'url_status' ): cs = [ ConnectionStatus ({ 'url_id' : self . id , 'status' : u . get ( 'url_status' ), 'date' : u . get ( 'connection_date' )})] else : cs = [] self . status = cs def __str__ ( self ): url_str = ', ' . join ([ f \"id= { self . id } \" , f \"url= { self . url } \" , f \"url_country= { self . url_country } \" , f \"url_coordinates= { self . url_coordinates } \" , f \"wayback_url= { self . wayback_url } \" , f \"status=[ { ', ' . join ([ s . __str__ () for s in self . status ]) } ]\" if self . status else \"status=[]\" ]) return f \"URL( { url_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write URL to database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the URL written to the database. \"\"\" conn_statuses = self . status d = self . __dict__ del d [ 'status' ] new_url_id = insert_into_table ( 'url' , d , conn = conn , engine = engine , debug = debug ) self . id = new_url_id for c in conn_statuses : c . url_id = self . id c . write ( conn = conn , engine = engine , debug = debug ) self . status = conn_statuses return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete URL from database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"URL object must have an ID to delete.\" ) delete_from_table ( 'connection_status' , { 'url_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'url' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> URL : \"\"\"Fetch URL from database by ID. Args: url_id (int): ID of the URL to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object. \"\"\" return fetch_url ({ 'id' : url_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_url ( url : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL from database by URL string. Args: url (str): URL string to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object if one result, else list of URLs, else `None`. \"\"\" return fetch_url ({ 'url' : url }, conn = conn , engine = engine , debug = debug ) def latest_connection_status ( self ) -> ConnectionStatus : \"\"\"Get the latest ConnectionStatus object for this URL. Returns: The latest ConnectionStatus object or `None` if not found. \"\"\" if not self . status or len ( self . status ) == 0 : return None latest_status = self . status [ 0 ] if latest_status . is_latest != 1 : for s in self . status : if s . is_latest == 1 : latest_status = s break return latest_status def is_online ( self ) -> bool : \"\"\"Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: `True` if URL is online, `False` otherwise. \"\"\" latest_status = self . latest_connection_status () return True if ( latest_status and latest_status . is_online ) else False delete delete ( conn = None , engine = None , debug = False ) Delete URL from database along with associated ConnectionStatus data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The number of rows deleted. Source code in globalbiodata/url.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete URL from database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"URL object must have an ID to delete.\" ) delete_from_table ( 'connection_status' , { 'url_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'url' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_id fetch_by_id ( url_id , conn = None , engine = None , debug = False ) Fetch URL from database by ID. Parameters: url_id ( int ) \u2013 ID of the URL to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: URL \u2013 The fetched URL object. Source code in globalbiodata/url.py 111 112 113 114 115 116 117 118 119 120 121 122 123 def fetch_by_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> URL : \"\"\"Fetch URL from database by ID. Args: url_id (int): ID of the URL to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object. \"\"\" return fetch_url ({ 'id' : url_id }, conn = conn , engine = engine , debug = debug ) fetch_by_url fetch_by_url ( url , conn = None , engine = None , debug = False ) Fetch URL from database by URL string. Parameters: url ( str ) \u2013 URL string to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ URL ] \u2013 The fetched URL object if one result, else list of URLs, else None . Source code in globalbiodata/url.py 125 126 127 128 129 130 131 132 133 134 135 136 137 def fetch_by_url ( url : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL from database by URL string. Args: url (str): URL string to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object if one result, else list of URLs, else `None`. \"\"\" return fetch_url ({ 'url' : url }, conn = conn , engine = engine , debug = debug ) is_online is_online () Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: bool \u2013 True if URL is online, False otherwise. Source code in globalbiodata/url.py 156 157 158 159 160 161 162 163 def is_online ( self ) -> bool : \"\"\"Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: `True` if URL is online, `False` otherwise. \"\"\" latest_status = self . latest_connection_status () return True if ( latest_status and latest_status . is_online ) else False latest_connection_status latest_connection_status () Get the latest ConnectionStatus object for this URL. Returns: ConnectionStatus \u2013 The latest ConnectionStatus object or None if not found. Source code in globalbiodata/url.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def latest_connection_status ( self ) -> ConnectionStatus : \"\"\"Get the latest ConnectionStatus object for this URL. Returns: The latest ConnectionStatus object or `None` if not found. \"\"\" if not self . status or len ( self . status ) == 0 : return None latest_status = self . status [ 0 ] if latest_status . is_latest != 1 : for s in self . status : if s . is_latest == 1 : latest_status = s break return latest_status write write ( conn = None , engine = None , debug = False ) Write URL to database along with associated ConnectionStatus data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the URL written to the database. Source code in globalbiodata/url.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write URL to database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the URL written to the database. \"\"\" conn_statuses = self . status d = self . __dict__ del d [ 'status' ] new_url_id = insert_into_table ( 'url' , d , conn = conn , engine = engine , debug = debug ) self . id = new_url_id for c in conn_statuses : c . url_id = self . id c . write ( conn = conn , engine = engine , debug = debug ) self . status = conn_statuses return self . id","title":"URL & ConnectionStatus"},{"location":"api/globalbiodata_url/#globalbiodata.url","text":"","title":"url"},{"location":"api/globalbiodata_url/#globalbiodata.url.ConnectionStatus","text":"Class to represent status of a ping of a URL Attributes: url_id ( int ) \u2013 Database ID for URL status ( str ) \u2013 Code returned from connection date ( datetime ) \u2013 Date of connection is_online ( bool ) \u2013 boolean describing whether return code indicates resource is online is_latest ( bool ) \u2013 boolean value describing whether this is the most recent connection attempt Source code in globalbiodata/url.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 @dataclass class ConnectionStatus : \"\"\" Class to represent status of a ping of a URL Attributes: url_id (int): Database ID for URL status (str): Code returned from connection date (datetime): Date of connection is_online (bool): boolean describing whether return code indicates resource is online is_latest (bool): boolean value describing whether this is the most recent connection attempt \"\"\" url_id : int status : str date : datetime is_online : bool is_latest : bool def __init__ ( self , c ): self . url_id = c . get ( 'url_id' ) self . status = str ( c . get ( 'status' )) self . date = c . get ( 'connection_date' ) or c . get ( 'date' ) self . is_latest = c . get ( 'is_latest' , 0 ) if not self . date : self . date = datetime . now () . strftime ( \"%Y-%m- %d %H:%M:%S\" ) self . is_latest = 1 else : self . date = datetime . strptime ( self . date , \"%Y-%m- %d %H:%M:%S\" ) if type ( self . date ) is str else self . date if c . get ( 'is_online' ) is None : self . is_online = self . status [: 18 ] not in [ '404' , '500' , 'HTTPConnectionPool' ] else : self . is_online = c . get ( 'is_online' ) def __str__ ( self ): status_str = f \"ConnectionStatus(url_id= { self . url_id } , status= { self . status } , date= { self . date } , is_online= { self . is_online } , is_latest= { self . is_latest } )\" return status_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write ConnectionStatus to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the ConnectionStatus written to the database. \"\"\" # update is_latest to 0 for other connection statuses if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE connection_status SET is_latest = 0 WHERE url_id = { self . url_id } \" )) lconn . commit () insert_into_table ( 'connection_status' , self . __dict__ , conn = conn , engine = engine , debug = debug ) def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete ConnectionStatus from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . url_id : raise ValueError ( \"ConnectionStatus object must have a URL ID to delete.\" ) del_result = delete_from_table ( 'connection_status' , { 'url_id' : self . url_id , 'date' : self . date }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_url_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ConnectionStatus from database by URL ID. Args: url_id (int): URL ID of the ConnectionStatus to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched ConnectionStatus objects. \"\"\" return fetch_connection_status ({ 'url_id' : url_id }, conn = conn , engine = engine , debug = debug )","title":"ConnectionStatus"},{"location":"api/globalbiodata_url/#globalbiodata.url.ConnectionStatus.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete ConnectionStatus from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/url.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete ConnectionStatus from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . url_id : raise ValueError ( \"ConnectionStatus object must have a URL ID to delete.\" ) del_result = delete_from_table ( 'connection_status' , { 'url_id' : self . url_id , 'date' : self . date }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_url/#globalbiodata.url.ConnectionStatus.fetch_by_url_id","text":"fetch_by_url_id ( url_id , conn = None , engine = None , debug = False ) Fetch ConnectionStatus from database by URL ID. Parameters: url_id ( int ) \u2013 URL ID of the ConnectionStatus to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 The list of fetched ConnectionStatus objects. Source code in globalbiodata/url.py 243 244 245 246 247 248 249 250 251 252 253 254 255 def fetch_by_url_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch ConnectionStatus from database by URL ID. Args: url_id (int): URL ID of the ConnectionStatus to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The list of fetched ConnectionStatus objects. \"\"\" return fetch_connection_status ({ 'url_id' : url_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_url_id"},{"location":"api/globalbiodata_url/#globalbiodata.url.ConnectionStatus.write","text":"write ( conn = None , engine = None , debug = False ) Write ConnectionStatus to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the ConnectionStatus written to the database. Source code in globalbiodata/url.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write ConnectionStatus to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the ConnectionStatus written to the database. \"\"\" # update is_latest to 0 for other connection statuses if self . is_latest : lconn = engine . connect () lconn . execute ( db . text ( f \"UPDATE connection_status SET is_latest = 0 WHERE url_id = { self . url_id } \" )) lconn . commit () insert_into_table ( 'connection_status' , self . __dict__ , conn = conn , engine = engine , debug = debug )","title":"write"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL","text":"Class to represent URL objects and associated information Attributes: id ( int ) \u2013 Database ID for URL url ( str ) \u2013 URL string url_country ( str ) \u2013 Country of URL url_coordinates ( str ) \u2013 Coordinates of URL status ( list [ ConnectionStatus ] ) \u2013 ConnectionStatus object(s) wayback_url ( str ) \u2013 URL for Wayback Machine Source code in globalbiodata/url.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @dataclass class URL : \"\"\" Class to represent URL objects and associated information Attributes: id (int): Database ID for URL url (str): URL string url_country (str): Country of URL url_coordinates (str): Coordinates of URL status (list[ConnectionStatus]): ConnectionStatus object(s) wayback_url (str): URL for Wayback Machine \"\"\" id : int url : str url_country : str url_coordinates : str url_status : str status : list [ ConnectionStatus ] wayback_url : str def __init__ ( self , u ): self . id = u . get ( 'id' ) self . url = u . get ( 'url' ) self . url_country = u . get ( 'url_country' ) self . url_coordinates = u . get ( 'url_coordinates' ) self . wayback_url = u . get ( 'wayback_url' ) # ConnectionStatus can either come as a list of dicts, a list of ConnectionStatus objects # or status fields directly in the url object. # End result should be a list of ConnectionStatus objs. if ( not u . get ( 'status' ) or len ( str ( u . get ( 'status' ))) == 0 ) and not u . get ( 'url_status' ): cs = [] if u . get ( 'status' ) and type ( u . get ( 'status' )) is not list : u [ 'status' ] = [ u [ 'status' ]] if type ( u . get ( 'status' )) is list : if type ( u . get ( 'status' )[ 0 ]) is dict : cs = [ ConnectionStatus ( s ) for s in u . get ( 'status' )] elif type ( u . get ( 'status' )[ 0 ]) is ConnectionStatus : cs = u . get ( 'status' ) elif u . get ( 'url_status' ): cs = [ ConnectionStatus ({ 'url_id' : self . id , 'status' : u . get ( 'url_status' ), 'date' : u . get ( 'connection_date' )})] else : cs = [] self . status = cs def __str__ ( self ): url_str = ', ' . join ([ f \"id= { self . id } \" , f \"url= { self . url } \" , f \"url_country= { self . url_country } \" , f \"url_coordinates= { self . url_coordinates } \" , f \"wayback_url= { self . wayback_url } \" , f \"status=[ { ', ' . join ([ s . __str__ () for s in self . status ]) } ]\" if self . status else \"status=[]\" ]) return f \"URL( { url_str } )\" def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write URL to database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the URL written to the database. \"\"\" conn_statuses = self . status d = self . __dict__ del d [ 'status' ] new_url_id = insert_into_table ( 'url' , d , conn = conn , engine = engine , debug = debug ) self . id = new_url_id for c in conn_statuses : c . url_id = self . id c . write ( conn = conn , engine = engine , debug = debug ) self . status = conn_statuses return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete URL from database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"URL object must have an ID to delete.\" ) delete_from_table ( 'connection_status' , { 'url_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'url' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> URL : \"\"\"Fetch URL from database by ID. Args: url_id (int): ID of the URL to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object. \"\"\" return fetch_url ({ 'id' : url_id }, conn = conn , engine = engine , debug = debug ) def fetch_by_url ( url : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL from database by URL string. Args: url (str): URL string to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object if one result, else list of URLs, else `None`. \"\"\" return fetch_url ({ 'url' : url }, conn = conn , engine = engine , debug = debug ) def latest_connection_status ( self ) -> ConnectionStatus : \"\"\"Get the latest ConnectionStatus object for this URL. Returns: The latest ConnectionStatus object or `None` if not found. \"\"\" if not self . status or len ( self . status ) == 0 : return None latest_status = self . status [ 0 ] if latest_status . is_latest != 1 : for s in self . status : if s . is_latest == 1 : latest_status = s break return latest_status def is_online ( self ) -> bool : \"\"\"Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: `True` if URL is online, `False` otherwise. \"\"\" latest_status = self . latest_connection_status () return True if ( latest_status and latest_status . is_online ) else False","title":"URL"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete URL from database along with associated ConnectionStatus data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The number of rows deleted. Source code in globalbiodata/url.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete URL from database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"URL object must have an ID to delete.\" ) delete_from_table ( 'connection_status' , { 'url_id' : self . id }, conn = conn , engine = engine , debug = debug ) del_result = delete_from_table ( 'url' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.fetch_by_id","text":"fetch_by_id ( url_id , conn = None , engine = None , debug = False ) Fetch URL from database by ID. Parameters: url_id ( int ) \u2013 ID of the URL to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: URL \u2013 The fetched URL object. Source code in globalbiodata/url.py 111 112 113 114 115 116 117 118 119 120 121 122 123 def fetch_by_id ( url_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> URL : \"\"\"Fetch URL from database by ID. Args: url_id (int): ID of the URL to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object. \"\"\" return fetch_url ({ 'id' : url_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_id"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.fetch_by_url","text":"fetch_by_url ( url , conn = None , engine = None , debug = False ) Fetch URL from database by URL string. Parameters: url ( str ) \u2013 URL string to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ URL ] \u2013 The fetched URL object if one result, else list of URLs, else None . Source code in globalbiodata/url.py 125 126 127 128 129 130 131 132 133 134 135 136 137 def fetch_by_url ( url : str , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL from database by URL string. Args: url (str): URL string to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched URL object if one result, else list of URLs, else `None`. \"\"\" return fetch_url ({ 'url' : url }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_url"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.is_online","text":"is_online () Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: bool \u2013 True if URL is online, False otherwise. Source code in globalbiodata/url.py 156 157 158 159 160 161 162 163 def is_online ( self ) -> bool : \"\"\"Return boolean describing whether URL is online based on latest ConnectionStatus. Returns: `True` if URL is online, `False` otherwise. \"\"\" latest_status = self . latest_connection_status () return True if ( latest_status and latest_status . is_online ) else False","title":"is_online"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.latest_connection_status","text":"latest_connection_status () Get the latest ConnectionStatus object for this URL. Returns: ConnectionStatus \u2013 The latest ConnectionStatus object or None if not found. Source code in globalbiodata/url.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def latest_connection_status ( self ) -> ConnectionStatus : \"\"\"Get the latest ConnectionStatus object for this URL. Returns: The latest ConnectionStatus object or `None` if not found. \"\"\" if not self . status or len ( self . status ) == 0 : return None latest_status = self . status [ 0 ] if latest_status . is_latest != 1 : for s in self . status : if s . is_latest == 1 : latest_status = s break return latest_status","title":"latest_connection_status"},{"location":"api/globalbiodata_url/#globalbiodata.url.URL.write","text":"write ( conn = None , engine = None , debug = False ) Write URL to database along with associated ConnectionStatus data. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the URL written to the database. Source code in globalbiodata/url.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write URL to database along with associated ConnectionStatus data. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the URL written to the database. \"\"\" conn_statuses = self . status d = self . __dict__ del d [ 'status' ] new_url_id = insert_into_table ( 'url' , d , conn = conn , engine = engine , debug = debug ) self . id = new_url_id for c in conn_statuses : c . url_id = self . id c . write ( conn = conn , engine = engine , debug = debug ) self . status = conn_statuses return self . id","title":"write"},{"location":"api/globalbiodata_utils/","text":"Object fetcher methods globalbiodata.utils_fetch fetch_accession fetch_accession ( query , expanded = False , conn = None , engine = None , debug = False , ) Fetch Accession(es) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. expanded ( bool , default: False ) \u2013 If True , fetch associated resource, version, and publications. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 list of Accession objects if found, else None . Source code in globalbiodata/utils_fetch.py 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def fetch_accession ( query : dict , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Accession(es) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. expanded (bool, optional): If `True`, fetch associated resource, version, and publications. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: list of Accession objects if found, else `None`. \"\"\" from .accession import Accession # join accession and accession_publication tables to get publication IDs order_by = [ \"accession_resource_id\" , \"accession_accession\" ] formatted_query = { f \"accession_publication_ { k } \" if k == 'publication_id' else f \"accession_ { k } \" : v for k , v in query . items () if v is not None } accession_raw = select_from_table ( 'accession' , formatted_query , join_table = 'accession_publication' , order_by = order_by , conn = conn , engine = engine , debug = debug ) # format column names to remove table prefixes added by sqlalchemy join accession_results = [] for a in accession_raw : af = { re . sub ( '^accession_publication_' , '' , k ): v for k , v in a . items ()} af = { re . sub ( '^accession_' , '' , k ): v for k , v in af . items ()} accession_results . append ( af ) if len ( accession_results ) == 0 : return None # group by accession to combine multiple publications grouped_accessions = {} for a in accession_results : if a [ 'accession' ] not in grouped_accessions : grouped_accessions [ a [ 'accession' ]] = { 'version_id' : a [ 'version_id' ], 'resource_id' : a [ 'resource_id' ], 'publications' : set (), 'url' : a [ 'url' ], 'additional_metadata' : a [ 'prediction_metadata' ] } grouped_accessions [ a [ 'accession' ]][ 'publications' ] . add ( a [ 'publication_id' ]) sorted_accessions = sorted ( grouped_accessions . keys ()) # sort for consistent order (important for testing) # build component objects accessions = [] for a in sorted_accessions : a_obj = { 'accession' : a , 'publications' : [] } a_obj [ 'resource' ] = fetch_resource ({ 'id' : grouped_accessions [ a ][ 'resource_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) a_obj [ 'version' ] = fetch_version ({ 'id' : grouped_accessions [ a ][ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) a_obj [ 'publications' ] = fetch_publication ({ 'id' : list ( grouped_accessions [ a ][ 'publications' ])}, expanded = expanded , conn = conn , engine = engine , debug = debug ) a_obj [ 'publications' ] = [ a_obj [ 'publications' ]] if type ( a_obj [ 'publications' ]) is not list else a_obj [ 'publications' ] accessions . append ( Accession ( a_obj )) return accessions fetch_all_connection_statuses fetch_all_connection_statuses ( order_by = \"url_id\" , conn = None , engine = None , debug = False ) Fetch all ConnectionStatuses from the database. Parameters: order_by ( str , default: 'url_id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of ConnectionStatus objects. Source code in globalbiodata/utils_fetch.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def fetch_all_connection_statuses ( order_by : str = 'url_id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all ConnectionStatuses from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of ConnectionStatus objects. \"\"\" return fetch_connection_status ({}, order_by = order_by , conn = conn , engine = engine , debug = debug ) fetch_all_grant_agencies fetch_all_grant_agencies ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all GrantAgencies from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of GrantAgency objects. Source code in globalbiodata/utils_fetch.py 327 328 329 330 331 332 333 334 335 336 337 338 339 def fetch_all_grant_agencies ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all GrantAgencies from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of GrantAgency objects. \"\"\" return fetch_grant_agency ({}, order_by = order_by , conn = conn , engine = engine , debug = debug ) fetch_all_grants fetch_all_grants ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all Grants from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Grant objects. Source code in globalbiodata/utils_fetch.py 290 291 292 293 294 295 296 297 298 299 300 301 302 def fetch_all_grants ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Grants from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Grant objects. \"\"\" return fetch_grant ({}, order_by = order_by , conn = conn , engine = engine , debug = debug ) fetch_all_online_resources fetch_all_online_resources ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Resources from the database where online status is true. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of online Resource objects. Source code in globalbiodata/utils_fetch.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def fetch_all_online_resources ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Resources from the database where online status is true. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of online Resource objects. \"\"\" full_list = fetch_all_resources ( order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug ) return [ r for r in full_list if r . is_online ()] fetch_all_publications fetch_all_publications ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Publications from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Publication objects. Source code in globalbiodata/utils_fetch.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def fetch_all_publications ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Publications from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Publication objects. \"\"\" return fetch_publication ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_all_resources fetch_all_resources ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Resources from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Resource objects. Source code in globalbiodata/utils_fetch.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def fetch_all_resources ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Resources from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Resource objects. \"\"\" return fetch_resource ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_all_urls fetch_all_urls ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all URLs from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated connection status. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of URL objects. Source code in globalbiodata/utils_fetch.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def fetch_all_urls ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all URLs from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated connection status. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of URL objects. \"\"\" return fetch_url ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug ) fetch_all_versions fetch_all_versions ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all Versions from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Version objects. Source code in globalbiodata/utils_fetch.py 199 200 201 202 203 204 205 206 207 208 209 210 211 def fetch_all_versions ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Versions from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Version objects. \"\"\" return fetch_version ({}, order_by = order_by , conn = conn , engine = engine , debug = debug ) fetch_connection_status fetch_connection_status ( query , order_by = \"url_id\" , conn = None , engine = None , debug = False , ) Fetch ConnectionStatus(es) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'url_id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ ConnectionStatus ] \u2013 single ConnectionStatus object (where single result if found), or list of ConnectionStatus objects if found, else None . Source code in globalbiodata/utils_fetch.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def fetch_connection_status ( query : dict , order_by : str = 'url_id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ ConnectionStatus ]: \"\"\"Fetch ConnectionStatus(es) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single ConnectionStatus object (where single result if found), or list of ConnectionStatus objects if found, else `None`. \"\"\" from .url import ConnectionStatus status_raw = select_from_table ( 'connection_status' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( status_raw ) == 0 : return None conn_stats = [ ConnectionStatus ( cs ) for cs in status_raw ] return conn_stats if len ( conn_stats ) > 1 else conn_stats [ 0 ] fetch_grant fetch_grant ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch Grant(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Grant ] \u2013 single Grant object (where single result if found), or list of Grant objects if found, else None . Source code in globalbiodata/utils_fetch.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 def fetch_grant ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Grant ]: \"\"\"Fetch Grant(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Grant object (where single result if found), or list of Grant objects if found, else `None`. \"\"\" from .grant import Grant grant_raw = select_from_table ( 'grant' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( grant_raw ) == 0 : return None grants = [] for g in grant_raw : g [ 'grant_agency' ] = fetch_grant_agency ({ 'id' : g [ 'grant_agency_id' ]}, conn = conn , engine = engine , debug = debug ) grants . append ( Grant ( g )) return grants if len ( grants ) > 1 else grants [ 0 ] fetch_grant_agency fetch_grant_agency ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch GrantAgency(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ GrantAgency ] \u2013 single GrantAgency object (where single result if found), or list of GrantAgency objects if found, else None . Source code in globalbiodata/utils_fetch.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 def fetch_grant_agency ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ GrantAgency ]: \"\"\"Fetch GrantAgency(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single GrantAgency object (where single result if found), or list of GrantAgency objects if found, else `None`. \"\"\" from .grant import GrantAgency grant_agency_raw = select_from_table ( 'grant_agency' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( grant_agency_raw ) == 0 : return None grant_agencies = [ GrantAgency ( ga ) for ga in grant_agency_raw ] return grant_agencies if len ( grant_agencies ) > 1 else grant_agencies [ 0 ] fetch_publication fetch_publication ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch Publication(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Publication ] \u2013 single Publication object (where single result if found), or list of Publication objects if found, else None . Source code in globalbiodata/utils_fetch.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def fetch_publication ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Publication ]: \"\"\"Fetch Publication(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Publication object (where single result if found), or list of Publication objects if found, else `None`. \"\"\" from .publication import Publication publication_raw = select_from_table ( 'publication' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( publication_raw ) == 0 : return None publications = [] for p in publication_raw : if expanded : grant_ids = select_from_table ( 'publication_grant' , { 'publication_id' : p [ 'id' ]}, conn = conn , engine = engine , debug = debug ) p [ 'grants' ] = fetch_grant ({ 'id' :[ g [ 'grant_id' ] for g in grant_ids ]}, conn = conn , engine = engine , debug = debug ) p [ 'grants' ] = [ p [ 'grants' ]] if ( p [ 'grants' ] is not None and type ( p [ 'grants' ]) is not list ) else p [ 'grants' ] else : p [ 'grants' ] = None p [ '__conn__' ] = conn p [ '__engine__' ] = engine publications . append ( Publication ( p )) return publications if len ( publications ) > 1 else publications [ 0 ] fetch_resource fetch_resource ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch Resource(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Resource ] \u2013 single Resource object (where single result if found), or list of Resource objects if found, else None . Source code in globalbiodata/utils_fetch.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def fetch_resource ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Resource ]: \"\"\"Fetch Resource(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Resource object (where single result if found), or list of Resource objects if found, else `None`. \"\"\" from .resource import Resource resource_raw = select_from_table ( 'resource' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( resource_raw ) == 0 : return None resources = [] for r in resource_raw : r [ 'url' ] = fetch_url ({ 'id' : r [ 'url_id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'version' ] = fetch_version ({ 'id' : r [ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) if expanded : pub_ids = select_from_table ( 'resource_publication' , { 'resource_id' : r [ 'id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'publications' ] = fetch_publication ({ 'id' :[ p [ 'publication_id' ] for p in pub_ids ]}, conn = conn , engine = engine , debug = debug ) r [ 'publications' ] = [ r [ 'publications' ]] if type ( r [ 'publications' ]) is not list else r [ 'publications' ] grant_ids = select_from_table ( 'resource_grant' , { 'resource_id' : r [ 'id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'grants' ] = fetch_grant ({ 'id' :[ g [ 'grant_id' ] for g in grant_ids ]}, conn = conn , engine = engine , debug = debug ) r [ 'grants' ] = [ r [ 'grants' ]] if ( r [ 'grants' ] is not None and type ( r [ 'grants' ]) is not list ) else r [ 'grants' ] r [ '__conn__' ] = conn r [ '__engine__' ] = engine resources . append ( Resource ( r )) return resources if len ( resources ) > 1 else resources [ 0 ] fetch_resource_mention fetch_resource_mention ( query , expanded = True , conn = None , engine = None , debug = False , ) Fetch ResourceMention(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. expanded ( bool , default: True ) \u2013 If True , fetch associated resource, version, and publication. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 list of ResourceMention objects if found, else None . Source code in globalbiodata/utils_fetch.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 def fetch_resource_mention ( query : dict , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch ResourceMention(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. expanded (bool, optional): If `True`, fetch associated resource, version, and publication. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: list of ResourceMention objects if found, else `None`. \"\"\" from .resource_mention import ResourceMention , MatchedAlias order_by = [ 'publication_id' , 'resource_id' , 'match_count' ] mention_raw = select_from_table ( 'resource_mention' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( mention_raw ) == 0 : return None # group by publication_id, resource_id, version_id to aggregate matched_aliases mentions_grouped = {} group_order = set () for m in mention_raw : m [ 'mean_confidence' ] = float ( m [ 'mean_confidence' ]) m [ 'match_count' ] = int ( m [ 'match_count' ]) key = ( m [ 'publication_id' ], m [ 'resource_id' ], m [ 'version_id' ]) group_order . add ( key ) if key not in mentions_grouped : mentions_grouped [ key ] = { 'publication_id' : m [ 'publication_id' ], 'resource_id' : m [ 'resource_id' ], 'version_id' : m [ 'version_id' ], 'matched_aliases' : [], } mentions_grouped [ key ][ 'matched_aliases' ] . append ( MatchedAlias ({ 'matched_alias' : m [ 'matched_alias' ], 'match_count' : m [ 'match_count' ], 'mean_confidence' : m [ 'mean_confidence' ] })) for k in mentions_grouped : this_group_match_count , this_group_conf_sum , this_group_conf_n = 0 , 0.0 , 0 for ma in mentions_grouped [ k ][ 'matched_aliases' ]: this_group_match_count += ma . match_count this_group_conf_sum += ma . mean_confidence this_group_conf_n += 1 mentions_grouped [ k ][ 'match_count' ] = this_group_match_count mentions_grouped [ k ][ 'mean_confidence' ] = ( this_group_conf_sum / this_group_conf_n ) if this_group_conf_n > 0 else 0.0 # build component objects mentions = [] cache = {} for group_key in group_order : m = mentions_grouped [ group_key ] m_obj = {} if f \"pub: { m [ 'publication_id' ] } \" in cache : m_obj [ 'publication' ] = cache [ f \"pub: { m [ 'publication_id' ] } \" ] else : m_obj [ 'publication' ] = fetch_publication ({ 'id' : m [ 'publication_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) cache [ f \"pub: { m [ 'publication_id' ] } \" ] = m_obj [ 'publication' ] if f \"res: { m [ 'resource_id' ] } \" in cache : m_obj [ 'resource' ] = cache [ f \"res: { m [ 'resource_id' ] } \" ] else : m_obj [ 'resource' ] = fetch_resource ({ 'id' : m [ 'resource_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) cache [ f \"res: { m [ 'resource_id' ] } \" ] = m_obj [ 'resource' ] if f \"ver: { m [ 'version_id' ] } \" in cache : m_obj [ 'version' ] = cache [ f \"ver: { m [ 'version_id' ] } \" ] else : m_obj [ 'version' ] = fetch_version ({ 'id' : m [ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) cache [ f \"ver: { m [ 'version_id' ] } \" ] = m_obj [ 'version' ] m_obj [ 'matched_aliases' ] = m [ 'matched_aliases' ][:: - 1 ] # reverse order to have highest count first m_obj [ 'match_count' ] = m [ 'match_count' ] m_obj [ 'mean_confidence' ] = m [ 'mean_confidence' ] mentions . append ( ResourceMention ( m_obj )) return mentions fetch_url fetch_url ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch URL(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated connection status. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ URL ] \u2013 single URL object (where single result if found), or list of URL objects if found, else None . Source code in globalbiodata/utils_fetch.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def fetch_url ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated connection status. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single URL object (where single result if found), or list of URL objects if found, else `None`. \"\"\" from .url import URL url_raw = select_from_table ( 'url' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( url_raw ) == 0 : return None urls = [] for u in url_raw : if expanded : u [ 'status' ] = fetch_connection_status ({ 'url_id' : u [ 'id' ]}, order_by = [ 'is_latest' , 'date' ], conn = conn , engine = engine , debug = debug ) u [ 'status' ] = [ u [ 'status' ]] if ( u [ 'status' ] is not None and type ( u [ 'status' ]) is not list ) else u [ 'status' ] u [ 'status' ] = u [ 'status' ][:: - 1 ] # reverse order to have latest first urls . append ( URL ( u )) return urls if len ( urls ) > 1 else urls [ 0 ] fetch_version fetch_version ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch Version(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Version ] \u2013 single Version object (where single result if found), or list of Version objects if found, else None . Source code in globalbiodata/utils_fetch.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def fetch_version ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Version ]: \"\"\"Fetch Version(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Version object (where single result if found), or list of Version objects if found, else `None`. \"\"\" from .version import Version version_raw = select_from_table ( 'version' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( version_raw ) == 0 : return None versions = [ Version ( p ) for p in version_raw ] return versions if len ( versions ) > 1 else versions [ 0 ] Generic database interactors globalbiodata.utils_db delete_from_table delete_from_table ( table_name , data , conn = None , engine = None , debug = False ) Delete rows from a table matching the provided data. Parameters: table_name ( str ) \u2013 Name of the table to delete from. data ( dict ) \u2013 Dictionary of column names and values to match for deletion. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/utils_db.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 def delete_from_table ( table_name : str , data : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete rows from a table matching the provided data. Args: table_name (str): Name of the table to delete from. data (dict): Dictionary of column names and values to match for deletion. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" metadata_obj = db . MetaData () conn_created = False if conn is None : if engine is None : raise ValueError ( \"select_from_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect the table using the active connection table = db . Table ( table_name , metadata_obj , autoload_with = conn ) data = _stringify_data ( data ) if debug : print ( f \" \\n --> Deleting from table: { table_name } WHERE:\" ) print ( ' AND ' . join ([ f \" { k } == { data [ k ] } \" for k in data . keys ()])) trans = conn . begin () if not conn . in_transaction () else None # Begin a transaction if we're not already in one try : wheres = [ table . columns . get ( c ) == data [ c ] for c in data . keys ()] del_result = conn . execute ( db . delete ( table ) . where ( db . and_ ( * wheres ))) if debug : print ( f \"Deleted { del_result . rowcount } rows.\" ) trans . commit () # Commit the transaction except Exception as e : if trans : trans . rollback () # Rollback the transaction if an error occurs sys . stderr . write ( f \"Transaction rolled back due to: { e } \\n \" ) raise finally : if conn_created : conn . close () # Close the connection return del_result . rowcount insert_into_table insert_into_table ( table_name , data , conn = None , engine = None , debug = False , filter_long_data = False , retry_on_deadlock = True , max_retries = 5 , base_delay = 0.2 , ) Insert-or-update a row and return its id. Parameters: table_name ( str ) \u2013 Name of the table to insert into. data ( dict ) \u2013 Dictionary of column names and values to insert. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. filter_long_data ( bool , default: False ) \u2013 If True , move overlength strings to long_text table. retry_on_deadlock ( bool , default: True ) \u2013 If True , retry on deadlock errors. max_retries ( int , default: 5 ) \u2013 Maximum number of retries on deadlock. base_delay ( float , default: 0.2 ) \u2013 Base delay in seconds for exponential backoff. Returns: int \u2013 The ID/PK of the inserted or updated row. Source code in globalbiodata/utils_db.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def insert_into_table ( table_name : str , data : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , filter_long_data : bool = False , retry_on_deadlock : bool = True , max_retries : int = 5 , base_delay : float = 0.2 , ) -> int : \"\"\"Insert-or-update a row and return its id. Args: table_name (str): Name of the table to insert into. data (dict): Dictionary of column names and values to insert. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. filter_long_data (bool, optional): If `True`, move overlength strings to long_text table. retry_on_deadlock (bool, optional): If `True`, retry on deadlock errors. max_retries (int, optional): Maximum number of retries on deadlock. base_delay (float, optional): Base delay in seconds for exponential backoff. Returns: The ID/PK of the inserted or updated row. \"\"\" metadata_obj = db . MetaData () conn_created = False if conn is None : if engine is None : raise ValueError ( \"insert_into_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect the table using the ENGINE (separate pooled connection) to avoid # starting an implicit transaction on our working connection. table = db . Table ( table_name , metadata_obj , autoload_with = conn ) pk_cols = _get_primary_keys ( table , conn ) data = _stringify_data ( data ) if debug : print ( f \" \\n --> Inserting into table: { table_name } \" ) print ( data ) print ( f \"Columns: { ', ' . join ( table . columns . keys ()) } \" ) print ( f \"Primary keys: { ', ' . join ( pk_cols ) } \" ) # Optionally move overlength strings to long_text and replace with reference token if filter_long_data : for k , v in list ( data . items ()): this_max_len = _get_max_len ( k , table_name , conn = conn , engine = engine ) if v and this_max_len and isinstance ( v , str ) and len ( v ) > this_max_len : longtext_id = insert_into_table ( 'long_text' , { 'text' : v }, conn = conn , engine = engine , debug = debug ) data [ k ] = f \"long_text( { longtext_id } )\" # We \"own\" the transaction if we opened this connection in this function. # Reflection above may have triggered an implicit txn elsewhere; don't let that # disable retries. We manage our own explicit txn when we created the conn. own_txn = conn_created # print(f\"conn_created={conn_created}, own_txn={own_txn}, conn.in_transaction()={conn.in_transaction()}\") # Retry loop only if we control our own transaction attempts = 0 while True : attempts += 1 # If we own the connection, start an explicit transaction only if one isn't already active implicit_txn = conn . in_transaction () trans = conn . begin () if ( own_txn and not implicit_txn ) else None try : insert_stmt = insert ( table ) . values ( data ) data_no_pks = _remove_key_fields ( table , conn , data ) if data_no_pks : # typical path: upsert (ON DUPLICATE KEY UPDATE) if pk_cols and len ( pk_cols ) == 1 : # single primary key: use LAST_INSERT_ID() hack to get the id of existing row if no insert occurred pk_name = pk_cols [ 0 ] data_no_pks [ pk_name ] = db . func . last_insert_id ( table . c [ pk_name ]) do_update_stmt = insert_stmt . on_duplicate_key_update ( ** data_no_pks ) if debug : print ( f \"Updating { table_name } with data: { data_no_pks } \" ) result = conn . execute ( do_update_stmt ) else : # tables that are pure key rows result = conn . execute ( insert_stmt . prefix_with ( 'IGNORE' )) if trans is not None : trans . commit () elif own_txn and implicit_txn and conn . in_transaction (): # We own the connection and were already in an implicit txn (likely started by prior metadata queries) conn . commit () inserted_pk = result . inserted_primary_key [ 0 ] if result . inserted_primary_key else None affected_rows = result . rowcount # Determine the resulting id to return if ( not inserted_pk ) or ( inserted_pk and affected_rows == 0 ): # entity existed and was not updated existing_id = conn . execute ( db . text ( \"SELECT LAST_INSERT_ID()\" )) . scalar () if len ( pk_cols ) == 1 else _fetch_id_from_unique_keys ( table , data , conn , debug = debug ) if debug : print ( f \"Entity already exists. Fetched id: { existing_id } \" ) this_id = existing_id elif ( inserted_pk and affected_rows > 1 ): # entity existed and was updated (MySQL reports >1 affected rows on upsert-update) this_id = inserted_pk if debug : print ( f \"Entity already exists. Updated id: { this_id } \" ) else : this_id = inserted_pk if debug : print ( f \"New entity added. Inserted id: { this_id } \" ) # Success; break retry loop break except OperationalError as e : # MySQL deadlock / lock wait timeout codes code = None try : code = e . orig . args [ 0 ] except Exception : pass if trans is not None : try : trans . rollback () except Exception : pass elif own_txn and conn . in_transaction (): try : conn . rollback () except Exception : pass # If we don't own the transaction or retries disabled, re-raise immediately if not own_txn or not retry_on_deadlock or code not in ( 1213 , 1205 ): raise # Backoff and retry (we own the txn) if attempts > max_retries : raise # Exponential backoff with jitter delay = ( base_delay * ( 2 ** ( attempts - 1 ))) * ( 1 + 0.25 * random . random ()) if debug : sys . stderr . write ( f \"[retry] { table_name } : OperationalError { code } ; attempt { attempts } / { max_retries } ; sleeping { delay : .2f } s \\n \" ) time . sleep ( delay ) continue except Exception as e : if trans is not None : try : trans . rollback () except Exception : pass elif own_txn and conn . in_transaction (): try : conn . rollback () except Exception : pass sys . stderr . write ( f \"Transaction rolled back due to: { e } \\n \" ) raise finally : if conn_created and own_txn and not conn . closed : # keep connection open for caller if they provided it; otherwise close at end pass if conn_created : conn . close () return this_id select_from_table select_from_table ( table_name , data = {}, join_table = None , order_by = None , conn = None , engine = None , debug = False , ) Select rows from a table matching the provided data. Parameters: table_name ( str ) \u2013 Name of the table to select from. data ( dict , default: {} ) \u2013 Dictionary of column names and values to match for selection. join_table ( str , default: None ) \u2013 Name of a table to join with. order_by ( list , default: None ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of dictionaries representing the selected rows. Source code in globalbiodata/utils_db.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def select_from_table ( table_name : str , data : dict = {}, join_table : str = None , order_by : list = None , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Select rows from a table matching the provided data. Args: table_name (str): Name of the table to select from. data (dict, optional): Dictionary of column names and values to match for selection. join_table (str, optional): Name of a table to join with. order_by (list, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of dictionaries representing the selected rows. \"\"\" metadata_obj = db . MetaData () # Ensure we have a live connection before reflecting conn_created = False if conn is None : if engine is None : raise ValueError ( \"select_from_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect using the active connection (works in SA 1.4/2.0) table = db . Table ( table_name , metadata_obj , autoload_with = conn ) if join_table : join_tbl = db . Table ( join_table , metadata_obj , autoload_with = conn ) table = table . join ( join_tbl ) # print(\"JOINED TABLE COLUMNS:\", table.columns.keys()) if debug : print ( f \" \\n --> Selecting from table: { table_name } WHERE:\" ) print ( 'AND ' . join ([ f \" { k } == ' { data [ k ] } '\" for k in data . keys ()])) wheres = [ table . columns . get ( c ) . in_ ( data [ c ]) if isinstance ( data [ c ], list ) else table . columns . get ( c ) == data [ c ] for c in data ] # construct select statement with correct options stmt = db . select ( table ) if wheres : stmt = stmt . where ( db . and_ ( * wheres )) if order_by : if isinstance ( order_by , list ): order_cols = [ table . columns . get ( col ) for col in order_by if table . columns . get ( col ) is not None ] if order_cols : stmt = stmt . order_by ( * order_cols ) else : order_col = table . columns . get ( order_by ) if order_col is not None : stmt = stmt . order_by ( order_col ) result = conn . execute ( stmt ) . fetchall () # convert result to list of dicts d_result = [ dict ( zip ( table . columns . keys (), list ( r ))) for r in result ] if conn_created : conn . close () return d_result Other utility methods globalbiodata.utils extract_fields_by_type extract_fields_by_type ( data , type_prefix ) Extract fields from a dictionary that start with a given prefix. Parameters: data ( dict ) \u2013 Input dictionary. type_prefix ( str ) \u2013 Prefix to filter keys. Returns: dict \u2013 Dictionary with extracted fields. Source code in globalbiodata/utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def extract_fields_by_type ( data : dict , type_prefix : str ) -> dict : \"\"\"Extract fields from a dictionary that start with a given prefix. Args: data (dict): Input dictionary. type_prefix (str): Prefix to filter keys. Returns: Dictionary with extracted fields. \"\"\" extracted = {} for k , v in data . items (): if k . startswith ( f \" { type_prefix } _\" ): extracted [ re . sub ( f \"^ { type_prefix } _\" , \"\" , k )] = v return extracted new_publication_from_EuropePMC_result new_publication_from_EuropePMC_result ( epmc_result , google_maps_api_key = None ) Create a new Publication object from an EuropePMC search result, including additional geographic metadata enrichment. Parameters: epmc_result ( dict ) \u2013 EuropePMC search result metadata. google_maps_api_key ( str , default: None ) \u2013 Google Maps API key for advanced geolocation. Returns: Publication \u2013 New Publication object. Source code in globalbiodata/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def new_publication_from_EuropePMC_result ( epmc_result : dict , google_maps_api_key : str = None ) -> Publication : \"\"\"Create a new Publication object from an EuropePMC search result, including additional geographic metadata enrichment. Args: epmc_result (dict): EuropePMC search result metadata. google_maps_api_key (str, optional): Google Maps API key for advanced geolocation. Returns: New Publication object. \"\"\" print ( f \"Creating new Publication from EuropePMC result: { epmc_result . get ( 'title' , '' ) } (PMID: { epmc_result . get ( 'pmid' , '' ) } )\" ) print ( \"Searching for author affiliations and countries...\" ) affiliations , countries = _extract_affiliations ( epmc_result , google_maps_api_key = google_maps_api_key ) print ( f \" Found countries: { ', ' . join ( countries ) if countries else 'None found' } \" ) new_publication = Publication ({ 'publication_title' : epmc_result . get ( 'title' , '' ), 'pubmed_id' : epmc_result . get ( 'pmid' , None ), 'pmc_id' : epmc_result . get ( 'pmcid' , '' ), 'publication_date' : epmc_result . get ( 'journalInfo' , {}) . get ( 'printPublicationDate' ) or epmc_result . get ( 'firstPublicationDate' ), 'grants' : _extract_grants ( epmc_result ), 'keywords' : '; ' . join ( _extract_keywords ( epmc_result )), 'citation_count' : epmc_result . get ( 'citedByCount' , 0 ), 'authors' : epmc_result . get ( 'authorString' , '' ), 'affiliation' : affiliations , 'affiliation_countries' : countries }) return new_publication","title":"Utilities"},{"location":"api/globalbiodata_utils/#object-fetcher-methods","text":"","title":"Object fetcher methods"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch","text":"","title":"utils_fetch"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_accession","text":"fetch_accession ( query , expanded = False , conn = None , engine = None , debug = False , ) Fetch Accession(es) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. expanded ( bool , default: False ) \u2013 If True , fetch associated resource, version, and publications. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 list of Accession objects if found, else None . Source code in globalbiodata/utils_fetch.py 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def fetch_accession ( query : dict , expanded : bool = False , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch Accession(es) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. expanded (bool, optional): If `True`, fetch associated resource, version, and publications. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: list of Accession objects if found, else `None`. \"\"\" from .accession import Accession # join accession and accession_publication tables to get publication IDs order_by = [ \"accession_resource_id\" , \"accession_accession\" ] formatted_query = { f \"accession_publication_ { k } \" if k == 'publication_id' else f \"accession_ { k } \" : v for k , v in query . items () if v is not None } accession_raw = select_from_table ( 'accession' , formatted_query , join_table = 'accession_publication' , order_by = order_by , conn = conn , engine = engine , debug = debug ) # format column names to remove table prefixes added by sqlalchemy join accession_results = [] for a in accession_raw : af = { re . sub ( '^accession_publication_' , '' , k ): v for k , v in a . items ()} af = { re . sub ( '^accession_' , '' , k ): v for k , v in af . items ()} accession_results . append ( af ) if len ( accession_results ) == 0 : return None # group by accession to combine multiple publications grouped_accessions = {} for a in accession_results : if a [ 'accession' ] not in grouped_accessions : grouped_accessions [ a [ 'accession' ]] = { 'version_id' : a [ 'version_id' ], 'resource_id' : a [ 'resource_id' ], 'publications' : set (), 'url' : a [ 'url' ], 'additional_metadata' : a [ 'prediction_metadata' ] } grouped_accessions [ a [ 'accession' ]][ 'publications' ] . add ( a [ 'publication_id' ]) sorted_accessions = sorted ( grouped_accessions . keys ()) # sort for consistent order (important for testing) # build component objects accessions = [] for a in sorted_accessions : a_obj = { 'accession' : a , 'publications' : [] } a_obj [ 'resource' ] = fetch_resource ({ 'id' : grouped_accessions [ a ][ 'resource_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) a_obj [ 'version' ] = fetch_version ({ 'id' : grouped_accessions [ a ][ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) a_obj [ 'publications' ] = fetch_publication ({ 'id' : list ( grouped_accessions [ a ][ 'publications' ])}, expanded = expanded , conn = conn , engine = engine , debug = debug ) a_obj [ 'publications' ] = [ a_obj [ 'publications' ]] if type ( a_obj [ 'publications' ]) is not list else a_obj [ 'publications' ] accessions . append ( Accession ( a_obj )) return accessions","title":"fetch_accession"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_connection_statuses","text":"fetch_all_connection_statuses ( order_by = \"url_id\" , conn = None , engine = None , debug = False ) Fetch all ConnectionStatuses from the database. Parameters: order_by ( str , default: 'url_id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of ConnectionStatus objects. Source code in globalbiodata/utils_fetch.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def fetch_all_connection_statuses ( order_by : str = 'url_id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all ConnectionStatuses from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of ConnectionStatus objects. \"\"\" return fetch_connection_status ({}, order_by = order_by , conn = conn , engine = engine , debug = debug )","title":"fetch_all_connection_statuses"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_grant_agencies","text":"fetch_all_grant_agencies ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all GrantAgencies from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of GrantAgency objects. Source code in globalbiodata/utils_fetch.py 327 328 329 330 331 332 333 334 335 336 337 338 339 def fetch_all_grant_agencies ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all GrantAgencies from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of GrantAgency objects. \"\"\" return fetch_grant_agency ({}, order_by = order_by , conn = conn , engine = engine , debug = debug )","title":"fetch_all_grant_agencies"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_grants","text":"fetch_all_grants ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all Grants from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Grant objects. Source code in globalbiodata/utils_fetch.py 290 291 292 293 294 295 296 297 298 299 300 301 302 def fetch_all_grants ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Grants from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Grant objects. \"\"\" return fetch_grant ({}, order_by = order_by , conn = conn , engine = engine , debug = debug )","title":"fetch_all_grants"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_online_resources","text":"fetch_all_online_resources ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Resources from the database where online status is true. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of online Resource objects. Source code in globalbiodata/utils_fetch.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def fetch_all_online_resources ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Resources from the database where online status is true. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of online Resource objects. \"\"\" full_list = fetch_all_resources ( order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug ) return [ r for r in full_list if r . is_online ()]","title":"fetch_all_online_resources"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_publications","text":"fetch_all_publications ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Publications from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Publication objects. Source code in globalbiodata/utils_fetch.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def fetch_all_publications ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Publications from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Publication objects. \"\"\" return fetch_publication ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_all_publications"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_resources","text":"fetch_all_resources ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all Resources from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Resource objects. Source code in globalbiodata/utils_fetch.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def fetch_all_resources ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Resources from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Resource objects. \"\"\" return fetch_resource ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_all_resources"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_urls","text":"fetch_all_urls ( order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch all URLs from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated connection status. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of URL objects. Source code in globalbiodata/utils_fetch.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def fetch_all_urls ( order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all URLs from the database. Args: order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated connection status. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of URL objects. \"\"\" return fetch_url ({}, order_by = order_by , expanded = expanded , conn = conn , engine = engine , debug = debug )","title":"fetch_all_urls"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_all_versions","text":"fetch_all_versions ( order_by = \"id\" , conn = None , engine = None , debug = False ) Fetch all Versions from the database. Parameters: order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of Version objects. Source code in globalbiodata/utils_fetch.py 199 200 201 202 203 204 205 206 207 208 209 210 211 def fetch_all_versions ( order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Fetch all Versions from the database. Args: order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of Version objects. \"\"\" return fetch_version ({}, order_by = order_by , conn = conn , engine = engine , debug = debug )","title":"fetch_all_versions"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_connection_status","text":"fetch_connection_status ( query , order_by = \"url_id\" , conn = None , engine = None , debug = False , ) Fetch ConnectionStatus(es) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'url_id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ ConnectionStatus ] \u2013 single ConnectionStatus object (where single result if found), or list of ConnectionStatus objects if found, else None . Source code in globalbiodata/utils_fetch.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def fetch_connection_status ( query : dict , order_by : str = 'url_id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ ConnectionStatus ]: \"\"\"Fetch ConnectionStatus(es) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single ConnectionStatus object (where single result if found), or list of ConnectionStatus objects if found, else `None`. \"\"\" from .url import ConnectionStatus status_raw = select_from_table ( 'connection_status' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( status_raw ) == 0 : return None conn_stats = [ ConnectionStatus ( cs ) for cs in status_raw ] return conn_stats if len ( conn_stats ) > 1 else conn_stats [ 0 ]","title":"fetch_connection_status"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_grant","text":"fetch_grant ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch Grant(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Grant ] \u2013 single Grant object (where single result if found), or list of Grant objects if found, else None . Source code in globalbiodata/utils_fetch.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 def fetch_grant ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Grant ]: \"\"\"Fetch Grant(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Grant object (where single result if found), or list of Grant objects if found, else `None`. \"\"\" from .grant import Grant grant_raw = select_from_table ( 'grant' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( grant_raw ) == 0 : return None grants = [] for g in grant_raw : g [ 'grant_agency' ] = fetch_grant_agency ({ 'id' : g [ 'grant_agency_id' ]}, conn = conn , engine = engine , debug = debug ) grants . append ( Grant ( g )) return grants if len ( grants ) > 1 else grants [ 0 ]","title":"fetch_grant"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_grant_agency","text":"fetch_grant_agency ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch GrantAgency(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ GrantAgency ] \u2013 single GrantAgency object (where single result if found), or list of GrantAgency objects if found, else None . Source code in globalbiodata/utils_fetch.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 def fetch_grant_agency ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ GrantAgency ]: \"\"\"Fetch GrantAgency(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single GrantAgency object (where single result if found), or list of GrantAgency objects if found, else `None`. \"\"\" from .grant import GrantAgency grant_agency_raw = select_from_table ( 'grant_agency' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( grant_agency_raw ) == 0 : return None grant_agencies = [ GrantAgency ( ga ) for ga in grant_agency_raw ] return grant_agencies if len ( grant_agencies ) > 1 else grant_agencies [ 0 ]","title":"fetch_grant_agency"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_publication","text":"fetch_publication ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch Publication(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Publication ] \u2013 single Publication object (where single result if found), or list of Publication objects if found, else None . Source code in globalbiodata/utils_fetch.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def fetch_publication ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Publication ]: \"\"\"Fetch Publication(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Publication object (where single result if found), or list of Publication objects if found, else `None`. \"\"\" from .publication import Publication publication_raw = select_from_table ( 'publication' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( publication_raw ) == 0 : return None publications = [] for p in publication_raw : if expanded : grant_ids = select_from_table ( 'publication_grant' , { 'publication_id' : p [ 'id' ]}, conn = conn , engine = engine , debug = debug ) p [ 'grants' ] = fetch_grant ({ 'id' :[ g [ 'grant_id' ] for g in grant_ids ]}, conn = conn , engine = engine , debug = debug ) p [ 'grants' ] = [ p [ 'grants' ]] if ( p [ 'grants' ] is not None and type ( p [ 'grants' ]) is not list ) else p [ 'grants' ] else : p [ 'grants' ] = None p [ '__conn__' ] = conn p [ '__engine__' ] = engine publications . append ( Publication ( p )) return publications if len ( publications ) > 1 else publications [ 0 ]","title":"fetch_publication"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_resource","text":"fetch_resource ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch Resource(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated publications and grants. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Resource ] \u2013 single Resource object (where single result if found), or list of Resource objects if found, else None . Source code in globalbiodata/utils_fetch.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def fetch_resource ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Resource ]: \"\"\"Fetch Resource(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated publications and grants. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Resource object (where single result if found), or list of Resource objects if found, else `None`. \"\"\" from .resource import Resource resource_raw = select_from_table ( 'resource' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( resource_raw ) == 0 : return None resources = [] for r in resource_raw : r [ 'url' ] = fetch_url ({ 'id' : r [ 'url_id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'version' ] = fetch_version ({ 'id' : r [ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) if expanded : pub_ids = select_from_table ( 'resource_publication' , { 'resource_id' : r [ 'id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'publications' ] = fetch_publication ({ 'id' :[ p [ 'publication_id' ] for p in pub_ids ]}, conn = conn , engine = engine , debug = debug ) r [ 'publications' ] = [ r [ 'publications' ]] if type ( r [ 'publications' ]) is not list else r [ 'publications' ] grant_ids = select_from_table ( 'resource_grant' , { 'resource_id' : r [ 'id' ]}, conn = conn , engine = engine , debug = debug ) r [ 'grants' ] = fetch_grant ({ 'id' :[ g [ 'grant_id' ] for g in grant_ids ]}, conn = conn , engine = engine , debug = debug ) r [ 'grants' ] = [ r [ 'grants' ]] if ( r [ 'grants' ] is not None and type ( r [ 'grants' ]) is not list ) else r [ 'grants' ] r [ '__conn__' ] = conn r [ '__engine__' ] = engine resources . append ( Resource ( r )) return resources if len ( resources ) > 1 else resources [ 0 ]","title":"fetch_resource"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_resource_mention","text":"fetch_resource_mention ( query , expanded = True , conn = None , engine = None , debug = False , ) Fetch ResourceMention(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. expanded ( bool , default: True ) \u2013 If True , fetch associated resource, version, and publication. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ list ] \u2013 list of ResourceMention objects if found, else None . Source code in globalbiodata/utils_fetch.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 def fetch_resource_mention ( query : dict , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ list ]: \"\"\"Fetch ResourceMention(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. expanded (bool, optional): If `True`, fetch associated resource, version, and publication. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: list of ResourceMention objects if found, else `None`. \"\"\" from .resource_mention import ResourceMention , MatchedAlias order_by = [ 'publication_id' , 'resource_id' , 'match_count' ] mention_raw = select_from_table ( 'resource_mention' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( mention_raw ) == 0 : return None # group by publication_id, resource_id, version_id to aggregate matched_aliases mentions_grouped = {} group_order = set () for m in mention_raw : m [ 'mean_confidence' ] = float ( m [ 'mean_confidence' ]) m [ 'match_count' ] = int ( m [ 'match_count' ]) key = ( m [ 'publication_id' ], m [ 'resource_id' ], m [ 'version_id' ]) group_order . add ( key ) if key not in mentions_grouped : mentions_grouped [ key ] = { 'publication_id' : m [ 'publication_id' ], 'resource_id' : m [ 'resource_id' ], 'version_id' : m [ 'version_id' ], 'matched_aliases' : [], } mentions_grouped [ key ][ 'matched_aliases' ] . append ( MatchedAlias ({ 'matched_alias' : m [ 'matched_alias' ], 'match_count' : m [ 'match_count' ], 'mean_confidence' : m [ 'mean_confidence' ] })) for k in mentions_grouped : this_group_match_count , this_group_conf_sum , this_group_conf_n = 0 , 0.0 , 0 for ma in mentions_grouped [ k ][ 'matched_aliases' ]: this_group_match_count += ma . match_count this_group_conf_sum += ma . mean_confidence this_group_conf_n += 1 mentions_grouped [ k ][ 'match_count' ] = this_group_match_count mentions_grouped [ k ][ 'mean_confidence' ] = ( this_group_conf_sum / this_group_conf_n ) if this_group_conf_n > 0 else 0.0 # build component objects mentions = [] cache = {} for group_key in group_order : m = mentions_grouped [ group_key ] m_obj = {} if f \"pub: { m [ 'publication_id' ] } \" in cache : m_obj [ 'publication' ] = cache [ f \"pub: { m [ 'publication_id' ] } \" ] else : m_obj [ 'publication' ] = fetch_publication ({ 'id' : m [ 'publication_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) cache [ f \"pub: { m [ 'publication_id' ] } \" ] = m_obj [ 'publication' ] if f \"res: { m [ 'resource_id' ] } \" in cache : m_obj [ 'resource' ] = cache [ f \"res: { m [ 'resource_id' ] } \" ] else : m_obj [ 'resource' ] = fetch_resource ({ 'id' : m [ 'resource_id' ]}, expanded = expanded , conn = conn , engine = engine , debug = debug ) cache [ f \"res: { m [ 'resource_id' ] } \" ] = m_obj [ 'resource' ] if f \"ver: { m [ 'version_id' ] } \" in cache : m_obj [ 'version' ] = cache [ f \"ver: { m [ 'version_id' ] } \" ] else : m_obj [ 'version' ] = fetch_version ({ 'id' : m [ 'version_id' ]}, conn = conn , engine = engine , debug = debug ) cache [ f \"ver: { m [ 'version_id' ] } \" ] = m_obj [ 'version' ] m_obj [ 'matched_aliases' ] = m [ 'matched_aliases' ][:: - 1 ] # reverse order to have highest count first m_obj [ 'match_count' ] = m [ 'match_count' ] m_obj [ 'mean_confidence' ] = m [ 'mean_confidence' ] mentions . append ( ResourceMention ( m_obj )) return mentions","title":"fetch_resource_mention"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_url","text":"fetch_url ( query , order_by = \"id\" , expanded = True , conn = None , engine = None , debug = False , ) Fetch URL(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. expanded ( bool , default: True ) \u2013 If True , fetch associated connection status. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ URL ] \u2013 single URL object (where single result if found), or list of URL objects if found, else None . Source code in globalbiodata/utils_fetch.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def fetch_url ( query : dict , order_by : str = 'id' , expanded : bool = True , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ URL ]: \"\"\"Fetch URL(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. expanded (bool, optional): If `True`, fetch associated connection status. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single URL object (where single result if found), or list of URL objects if found, else `None`. \"\"\" from .url import URL url_raw = select_from_table ( 'url' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( url_raw ) == 0 : return None urls = [] for u in url_raw : if expanded : u [ 'status' ] = fetch_connection_status ({ 'url_id' : u [ 'id' ]}, order_by = [ 'is_latest' , 'date' ], conn = conn , engine = engine , debug = debug ) u [ 'status' ] = [ u [ 'status' ]] if ( u [ 'status' ] is not None and type ( u [ 'status' ]) is not list ) else u [ 'status' ] u [ 'status' ] = u [ 'status' ][:: - 1 ] # reverse order to have latest first urls . append ( URL ( u )) return urls if len ( urls ) > 1 else urls [ 0 ]","title":"fetch_url"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_fetch.fetch_version","text":"fetch_version ( query , order_by = \"id\" , conn = None , engine = None , debug = False , ) Fetch Version(s) from the database matching the provided query. Parameters: query ( dict ) \u2013 Dictionary of column names and values to match for selection. order_by ( str , default: 'id' ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Optional [ Version ] \u2013 single Version object (where single result if found), or list of Version objects if found, else None . Source code in globalbiodata/utils_fetch.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def fetch_version ( query : dict , order_by : str = 'id' , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Optional [ Version ]: \"\"\"Fetch Version(s) from the database matching the provided query. Args: query (dict): Dictionary of column names and values to match for selection. order_by (str, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: single Version object (where single result if found), or list of Version objects if found, else `None`. \"\"\" from .version import Version version_raw = select_from_table ( 'version' , query , order_by = order_by , conn = conn , engine = engine , debug = debug ) if len ( version_raw ) == 0 : return None versions = [ Version ( p ) for p in version_raw ] return versions if len ( versions ) > 1 else versions [ 0 ]","title":"fetch_version"},{"location":"api/globalbiodata_utils/#generic-database-interactors","text":"","title":"Generic database interactors"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_db","text":"","title":"utils_db"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_db.delete_from_table","text":"delete_from_table ( table_name , data , conn = None , engine = None , debug = False ) Delete rows from a table matching the provided data. Parameters: table_name ( str ) \u2013 Name of the table to delete from. data ( dict ) \u2013 Dictionary of column names and values to match for deletion. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/utils_db.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 def delete_from_table ( table_name : str , data : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete rows from a table matching the provided data. Args: table_name (str): Name of the table to delete from. data (dict): Dictionary of column names and values to match for deletion. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" metadata_obj = db . MetaData () conn_created = False if conn is None : if engine is None : raise ValueError ( \"select_from_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect the table using the active connection table = db . Table ( table_name , metadata_obj , autoload_with = conn ) data = _stringify_data ( data ) if debug : print ( f \" \\n --> Deleting from table: { table_name } WHERE:\" ) print ( ' AND ' . join ([ f \" { k } == { data [ k ] } \" for k in data . keys ()])) trans = conn . begin () if not conn . in_transaction () else None # Begin a transaction if we're not already in one try : wheres = [ table . columns . get ( c ) == data [ c ] for c in data . keys ()] del_result = conn . execute ( db . delete ( table ) . where ( db . and_ ( * wheres ))) if debug : print ( f \"Deleted { del_result . rowcount } rows.\" ) trans . commit () # Commit the transaction except Exception as e : if trans : trans . rollback () # Rollback the transaction if an error occurs sys . stderr . write ( f \"Transaction rolled back due to: { e } \\n \" ) raise finally : if conn_created : conn . close () # Close the connection return del_result . rowcount","title":"delete_from_table"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_db.insert_into_table","text":"insert_into_table ( table_name , data , conn = None , engine = None , debug = False , filter_long_data = False , retry_on_deadlock = True , max_retries = 5 , base_delay = 0.2 , ) Insert-or-update a row and return its id. Parameters: table_name ( str ) \u2013 Name of the table to insert into. data ( dict ) \u2013 Dictionary of column names and values to insert. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. filter_long_data ( bool , default: False ) \u2013 If True , move overlength strings to long_text table. retry_on_deadlock ( bool , default: True ) \u2013 If True , retry on deadlock errors. max_retries ( int , default: 5 ) \u2013 Maximum number of retries on deadlock. base_delay ( float , default: 0.2 ) \u2013 Base delay in seconds for exponential backoff. Returns: int \u2013 The ID/PK of the inserted or updated row. Source code in globalbiodata/utils_db.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def insert_into_table ( table_name : str , data : dict , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False , filter_long_data : bool = False , retry_on_deadlock : bool = True , max_retries : int = 5 , base_delay : float = 0.2 , ) -> int : \"\"\"Insert-or-update a row and return its id. Args: table_name (str): Name of the table to insert into. data (dict): Dictionary of column names and values to insert. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. filter_long_data (bool, optional): If `True`, move overlength strings to long_text table. retry_on_deadlock (bool, optional): If `True`, retry on deadlock errors. max_retries (int, optional): Maximum number of retries on deadlock. base_delay (float, optional): Base delay in seconds for exponential backoff. Returns: The ID/PK of the inserted or updated row. \"\"\" metadata_obj = db . MetaData () conn_created = False if conn is None : if engine is None : raise ValueError ( \"insert_into_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect the table using the ENGINE (separate pooled connection) to avoid # starting an implicit transaction on our working connection. table = db . Table ( table_name , metadata_obj , autoload_with = conn ) pk_cols = _get_primary_keys ( table , conn ) data = _stringify_data ( data ) if debug : print ( f \" \\n --> Inserting into table: { table_name } \" ) print ( data ) print ( f \"Columns: { ', ' . join ( table . columns . keys ()) } \" ) print ( f \"Primary keys: { ', ' . join ( pk_cols ) } \" ) # Optionally move overlength strings to long_text and replace with reference token if filter_long_data : for k , v in list ( data . items ()): this_max_len = _get_max_len ( k , table_name , conn = conn , engine = engine ) if v and this_max_len and isinstance ( v , str ) and len ( v ) > this_max_len : longtext_id = insert_into_table ( 'long_text' , { 'text' : v }, conn = conn , engine = engine , debug = debug ) data [ k ] = f \"long_text( { longtext_id } )\" # We \"own\" the transaction if we opened this connection in this function. # Reflection above may have triggered an implicit txn elsewhere; don't let that # disable retries. We manage our own explicit txn when we created the conn. own_txn = conn_created # print(f\"conn_created={conn_created}, own_txn={own_txn}, conn.in_transaction()={conn.in_transaction()}\") # Retry loop only if we control our own transaction attempts = 0 while True : attempts += 1 # If we own the connection, start an explicit transaction only if one isn't already active implicit_txn = conn . in_transaction () trans = conn . begin () if ( own_txn and not implicit_txn ) else None try : insert_stmt = insert ( table ) . values ( data ) data_no_pks = _remove_key_fields ( table , conn , data ) if data_no_pks : # typical path: upsert (ON DUPLICATE KEY UPDATE) if pk_cols and len ( pk_cols ) == 1 : # single primary key: use LAST_INSERT_ID() hack to get the id of existing row if no insert occurred pk_name = pk_cols [ 0 ] data_no_pks [ pk_name ] = db . func . last_insert_id ( table . c [ pk_name ]) do_update_stmt = insert_stmt . on_duplicate_key_update ( ** data_no_pks ) if debug : print ( f \"Updating { table_name } with data: { data_no_pks } \" ) result = conn . execute ( do_update_stmt ) else : # tables that are pure key rows result = conn . execute ( insert_stmt . prefix_with ( 'IGNORE' )) if trans is not None : trans . commit () elif own_txn and implicit_txn and conn . in_transaction (): # We own the connection and were already in an implicit txn (likely started by prior metadata queries) conn . commit () inserted_pk = result . inserted_primary_key [ 0 ] if result . inserted_primary_key else None affected_rows = result . rowcount # Determine the resulting id to return if ( not inserted_pk ) or ( inserted_pk and affected_rows == 0 ): # entity existed and was not updated existing_id = conn . execute ( db . text ( \"SELECT LAST_INSERT_ID()\" )) . scalar () if len ( pk_cols ) == 1 else _fetch_id_from_unique_keys ( table , data , conn , debug = debug ) if debug : print ( f \"Entity already exists. Fetched id: { existing_id } \" ) this_id = existing_id elif ( inserted_pk and affected_rows > 1 ): # entity existed and was updated (MySQL reports >1 affected rows on upsert-update) this_id = inserted_pk if debug : print ( f \"Entity already exists. Updated id: { this_id } \" ) else : this_id = inserted_pk if debug : print ( f \"New entity added. Inserted id: { this_id } \" ) # Success; break retry loop break except OperationalError as e : # MySQL deadlock / lock wait timeout codes code = None try : code = e . orig . args [ 0 ] except Exception : pass if trans is not None : try : trans . rollback () except Exception : pass elif own_txn and conn . in_transaction (): try : conn . rollback () except Exception : pass # If we don't own the transaction or retries disabled, re-raise immediately if not own_txn or not retry_on_deadlock or code not in ( 1213 , 1205 ): raise # Backoff and retry (we own the txn) if attempts > max_retries : raise # Exponential backoff with jitter delay = ( base_delay * ( 2 ** ( attempts - 1 ))) * ( 1 + 0.25 * random . random ()) if debug : sys . stderr . write ( f \"[retry] { table_name } : OperationalError { code } ; attempt { attempts } / { max_retries } ; sleeping { delay : .2f } s \\n \" ) time . sleep ( delay ) continue except Exception as e : if trans is not None : try : trans . rollback () except Exception : pass elif own_txn and conn . in_transaction (): try : conn . rollback () except Exception : pass sys . stderr . write ( f \"Transaction rolled back due to: { e } \\n \" ) raise finally : if conn_created and own_txn and not conn . closed : # keep connection open for caller if they provided it; otherwise close at end pass if conn_created : conn . close () return this_id","title":"insert_into_table"},{"location":"api/globalbiodata_utils/#globalbiodata.utils_db.select_from_table","text":"select_from_table ( table_name , data = {}, join_table = None , order_by = None , conn = None , engine = None , debug = False , ) Select rows from a table matching the provided data. Parameters: table_name ( str ) \u2013 Name of the table to select from. data ( dict , default: {} ) \u2013 Dictionary of column names and values to match for selection. join_table ( str , default: None ) \u2013 Name of a table to join with. order_by ( list , default: None ) \u2013 Column name(s) to order the results by. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: list \u2013 List of dictionaries representing the selected rows. Source code in globalbiodata/utils_db.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def select_from_table ( table_name : str , data : dict = {}, join_table : str = None , order_by : list = None , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> list : \"\"\"Select rows from a table matching the provided data. Args: table_name (str): Name of the table to select from. data (dict, optional): Dictionary of column names and values to match for selection. join_table (str, optional): Name of a table to join with. order_by (list, optional): Column name(s) to order the results by. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: List of dictionaries representing the selected rows. \"\"\" metadata_obj = db . MetaData () # Ensure we have a live connection before reflecting conn_created = False if conn is None : if engine is None : raise ValueError ( \"select_from_table requires either an engine or an open connection\" ) conn = engine . connect () conn_created = True # Reflect using the active connection (works in SA 1.4/2.0) table = db . Table ( table_name , metadata_obj , autoload_with = conn ) if join_table : join_tbl = db . Table ( join_table , metadata_obj , autoload_with = conn ) table = table . join ( join_tbl ) # print(\"JOINED TABLE COLUMNS:\", table.columns.keys()) if debug : print ( f \" \\n --> Selecting from table: { table_name } WHERE:\" ) print ( 'AND ' . join ([ f \" { k } == ' { data [ k ] } '\" for k in data . keys ()])) wheres = [ table . columns . get ( c ) . in_ ( data [ c ]) if isinstance ( data [ c ], list ) else table . columns . get ( c ) == data [ c ] for c in data ] # construct select statement with correct options stmt = db . select ( table ) if wheres : stmt = stmt . where ( db . and_ ( * wheres )) if order_by : if isinstance ( order_by , list ): order_cols = [ table . columns . get ( col ) for col in order_by if table . columns . get ( col ) is not None ] if order_cols : stmt = stmt . order_by ( * order_cols ) else : order_col = table . columns . get ( order_by ) if order_col is not None : stmt = stmt . order_by ( order_col ) result = conn . execute ( stmt ) . fetchall () # convert result to list of dicts d_result = [ dict ( zip ( table . columns . keys (), list ( r ))) for r in result ] if conn_created : conn . close () return d_result","title":"select_from_table"},{"location":"api/globalbiodata_utils/#other-utility-methods","text":"","title":"Other utility methods"},{"location":"api/globalbiodata_utils/#globalbiodata.utils","text":"","title":"utils"},{"location":"api/globalbiodata_utils/#globalbiodata.utils.extract_fields_by_type","text":"extract_fields_by_type ( data , type_prefix ) Extract fields from a dictionary that start with a given prefix. Parameters: data ( dict ) \u2013 Input dictionary. type_prefix ( str ) \u2013 Prefix to filter keys. Returns: dict \u2013 Dictionary with extracted fields. Source code in globalbiodata/utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def extract_fields_by_type ( data : dict , type_prefix : str ) -> dict : \"\"\"Extract fields from a dictionary that start with a given prefix. Args: data (dict): Input dictionary. type_prefix (str): Prefix to filter keys. Returns: Dictionary with extracted fields. \"\"\" extracted = {} for k , v in data . items (): if k . startswith ( f \" { type_prefix } _\" ): extracted [ re . sub ( f \"^ { type_prefix } _\" , \"\" , k )] = v return extracted","title":"extract_fields_by_type"},{"location":"api/globalbiodata_utils/#globalbiodata.utils.new_publication_from_EuropePMC_result","text":"new_publication_from_EuropePMC_result ( epmc_result , google_maps_api_key = None ) Create a new Publication object from an EuropePMC search result, including additional geographic metadata enrichment. Parameters: epmc_result ( dict ) \u2013 EuropePMC search result metadata. google_maps_api_key ( str , default: None ) \u2013 Google Maps API key for advanced geolocation. Returns: Publication \u2013 New Publication object. Source code in globalbiodata/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def new_publication_from_EuropePMC_result ( epmc_result : dict , google_maps_api_key : str = None ) -> Publication : \"\"\"Create a new Publication object from an EuropePMC search result, including additional geographic metadata enrichment. Args: epmc_result (dict): EuropePMC search result metadata. google_maps_api_key (str, optional): Google Maps API key for advanced geolocation. Returns: New Publication object. \"\"\" print ( f \"Creating new Publication from EuropePMC result: { epmc_result . get ( 'title' , '' ) } (PMID: { epmc_result . get ( 'pmid' , '' ) } )\" ) print ( \"Searching for author affiliations and countries...\" ) affiliations , countries = _extract_affiliations ( epmc_result , google_maps_api_key = google_maps_api_key ) print ( f \" Found countries: { ', ' . join ( countries ) if countries else 'None found' } \" ) new_publication = Publication ({ 'publication_title' : epmc_result . get ( 'title' , '' ), 'pubmed_id' : epmc_result . get ( 'pmid' , None ), 'pmc_id' : epmc_result . get ( 'pmcid' , '' ), 'publication_date' : epmc_result . get ( 'journalInfo' , {}) . get ( 'printPublicationDate' ) or epmc_result . get ( 'firstPublicationDate' ), 'grants' : _extract_grants ( epmc_result ), 'keywords' : '; ' . join ( _extract_keywords ( epmc_result )), 'citation_count' : epmc_result . get ( 'citedByCount' , 0 ), 'authors' : epmc_result . get ( 'authorString' , '' ), 'affiliation' : affiliations , 'affiliation_countries' : countries }) return new_publication","title":"new_publication_from_EuropePMC_result"},{"location":"api/globalbiodata_version/","text":"globalbiodata.version Version dataclass Class to represent Version information Attributes: id ( int ) \u2013 Database ID for Version name ( str ) \u2013 Name of version/pipeline/type date ( date ) \u2013 Date of run user ( str ) \u2013 User who ran pipeline additional_metadata ( dict ) \u2013 Additional data in JSON format Source code in globalbiodata/version.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @dataclass class Version : \"\"\" Class to represent Version information Attributes: id (int): Database ID for Version name (str): Name of version/pipeline/type date (date): Date of run user (str): User who ran pipeline additional_metadata (dict): Additional data in JSON format \"\"\" id : int name : str date : date user : str additional_metadata : dict def __init__ ( self , p ): self . id = p . get ( 'id' ) self . name = p . get ( 'version_name' ) or p . get ( 'name' ) self . date = p . get ( 'version_date' ) or p . get ( 'date' ) self . user = p . get ( 'version_user' ) or p . get ( 'user' ) self . additional_metadata = p . get ( 'additional_version_metadata' ) or p . get ( 'additional_metadata' ) self . date = datetime . strptime ( self . date , \"%Y-%m- %d \" ) . date () if self . date and type ( self . date ) is str else self . date def __str__ ( self ): version_str = f \"Version(id= { self . id } , name= { self . name } , date= { self . date } , user= { self . user } , additional_metadata= { self . additional_metadata } )\" return version_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write Version to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the Version written to the database. \"\"\" new_version_id = insert_into_table ( 'version' , self . __dict__ , conn = conn , engine = engine , debug = debug ) self . id = new_version_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Version from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Version object must have an ID to delete.\" ) del_result = delete_from_table ( 'version' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( version_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Version : \"\"\"Fetch Version from database by ID. Args: version_id (int): ID of the Version to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Version object. \"\"\" return fetch_version ({ 'id' : version_id }, conn = conn , engine = engine , debug = debug ) delete delete ( conn = None , engine = None , debug = False ) Delete Version from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/version.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Version from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Version object must have an ID to delete.\" ) del_result = delete_from_table ( 'version' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result fetch_by_id fetch_by_id ( version_id , conn = None , engine = None , debug = False ) Fetch Version from database by ID. Parameters: version_id ( int ) \u2013 ID of the Version to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Version \u2013 The fetched Version object. Source code in globalbiodata/version.py 77 78 79 80 81 82 83 84 85 86 87 88 89 def fetch_by_id ( version_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Version : \"\"\"Fetch Version from database by ID. Args: version_id (int): ID of the Version to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Version object. \"\"\" return fetch_version ({ 'id' : version_id }, conn = conn , engine = engine , debug = debug ) write write ( conn = None , engine = None , debug = False ) Write Version to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the Version written to the database. Source code in globalbiodata/version.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write Version to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the Version written to the database. \"\"\" new_version_id = insert_into_table ( 'version' , self . __dict__ , conn = conn , engine = engine , debug = debug ) self . id = new_version_id return self . id","title":"Version"},{"location":"api/globalbiodata_version/#globalbiodata.version","text":"","title":"version"},{"location":"api/globalbiodata_version/#globalbiodata.version.Version","text":"Class to represent Version information Attributes: id ( int ) \u2013 Database ID for Version name ( str ) \u2013 Name of version/pipeline/type date ( date ) \u2013 Date of run user ( str ) \u2013 User who ran pipeline additional_metadata ( dict ) \u2013 Additional data in JSON format Source code in globalbiodata/version.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @dataclass class Version : \"\"\" Class to represent Version information Attributes: id (int): Database ID for Version name (str): Name of version/pipeline/type date (date): Date of run user (str): User who ran pipeline additional_metadata (dict): Additional data in JSON format \"\"\" id : int name : str date : date user : str additional_metadata : dict def __init__ ( self , p ): self . id = p . get ( 'id' ) self . name = p . get ( 'version_name' ) or p . get ( 'name' ) self . date = p . get ( 'version_date' ) or p . get ( 'date' ) self . user = p . get ( 'version_user' ) or p . get ( 'user' ) self . additional_metadata = p . get ( 'additional_version_metadata' ) or p . get ( 'additional_metadata' ) self . date = datetime . strptime ( self . date , \"%Y-%m- %d \" ) . date () if self . date and type ( self . date ) is str else self . date def __str__ ( self ): version_str = f \"Version(id= { self . id } , name= { self . name } , date= { self . date } , user= { self . user } , additional_metadata= { self . additional_metadata } )\" return version_str def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write Version to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the Version written to the database. \"\"\" new_version_id = insert_into_table ( 'version' , self . __dict__ , conn = conn , engine = engine , debug = debug ) self . id = new_version_id return self . id def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Version from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Version object must have an ID to delete.\" ) del_result = delete_from_table ( 'version' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result def fetch_by_id ( version_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Version : \"\"\"Fetch Version from database by ID. Args: version_id (int): ID of the Version to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Version object. \"\"\" return fetch_version ({ 'id' : version_id }, conn = conn , engine = engine , debug = debug )","title":"Version"},{"location":"api/globalbiodata_version/#globalbiodata.version.Version.delete","text":"delete ( conn = None , engine = None , debug = False ) Delete Version from database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 Number of rows deleted. Source code in globalbiodata/version.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def delete ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Delete Version from database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: Number of rows deleted. \"\"\" if conn is None : conn = engine . connect () if not self . id : raise ValueError ( \"Version object must have an ID to delete.\" ) del_result = delete_from_table ( 'version' , { 'id' : self . id }, conn = conn , engine = engine , debug = debug ) return del_result","title":"delete"},{"location":"api/globalbiodata_version/#globalbiodata.version.Version.fetch_by_id","text":"fetch_by_id ( version_id , conn = None , engine = None , debug = False ) Fetch Version from database by ID. Parameters: version_id ( int ) \u2013 ID of the Version to fetch. conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: Version \u2013 The fetched Version object. Source code in globalbiodata/version.py 77 78 79 80 81 82 83 84 85 86 87 88 89 def fetch_by_id ( version_id : int , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> Version : \"\"\"Fetch Version from database by ID. Args: version_id (int): ID of the Version to fetch. conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The fetched Version object. \"\"\" return fetch_version ({ 'id' : version_id }, conn = conn , engine = engine , debug = debug )","title":"fetch_by_id"},{"location":"api/globalbiodata_version/#globalbiodata.version.Version.write","text":"write ( conn = None , engine = None , debug = False ) Write Version to database. Parameters: conn ( Optional [ Connection ] , default: None ) \u2013 SQLAlchemy Connection object. engine ( Optional [ Engine ] , default: None ) \u2013 SQLAlchemy Engine object. debug ( bool , default: False ) \u2013 If True , print debug information. Returns: int \u2013 The ID of the Version written to the database. Source code in globalbiodata/version.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def write ( self , conn : Optional [ Connection ] = None , engine : Optional [ Engine ] = None , debug : bool = False ) -> int : \"\"\"Write Version to database. Args: conn (Optional[Connection], optional): SQLAlchemy Connection object. engine (Optional[Engine], optional): SQLAlchemy Engine object. debug (bool, optional): If `True`, print debug information. Returns: The ID of the Version written to the database. \"\"\" new_version_id = insert_into_table ( 'version' , self . __dict__ , conn = conn , engine = engine , debug = debug ) self . id = new_version_id return self . id","title":"write"}]}